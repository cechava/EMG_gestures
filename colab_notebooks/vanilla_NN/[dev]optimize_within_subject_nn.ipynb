{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"[dev]optimize_within_subject_nn.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.13"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TyYD4oUuvm6h","executionInfo":{"status":"ok","timestamp":1632234593657,"user_tz":240,"elapsed":29224,"user":{"displayName":"Cesar Echavarria","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12535184235153277849"}},"outputId":"c173ba0d-8a4c-4660-b073-5ad4aa178cce"},"source":["#Run cell to mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AebVcdf9OWZc","executionInfo":{"status":"ok","timestamp":1632234631321,"user_tz":240,"elapsed":37093,"user":{"displayName":"Cesar Echavarria","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12535184235153277849"}},"outputId":"d75651fd-79e2-474f-c660-c63c515c9d28"},"source":["# install package to have access to custom functions\n","%pip install /content/drive/MyDrive/EMG_gestures/ --use-feature=in-tree-build"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing ./drive/MyDrive/EMG_gestures\n","Building wheels for collected packages: EMG-gestures\n","  Building wheel for EMG-gestures (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for EMG-gestures: filename=EMG_gestures-0.1.0-py3-none-any.whl size=45275 sha256=1b02117d413a379e84822104433b31c258750355e41e07a653736fc983e28888\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-bqvjjkjv/wheels/a2/b7/61/2147fa082a9e51bef5dcc38dd3f0898fe0554d62203c0e383e\n","Successfully built EMG-gestures\n","Installing collected packages: EMG-gestures\n","Successfully installed EMG-gestures-0.1.0\n"]}]},{"cell_type":"code","metadata":{"id":"RVmD2y3kvVQm","executionInfo":{"status":"ok","timestamp":1632234639910,"user_tz":240,"elapsed":2609,"user":{"displayName":"Cesar Echavarria","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12535184235153277849"}}},"source":["#import necessary packages\n","\n","#our workhorses\n","import numpy as np\n","import pandas as pd\n","import scipy\n","\n","#to visualize\n","%matplotlib inline\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","#style params for figures\n","sns.set(font_scale = 2)\n","plt.style.use('seaborn-white')\n","plt.rc(\"axes\", labelweight=\"bold\")\n","from IPython.display import display, HTML\n","\n","#to load files\n","import os\n","import sys\n","import h5py\n","\n","#import cusotm functions\n","from EMG_gestures.utils import *\n","from EMG_gestures.analysis import within_subject_nn_performance\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"oDh_RNK2SztA","executionInfo":{"status":"ok","timestamp":1632234639917,"user_tz":240,"elapsed":14,"user":{"displayName":"Cesar Echavarria","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12535184235153277849"}}},"source":["#define hyper params for each model\n","model_dict = {0:{'fe_layers':0, 'fe_activation':''},\\\n","              1:{'fe_layers':1, 'fe_activation':'tanh'},\\\n","              2:{'fe_layers':1, 'fe_activation':'relu'},\\\n","              3:{'fe_layers':2, 'fe_activation':'tanh'},\\\n","              4:{'fe_layers':2, 'fe_activation':'relu'},\\\n","              }\n"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wcuPGJLhvv3j","executionInfo":{"status":"ok","timestamp":1632153129744,"user_tz":240,"elapsed":301941,"user":{"displayName":"Cesar Echavarria","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12535184235153277849"}},"outputId":"e6587990-e925-41a3-edb6-7c088df9970c"},"source":["#define where the data files are located\n","data_folder = '/content/drive/MyDrive/EMG_gestures/EMG_data/'\n","results_folder = '/content/drive/MyDrive/EMG_gestures/results_data/single_subject_training/NN/'\n","\n","nsubjects = 36\n","\n","\n","# User-defined parameters\n","lo_freq = 20 #lower bound of bandpass filter\n","hi_freq = 450 #upper bound of bandpass filter\n","\n","win_size = 100 #define window size over which to compute time-domain features\n","step = win_size #keeping this parameter in case we want to re-run later with some overlap\n","\n","nreps = 10\n","exclude = [0,7]#labels to exclude\n","\n","#for NN training\n","verbose = 0\n","epochs = 1000\n","batch_size = 2\n","es_patience = 5\n","\n","#performance metrics\n","score_list = ['f1','accuracy']\n","model_id = 3\n","#for model_id in range(4,5):\n","subject_id = 36\n","#    for subject_id in range(1,nsubjects+1):\n","\n","subject_folder = os.path.join(data_folder,'%02d'%(subject_id))\n","print('=======================')\n","print(subject_folder)\n","\n","# Process data and get features \n","#get features across segments and corresponding info\n","feature_matrix_sub, target_labels_sub, window_tstamps_sub, \\\n","block_labels_sub, series_labels_sub = get_subject_data_for_classification(subject_folder, lo_freq, hi_freq, \\\n","                                                                win_size, step)\n","np.random.seed(42)#for reproducibility\n","results_df = []#initialize empty array for dataframes\n","for rep in range(nreps):\n","    print('Model %d|Subject %d|Rep %d'%(model_id,subject_id, rep+1))\n","\n","    print('True Data')\n","    train_scores, test_scores, dummy, train_info_dict = within_subject_nn_performance(feature_matrix_sub, target_labels_sub, series_labels_sub,model_dict[model_id],\\\n","                                                                        exclude, score_list,\\\n","                                                                        verbose = 0, epochs = epochs, batch_size = batch_size, es_patience = es_patience)\n","    \n","    n_splits, n_scores = train_scores.shape\n","    #put testing results in dataframe\n","    data_dict = {'Fold':np.arange(n_splits)+1,\\\n","                        'Rep':[rep+1 for x in range(n_splits)],\\\n","                        'Type':['Train' for x in range(n_splits)],\\\n","                        'Shuffled':[False for x in range(n_splits)],\\\n","                        'Subject':[subject_id for x in range(n_splits)],\\\n","                'Epochs':[epochs for x in range(n_splits)],\\\n","                'Batch_Size':[batch_size for x in range(n_splits)],\\\n","                'Train_Loss':train_info_dict['train_loss'],\\\n","                    'Val_Loss':train_info_dict['val_loss'],\\\n","                    'Epochs_Trained':train_info_dict['epochs_trained'],\\\n","                }\n","    for sidx in range(n_scores):\n","        data_dict['%s_score'%(score_list[sidx])] = train_scores[:,sidx]\n","    results_df.append(pd.DataFrame(data_dict))\n","\n","    data_dict = {'Fold':np.arange(n_splits)+1,\\\n","                        'Rep':[rep+1 for x in range(n_splits)],\\\n","                        'Type':['Test' for x in range(n_splits)],\\\n","                        'Shuffled':[False for x in range(n_splits)],\\\n","                        'Subject':[subject_id for x in range(n_splits)],\\\n","                    'Epochs':[epochs for x in range(n_splits)],\\\n","                'Batch_Size':[batch_size for x in range(n_splits)],\\\n","                'Train_Loss':train_info_dict['train_loss'],\\\n","                    'Val_Loss':train_info_dict['val_loss'],\\\n","                    'Epochs_Trained':train_info_dict['epochs_trained'],\\\n","                }\n","    for sidx in range(n_scores):\n","        data_dict['%s_score'%(score_list[sidx])] = test_scores[:,sidx]\n","    results_df.append(pd.DataFrame(data_dict))\n","\n","\n","    \n","    print('Permuted Data')\n","    target_labels_sub_perm = permute_class_within_sub(target_labels_sub, block_labels_sub, series_labels_sub, exclude)\n","    train_scores, test_scores, dummy, train_info_dict = within_subject_nn_performance(feature_matrix_sub, target_labels_sub_perm, series_labels_sub,model_dict[model_id], exclude, score_list,\\\n","                                                                        verbose = 0, epochs = epochs, batch_size = batch_size, es_patience = es_patience)\n","    n_splits, n_scores = train_scores.shape\n","    #put testing results in dataframe\n","    data_dict = {'Fold':np.arange(n_splits)+1,\\\n","                        'Rep':[rep+1 for x in range(n_splits)],\\\n","                        'Type':['Train' for x in range(n_splits)],\\\n","                        'Shuffled':[True for x in range(n_splits)],\\\n","                        'Subject':[subject_id for x in range(n_splits)],\\\n","                    'Epochs':[epochs for x in range(n_splits)],\\\n","                'Batch_Size':[batch_size for x in range(n_splits)],\\\n","                'Train_Loss':train_info_dict['train_loss'],\\\n","                    'Val_Loss':train_info_dict['val_loss'],\\\n","                    'Epochs_Trained':train_info_dict['epochs_trained'],\\\n","                }\n","    for sidx in range(n_scores):\n","        data_dict['%s_score'%(score_list[sidx])] = train_scores[:,sidx]\n","    results_df.append(pd.DataFrame(data_dict))\n","\n","    data_dict = {'Fold':np.arange(n_splits)+1,\\\n","                        'Rep':[rep+1 for x in range(n_splits)],\\\n","                        'Type':['Test' for x in range(n_splits)],\\\n","                        'Shuffled':[True for x in range(n_splits)],\\\n","                        'Subject':[subject_id for x in range(n_splits)],\\\n","                    'Epochs':[epochs for x in range(n_splits)],\\\n","                'Batch_Size':[batch_size for x in range(n_splits)],\\\n","                'Train_Loss':train_info_dict['train_loss'],\\\n","                    'Val_Loss':train_info_dict['val_loss'],\\\n","                    'Epochs_Trained':train_info_dict['epochs_trained'],\\\n","                }\n","    for sidx in range(n_scores):\n","        data_dict['%s_score'%(score_list[sidx])] = test_scores[:,sidx]\n","    results_df.append(pd.DataFrame(data_dict))\n","\n","results_df = pd.concat(results_df, axis = 0)\n","# #save results to file\n","results_fn = 'subject_%02d_model_%d_within_subject_results.h5'%(subject_id, model_id)\n","results_df.to_hdf(os.path.join(results_folder,results_fn), key='results_df', mode='w')\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/36\n","Model 3|Subject 36|Rep 1\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Model 3|Subject 36|Rep 2\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Model 3|Subject 36|Rep 3\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Model 3|Subject 36|Rep 4\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Model 3|Subject 36|Rep 5\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Model 3|Subject 36|Rep 6\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Model 3|Subject 36|Rep 7\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Model 3|Subject 36|Rep 8\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Model 3|Subject 36|Rep 9\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Model 3|Subject 36|Rep 10\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":200},"id":"2P5DDNKiRSxj","executionInfo":{"elapsed":199,"status":"ok","timestamp":1631890582217,"user":{"displayName":"Cesar Echavarria","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12535184235153277849"},"user_tz":240},"outputId":"c392af02-74bb-48f9-c284-fbb2ce9cf1dc"},"source":["results_df.groupby(['Shuffled','Type']).mean()"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th>Fold</th>\n","      <th>Rep</th>\n","      <th>Subject</th>\n","      <th>f1_score</th>\n","      <th>accuracy_score</th>\n","    </tr>\n","    <tr>\n","      <th>Shuffled</th>\n","      <th>Type</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">False</th>\n","      <th>Test</th>\n","      <td>1.5</td>\n","      <td>5.5</td>\n","      <td>36.0</td>\n","      <td>0.922077</td>\n","      <td>0.923213</td>\n","    </tr>\n","    <tr>\n","      <th>Train</th>\n","      <td>1.5</td>\n","      <td>5.5</td>\n","      <td>36.0</td>\n","      <td>0.989461</td>\n","      <td>0.989475</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">True</th>\n","      <th>Test</th>\n","      <td>1.5</td>\n","      <td>5.5</td>\n","      <td>36.0</td>\n","      <td>0.139313</td>\n","      <td>0.143898</td>\n","    </tr>\n","    <tr>\n","      <th>Train</th>\n","      <td>1.5</td>\n","      <td>5.5</td>\n","      <td>36.0</td>\n","      <td>0.701098</td>\n","      <td>0.716220</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                Fold  Rep  Subject  f1_score  accuracy_score\n","Shuffled Type                                               \n","False    Test    1.5  5.5     36.0  0.922077        0.923213\n","         Train   1.5  5.5     36.0  0.989461        0.989475\n","True     Test    1.5  5.5     36.0  0.139313        0.143898\n","         Train   1.5  5.5     36.0  0.701098        0.716220"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KAJVnlTH0UOQ","outputId":"f0b1e29e-b9b8-4d90-aa30-ddd3c01096f7"},"source":["#define where the data files are located\n","data_folder = '/content/drive/MyDrive/EMG_gestures/EMG_data/'\n","results_folder = '/content/drive/MyDrive/EMG_gestures/results_data/single_subject_training/NN/batch_size_comparison'\n","\n","nsubjects = 36\n","\n","\n","# User-defined parameters\n","lo_freq = 20 #lower bound of bandpass filter\n","hi_freq = 450 #upper bound of bandpass filter\n","\n","win_size = 100 #define window size over which to compute time-domain features\n","step = win_size #keeping this parameter in case we want to re-run later with some overlap\n","\n","nreps = 10\n","exclude = [0,7]#labels to exclude\n","\n","#for NN training\n","verbose = 0\n","epochs = 1000\n","#batch_size = 5\n","es_patience = 5\n","\n","#performance metrics\n","score_list = ['f1','accuracy']\n","model_id = 1\n","for batch_size in [5, 10,20]:\n","\n","    for subject_id in range(1,nsubjects+1):\n","\n","        subject_folder = os.path.join(data_folder,'%02d'%(subject_id))\n","        print('=======================')\n","        print(subject_folder)\n","\n","        # Process data and get features \n","        #get features across segments and corresponding info\n","        feature_matrix_sub, target_labels_sub, window_tstamps_sub, \\\n","        block_labels_sub, series_labels_sub = get_subject_data_for_classification(subject_folder, lo_freq, hi_freq, \\\n","                                                                        win_size, step)\n","        np.random.seed(42)#for reproducibility\n","        results_df = []#initialize empty array for dataframes\n","        for rep in range(nreps):\n","            print('Batch Size %d|Subject %d|Rep %d'%(batch_size,subject_id, rep+1))\n","\n","            print('True Data')\n","            train_scores, test_scores, dummy, train_info_dict = within_subject_nn_performance(feature_matrix_sub, target_labels_sub, series_labels_sub,model_dict[model_id],\\\n","                                                                                exclude, score_list,\\\n","                                                                                verbose = 0, epochs = epochs, batch_size = batch_size, es_patience = es_patience)\n","            \n","            n_splits, n_scores = train_scores.shape\n","            #put testing results in dataframe\n","            data_dict = {'Fold':np.arange(n_splits)+1,\\\n","                                'Rep':[rep+1 for x in range(n_splits)],\\\n","                                'Type':['Train' for x in range(n_splits)],\\\n","                                'Shuffled':[False for x in range(n_splits)],\\\n","                                'Subject':[subject_id for x in range(n_splits)],\\\n","                        'Epochs':[epochs for x in range(n_splits)],\\\n","                        'Batch_Size':[batch_size for x in range(n_splits)],\\\n","                        'Train_Loss':train_info_dict['train_loss'],\\\n","                            'Val_Loss':train_info_dict['val_loss'],\\\n","                            'Epochs_Trained':train_info_dict['epochs_trained'],\\\n","                        }\n","            for sidx in range(n_scores):\n","                data_dict['%s_score'%(score_list[sidx])] = train_scores[:,sidx]\n","            results_df.append(pd.DataFrame(data_dict))\n","\n","            data_dict = {'Fold':np.arange(n_splits)+1,\\\n","                                'Rep':[rep+1 for x in range(n_splits)],\\\n","                                'Type':['Test' for x in range(n_splits)],\\\n","                                'Shuffled':[False for x in range(n_splits)],\\\n","                                'Subject':[subject_id for x in range(n_splits)],\\\n","                            'Epochs':[epochs for x in range(n_splits)],\\\n","                        'Batch_Size':[batch_size for x in range(n_splits)],\\\n","                        'Train_Loss':train_info_dict['train_loss'],\\\n","                            'Val_Loss':train_info_dict['val_loss'],\\\n","                            'Epochs_Trained':train_info_dict['epochs_trained'],\\\n","                        }\n","            for sidx in range(n_scores):\n","                data_dict['%s_score'%(score_list[sidx])] = test_scores[:,sidx]\n","            results_df.append(pd.DataFrame(data_dict))\n","\n","\n","            \n","            print('Permuted Data')\n","            target_labels_sub_perm = permute_class_within_sub(target_labels_sub, block_labels_sub, series_labels_sub, exclude)\n","            train_scores, test_scores, dummy, train_info_dict = within_subject_nn_performance(feature_matrix_sub, target_labels_sub_perm, series_labels_sub,model_dict[model_id], exclude, score_list,\\\n","                                                                                verbose = 0, epochs = epochs, batch_size = batch_size, es_patience = es_patience)\n","            n_splits, n_scores = train_scores.shape\n","            #put testing results in dataframe\n","            data_dict = {'Fold':np.arange(n_splits)+1,\\\n","                                'Rep':[rep+1 for x in range(n_splits)],\\\n","                                'Type':['Train' for x in range(n_splits)],\\\n","                                'Shuffled':[True for x in range(n_splits)],\\\n","                                'Subject':[subject_id for x in range(n_splits)],\\\n","                            'Epochs':[epochs for x in range(n_splits)],\\\n","                        'Batch_Size':[batch_size for x in range(n_splits)],\\\n","                        'Train_Loss':train_info_dict['train_loss'],\\\n","                            'Val_Loss':train_info_dict['val_loss'],\\\n","                            'Epochs_Trained':train_info_dict['epochs_trained'],\\\n","                        }\n","            for sidx in range(n_scores):\n","                data_dict['%s_score'%(score_list[sidx])] = train_scores[:,sidx]\n","            results_df.append(pd.DataFrame(data_dict))\n","\n","            data_dict = {'Fold':np.arange(n_splits)+1,\\\n","                                'Rep':[rep+1 for x in range(n_splits)],\\\n","                                'Type':['Test' for x in range(n_splits)],\\\n","                                'Shuffled':[True for x in range(n_splits)],\\\n","                                'Subject':[subject_id for x in range(n_splits)],\\\n","                            'Epochs':[epochs for x in range(n_splits)],\\\n","                        'Batch_Size':[batch_size for x in range(n_splits)],\\\n","                        'Train_Loss':train_info_dict['train_loss'],\\\n","                            'Val_Loss':train_info_dict['val_loss'],\\\n","                            'Epochs_Trained':train_info_dict['epochs_trained'],\\\n","                        }\n","            for sidx in range(n_scores):\n","                data_dict['%s_score'%(score_list[sidx])] = test_scores[:,sidx]\n","            results_df.append(pd.DataFrame(data_dict))\n","\n","        results_df = pd.concat(results_df, axis = 0)\n","        # #save results to file\n","        results_fn = 'subject_%02d_batch_size_%02d_within_subject_results.h5'%(subject_id, batch_size)\n","        results_df.to_hdf(os.path.join(results_folder,results_fn), key='results_df', mode='w')\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/01\n","Batch Size 5|Subject 1|Rep 1\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 1|Rep 2\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 1|Rep 3\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 1|Rep 4\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 1|Rep 5\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 1|Rep 6\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 1|Rep 7\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 1|Rep 8\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 1|Rep 9\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 1|Rep 10\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/02\n","Batch Size 5|Subject 2|Rep 1\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 2|Rep 2\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 2|Rep 3\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 2|Rep 4\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 2|Rep 5\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 2|Rep 6\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 2|Rep 7\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 2|Rep 8\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 2|Rep 9\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 2|Rep 10\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/03\n","Batch Size 5|Subject 3|Rep 1\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 3|Rep 2\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 3|Rep 3\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 3|Rep 4\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 3|Rep 5\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 3|Rep 6\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 3|Rep 7\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 3|Rep 8\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 3|Rep 9\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 3|Rep 10\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/04\n","Batch Size 5|Subject 4|Rep 1\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 4|Rep 2\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 4|Rep 3\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 4|Rep 4\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 4|Rep 5\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 4|Rep 6\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 4|Rep 7\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 4|Rep 8\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 4|Rep 9\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 4|Rep 10\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/05\n","Batch Size 5|Subject 5|Rep 1\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 5|Rep 2\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 5|Rep 3\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 5|Rep 4\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 5|Rep 5\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 5|Rep 6\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 5|Rep 7\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 5|Rep 8\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 5|Rep 9\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 5|Rep 10\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/06\n","Batch Size 5|Subject 6|Rep 1\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 6|Rep 2\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 6|Rep 3\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 6|Rep 4\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 6|Rep 5\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 6|Rep 6\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 6|Rep 7\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 6|Rep 8\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 6|Rep 9\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 6|Rep 10\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/07\n","Batch Size 5|Subject 7|Rep 1\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 7|Rep 2\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 7|Rep 3\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 7|Rep 4\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 7|Rep 5\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 7|Rep 6\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 7|Rep 7\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 7|Rep 8\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 7|Rep 9\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 7|Rep 10\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/08\n","Batch Size 5|Subject 8|Rep 1\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 8|Rep 2\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 8|Rep 3\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 8|Rep 4\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 8|Rep 5\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 8|Rep 6\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 8|Rep 7\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 8|Rep 8\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 8|Rep 9\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 8|Rep 10\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/09\n","Batch Size 5|Subject 9|Rep 1\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 9|Rep 2\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 9|Rep 3\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 9|Rep 4\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 9|Rep 5\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 9|Rep 6\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 9|Rep 7\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 9|Rep 8\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 9|Rep 9\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 9|Rep 10\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/10\n","Batch Size 5|Subject 10|Rep 1\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 10|Rep 2\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model\n","Batch Size 5|Subject 10|Rep 3\n","True Data\n","Split Count: 1\n","Training Model\n","Evaluate Model\n","Split Count: 2\n","Training Model\n"]}]},{"cell_type":"code","metadata":{"id":"UmJA3Z0DxiPL"},"source":[""],"execution_count":null,"outputs":[]}]}