{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"across_subject_NN_transform_module.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyPy4KZu/QkWWL0tW6dQHx5P"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"pvTu1kDdN82T"},"source":["# **Transform module approach**\n","\n","# General Idea\n","The general idea of a transform module is to pre-pend a number of layers to the feature extraction module of the network. These layers can be trained jointly or independently of the rest of the network, by freezing the weights of layers outside the tranform module. The transform module is trained with each subject's data independently in order to find a transformation of that subject's data that minimizes the overal network loss.\n","\n","Data from a total of 6 subjects was used as a held-out test set. The data from the remaining 26 subjects was used to train the whole network.\n","\n","# Transform module architecture and hyperparameter selection\n","  A 4-fold cross-validation scheme across subjects was used to select the transform module architecture and activation function that provided the best cross-validation test score. During these training scheme, subjects' data in the held-out fold were not included in the training of the feature extraction layers. Model performance for these held-out subjects was evaluated with a 2-fold cross-validations scheme within each subject. That is, one half of each subject's data was used to train the transfer module portion of the network and model performance was evaluated on the other half.\n","*The results of the above approach for various transofrm module architecture and hyperparameter settings can be found in dev_notebooks/[dev]visualize_xsubject_robustness_transform_module. *  Cross-validation scores from the above scheme showed that a transform module with a single layer and a linear activation function had the best generalization performance on held-out subjects not used to train the feature extration module of the network. \n","\n","\n","# Training and testing model\n","A transform module consisting of a single layer with linear activation function is pre-pended to the feature extraction module of the neural network. This transfer module is independently trained for each training subject while the feature extraction layers are trained jointly across all training subjects. After this training stage, the weights of layers outside the transform module are frozen.\n","\n","Model test performance was obtained by evaluating model with a set of 6 held-out subjects not used to trained the feature extraction module. For these test subjects, transform module layers were trained with half of the data and model performance was evaluated on the held-out data. Cross-validated test performance was obtained with a 2-fold cross-validation scheme.\n"]},{"cell_type":"code","metadata":{"id":"IbZgYOxVN-wt"},"source":["#Run cell to mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CC3YpA5RX2iO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636216762870,"user_tz":240,"elapsed":26430,"user":{"displayName":"Cesar Echavarria","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12535184235153277849"}},"outputId":"31fc1647-4d46-4838-9f3c-bbd8547d00c2"},"source":["# install package to have access to custom functions\n","%pip install /content/drive/Othercomputers/'My MacBook Pro'/EMG_gestures/ --use-feature=in-tree-build"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing ./drive/Othercomputers/My MacBook Pro/EMG_gestures\n","Building wheels for collected packages: EMG-gestures\n","  Building wheel for EMG-gestures (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for EMG-gestures: filename=EMG_gestures-0.1.0-py3-none-any.whl size=31272 sha256=9fc7704d0108b73ce5837e43368cb42bcc09e9a318321891916fbeb7b27fb77b\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-td8y6jv8/wheels/74/96/87/ceb916fceabb875209ae993e697bf574966ab592f4167a4958\n","Successfully built EMG-gestures\n","Installing collected packages: EMG-gestures\n","Successfully installed EMG-gestures-0.1.0\n"]}]},{"cell_type":"code","metadata":{"id":"RVmD2y3kvVQm","executionInfo":{"status":"ok","timestamp":1636217368076,"user_tz":240,"elapsed":191,"user":{"displayName":"Cesar Echavarria","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12535184235153277849"}}},"source":["#import necessary packages\n","\n","#our workhorses\n","import numpy as np\n","import pandas as pd\n","import scipy\n","\n","#to visualize\n","%matplotlib inline\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","#style params for figures\n","sns.set(font_scale = 2)\n","plt.style.use('seaborn-white')\n","plt.rc(\"axes\", labelweight=\"bold\")\n","from IPython.display import display, HTML\n","\n","#to load files\n","import os\n","import sys\n","import h5py\n","import pickle\n","import keras\n","\n","#import cusotm functions\n","from EMG_gestures.utils import *\n","from EMG_gestures.analysis import nn_xsubject_transform_module_train_frac_subjects,\\\n"," nn_xsubject_transform_module_train_all_subjects,\\\n"," nn_xsubject_transform_module_test_subject_eval\n"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"IouUsT8S59b0"},"source":["#define where the data files are located\n","data_folder = '/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/'\n","\n","nsubjects = 36\n","\n","#randomly-selected subjects to use as hold-out test data \n","test_subjects = [10, 12, 20, 14, 23, 34,  0]\n","\n","# User-defined parameters\n","lo_freq = 20 #lower bound of bandpass filter\n","hi_freq = 450 #upper bound of bandpass filter\n","\n","win_size = 100 #define window size over which to compute time-domain features\n","step = win_size #keeping this parameter in case we want to re-run later with some overlap\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oDh_RNK2SztA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634770517965,"user_tz":240,"elapsed":41969,"user":{"displayName":"Cesar Echavarria","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12535184235153277849"}},"outputId":"99ffb168-13a1-4481-dbc7-1590406029a5"},"source":["#intialize empty lists\n","feature_matrix_all = np.empty((0,0))\n","target_labels_all = np.empty((0,))\n","window_tstamps_all = np.empty((0,))\n","block_labels_all  = np.empty((0,))\n","series_labels_all  = np.empty((0,))\n","subject_id_all = np.empty((0,))\n","block_count = 0\n","\n","for subject_id in range(1,nsubjects+1):\n","    if subject_id not in test_subjects:\n","        subject_folder = os.path.join(data_folder,'%02d'%(subject_id))\n","        print('=======================')\n","        print(subject_folder)\n","\n","        # Process data and get features \n","        #get features across segments and corresponding info\n","        feature_matrix, target_labels, window_tstamps, \\\n","        block_labels, series_labels = get_subject_data_for_classification(subject_folder, lo_freq, hi_freq, \\\n","                                                                        win_size, step)\n","\n","        #prevent repeat of block labels by increasing block count\n","        block_labels = block_labels+block_count\n","        block_count = np.max([block_count, np.max(block_labels)])\n","\n","\n","        # concatenate lists\n","        feature_matrix_all = np.vstack((feature_matrix_all,feature_matrix)) if feature_matrix_all.size else feature_matrix\n","        target_labels_all = np.hstack((target_labels_all,target_labels))\n","        window_tstamps_all = np.hstack((window_tstamps_all,window_tstamps))\n","        block_labels_all = np.hstack((block_labels_all,block_labels))\n","        series_labels_all = np.hstack((series_labels_all,series_labels))\n","        subject_id_all = np.hstack((subject_id_all,np.ones((block_labels.size))*subject_id))\n","        "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["=======================\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/01\n","=======================\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/02\n","=======================\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/03\n","=======================\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/04\n","=======================\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/05\n","=======================\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/06\n","=======================\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/07\n","=======================\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/08\n","=======================\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/09\n","=======================\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/11\n","=======================\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/13\n","=======================\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/15\n","=======================\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/16\n","=======================\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/17\n","=======================\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/18\n","=======================\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/19\n","=======================\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/21\n","=======================\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/22\n","=======================\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/24\n","=======================\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/25\n","=======================\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/26\n","=======================\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/27\n","=======================\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/28\n","=======================\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/29\n","=======================\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/30\n","=======================\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/31\n","=======================\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/32\n","=======================\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/33\n","=======================\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/35\n","=======================\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/36\n"]}]},{"cell_type":"code","metadata":{"id":"I9Z1JDqrcRl5","executionInfo":{"status":"ok","timestamp":1636217389490,"user_tz":240,"elapsed":454,"user":{"displayName":"Cesar Echavarria","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12535184235153277849"}}},"source":["\n","#define hyper params for each model\n","model_dict = {0:{'tm_layers':0,'tm_activation':'','fe_layers':1, 'fe_activation':'tanh'},\\\n","              1:{'tm_layers':1,'tm_activation':'linear','fe_layers':1, 'fe_activation':'tanh'},\\\n","              2:{'tm_layers':1,'tm_activation':'tanh','fe_layers':1, 'fe_activation':'tanh'},\\\n","              3:{'tm_layers':1,'tm_activation':'relu','fe_layers':1, 'fe_activation':'tanh'},\\\n","              4:{'tm_layers':2,'tm_activation':'linear','fe_layers':1, 'fe_activation':'tanh'},\\\n","              5:{'tm_layers':2,'tm_activation':'tanh','fe_layers':1, 'fe_activation':'tanh'},\\\n","              6:{'tm_layers':2,'tm_activation':'relu','fe_layers':1, 'fe_activation':'tanh'},\\\n","              }\n","\n"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"HMvU4lEH6agN"},"source":["results_folder = '/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/results_data/xsubject_transform_module/simple_NN/'\n","\n","#network training args \n","verbose = 0\n","epochs = 200\n","batch_size = 2\n","es_patience = 5\n","\n","#validation scheme args\n","n_train_splits = 4\n","n_val_splits = 2\n","nreps = 10\n","\n","#excluded labels\n","exclude = [0,7]\n","#performance metrics\n","score_list = ['f1','accuracy']\n","\n","\n","\n","for model_id in range(4,6+1):\n","\n","    results_model_df = []\n","\n","    for rep in range(nreps):\n","        np.random.seed(rep)#to replicate results\n","\n","        print('Model %i || Rep %02d'%(model_id, rep+1))\n","        print('----True Data----')\n","        rep_results_df = nn_xsubject_transform_module_train_frac_subjects(feature_matrix_all, target_labels_all, subject_id_all, block_labels_all,\\\n","                                                        series_labels_all, model_dict[model_id], exclude, score_list,\\\n","                                                        n_train_splits = n_train_splits,n_val_splits = n_val_splits,\\\n","                                                        verbose = verbose, epochs = epochs, batch_size = batch_size,\\\n","                                                        es_patience = es_patience, permute = False)\n","        #add details and concatenate dataframe\n","        rep_results_df['Shuffled'] = False\n","        rep_results_df['Rep'] =  rep+1\n","        rep_results_df['Model'] = model_id\n","        results_model_df.append(rep_results_df)\n","\n","        print('Model %i || Rep %02d'%(model_id, rep+1))\n","        print('----Permuted Data----')\n","        rep_results_df = nn_xsubject_transform_module_train_frac_subjects(feature_matrix_all, target_labels_all, subject_id_all, block_labels_all,\\\n","                                                        series_labels_all, model_dict[model_id], exclude, score_list,\\\n","                                                        n_train_splits = n_train_splits,n_val_splits = n_val_splits,\\\n","                                                        verbose = verbose, epochs = epochs, batch_size = batch_size,\\\n","                                                        es_patience = es_patience, permute = True)\n","        # add details and concatenate dataframe\n","        rep_results_df['Shuffled'] = True\n","        rep_results_df['Rep'] =  rep+1\n","        rep_results_df['Model'] = model_id\n","        results_model_df.append(rep_results_df)\n","\n","    results_model_df = pd.concat(results_model_df,axis = 0)\n","    #save results to file\n","    results_fn = 'model_%02d_results.h5'%(model_id)\n","    results_model_df.to_hdf(os.path.join(results_folder,results_fn), key='results_df', mode='w')\n","print('***Finished!**')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QoHuE7AVTmLZ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":260},"id":"lqFf-UXHrrut","executionInfo":{"status":"ok","timestamp":1634579497722,"user_tz":240,"elapsed":20,"user":{"displayName":"Cesar Echavarria","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12535184235153277849"}},"outputId":"b824bdaa-3788-4cf9-b5a7-1091ca113938"},"source":["\n","results_model_df.groupby(['Shuffled','Type']).mean()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th>Subject</th>\n","      <th>Fold</th>\n","      <th>Epochs</th>\n","      <th>Batch_Size</th>\n","      <th>Train_Loss</th>\n","      <th>Val_Loss</th>\n","      <th>Epochs_Trained</th>\n","      <th>f1_score</th>\n","      <th>accuracy_score</th>\n","      <th>Rep</th>\n","      <th>Model</th>\n","    </tr>\n","    <tr>\n","      <th>Shuffled</th>\n","      <th>Type</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">False</th>\n","      <th>Train</th>\n","      <td>6.0</td>\n","      <td>2.555556</td>\n","      <td>200.0</td>\n","      <td>2.0</td>\n","      <td>0.176355</td>\n","      <td>0.210548</td>\n","      <td>34.296296</td>\n","      <td>0.959739</td>\n","      <td>0.959872</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>Val_Test</th>\n","      <td>6.0</td>\n","      <td>2.333333</td>\n","      <td>200.0</td>\n","      <td>2.0</td>\n","      <td>1.996984</td>\n","      <td>1.965846</td>\n","      <td>6.000000</td>\n","      <td>0.566185</td>\n","      <td>0.594131</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>Val_Train</th>\n","      <td>6.0</td>\n","      <td>2.333333</td>\n","      <td>200.0</td>\n","      <td>2.0</td>\n","      <td>1.996984</td>\n","      <td>1.965846</td>\n","      <td>6.000000</td>\n","      <td>0.566185</td>\n","      <td>0.594131</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">True</th>\n","      <th>Train</th>\n","      <td>6.0</td>\n","      <td>2.555556</td>\n","      <td>200.0</td>\n","      <td>2.0</td>\n","      <td>1.390585</td>\n","      <td>2.240562</td>\n","      <td>7.518519</td>\n","      <td>0.350335</td>\n","      <td>0.396410</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>Val_Test</th>\n","      <td>6.0</td>\n","      <td>2.333333</td>\n","      <td>200.0</td>\n","      <td>2.0</td>\n","      <td>2.203371</td>\n","      <td>2.539136</td>\n","      <td>6.000000</td>\n","      <td>0.171627</td>\n","      <td>0.199007</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>Val_Train</th>\n","      <td>6.0</td>\n","      <td>2.333333</td>\n","      <td>200.0</td>\n","      <td>2.0</td>\n","      <td>2.203371</td>\n","      <td>2.539136</td>\n","      <td>6.000000</td>\n","      <td>0.171627</td>\n","      <td>0.199007</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                    Subject      Fold  Epochs  ...  accuracy_score  Rep  Model\n","Shuffled Type                                  ...                            \n","False    Train          6.0  2.555556   200.0  ...        0.959872  1.0    0.0\n","         Val_Test       6.0  2.333333   200.0  ...        0.594131  1.0    0.0\n","         Val_Train      6.0  2.333333   200.0  ...        0.594131  1.0    0.0\n","True     Train          6.0  2.555556   200.0  ...        0.396410  1.0    0.0\n","         Val_Test       6.0  2.333333   200.0  ...        0.199007  1.0    0.0\n","         Val_Train      6.0  2.333333   200.0  ...        0.199007  1.0    0.0\n","\n","[6 rows x 11 columns]"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"7vmldkLE6e72"},"source":["results_folder = '/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/results_data/xsubject_transform_module/simple_NN/'\n","model_dir = '/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/model_data/xsubject_transform_module/simple_NN/'\n","figure_dir = '/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/figures/training_history/xsubject_transform_module/simple_NN/'\n","\n","#network training args \n","verbose = 0\n","epochs = 200\n","batch_size = 2\n","es_patience = 5\n","\n","nreps = 10\n","\n","#use first series to train (let it be input)\n","# train_idxs = np.where(series_labels_all==0)[0]\n","# test_idxs = np.where(series_labels_all==1)[0]\n","\n","train_idxs = np.where(series_labels_all>=0)[0]\n","test_idxs = np.array([])\n","exclude = [0,7]\n","\n","score_list = ['f1','accuracy']#performance metrics\n","\n","model_id = 1\n","results_model_df = []\n","np.random.seed(1)\n","for rep in range(nreps):\n","\n","    print('Model %i || Rep %02d'%(model_id, rep+1))\n","    print('----True Data----')\n","    figure_folder = os.path.join(figure_dir,'rep_%i'%(rep+1))\n","    if not os.path.isdir(figure_folder):\n","        os.makedirs(figure_folder)\n","    model_folder = os.path.join(model_dir,'rep_%i'%(rep+1))\n","    if not os.path.isdir(model_folder):\n","        os.makedirs(model_folder)\n","\n","    results_df, scaler = nn_xsubject_transform_module_train_all_subjects(feature_matrix_all, target_labels_all, subject_id_all, block_labels_all,\\\n","                                                            train_idxs, test_idxs,  model_dict[model_id], exclude, score_list,\\\n","                                                            figure_folder = figure_folder, model_folder = model_folder,\\\n","                                                            verbose = verbose, epochs = epochs, batch_size = batch_size,\\\n","                                                            es_patience = es_patience, permute = False)\n","    #fill in details and append to list\n","    results_df['Shuffled'] = False\n","    results_df['Rep'] = rep+1\n","    results_model_df.append(results_df)\n","\n","    print('Model %i || Rep %02d'%(model_id, rep+1))\n","    print('----Permuted Data----')\n","    results_df, scaler = nn_xsubject_transform_module_train_all_subjects(feature_matrix_all, target_labels_all, subject_id_all, block_labels_all,\\\n","                                                            train_idxs, test_idxs, model_dict[model_id], exclude, score_list,\\\n","                                                            figure_folder = None, model_folder = None,\\\n","                                                            verbose = verbose, epochs = epochs, batch_size = batch_size,\\\n","                                                            es_patience = es_patience,permute = True)\n","    #fill in details and append to list\n","    results_df['Shuffled'] = True\n","    results_df['Rep'] = rep+1\n","    results_model_df.append(results_df)\n","results_model_df = pd.concat(results_model_df,axis = 0)\n","\n","#save results to file\n","results_fn = 'train_model_transform_module_all_training_data_results.h5'\n","results_model_df.to_hdf(os.path.join(results_folder,results_fn), key='results_df', mode='w')\n","\n","#save scaler\n","scaler_fn = 'trained_scaler_all_training_data.pkl'\n","with open(os.path.join(model_dir,scaler_fn), \"wb\") as output_file:\n","    pickle.dump(scaler, output_file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iG2Dy1kHXzO0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636217170740,"user_tz":240,"elapsed":9331,"user":{"displayName":"Cesar Echavarria","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12535184235153277849"}},"outputId":"028d27cd-6e1a-45ef-effc-52b2644d8bbc"},"source":["# LOAD TEST SUBJECT DATA\n","#define where the data files are located\n","data_folder = '/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/'\n","\n","#randomly-selected subjects to use as hold-out test data \n","test_subjects = [10, 12, 20, 14, 23, 34]\n","\n","# User-defined parameters\n","lo_freq = 20 #lower bound of bandpass filter\n","hi_freq = 450 #upper bound of bandpass filter\n","\n","win_size = 100 #define window size over which to compute time-domain features\n","step = win_size #keeping this parameter in case we want to re-run later with some overlap\n","\n","#intialize empty lists\n","feature_matrix_all = np.empty((0,0))\n","target_labels_all = np.empty((0,))\n","window_tstamps_all = np.empty((0,))\n","block_labels_all  = np.empty((0,))\n","series_labels_all  = np.empty((0,))\n","subject_id_all = np.empty((0,))\n","block_count = 0\n","\n","for subject_id in test_subjects:\n","    subject_folder = os.path.join(data_folder,'%02d'%(subject_id))\n","    print('=======================')\n","    print(subject_folder)\n","\n","    # Process data and get features \n","    #get features across segments and corresponding info\n","    feature_matrix, target_labels, window_tstamps, \\\n","    block_labels, series_labels = get_subject_data_for_classification(subject_folder, lo_freq, hi_freq, \\\n","                                                                    win_size, step)\n","\n","    #prevent repeat of block labels by increasing block count\n","    block_labels = block_labels+block_count\n","    block_count = np.max([block_count, np.max(block_labels)])\n","\n","    # concatenate lists\n","    feature_matrix_all = np.vstack((feature_matrix_all,feature_matrix)) if feature_matrix_all.size else feature_matrix\n","    target_labels_all = np.hstack((target_labels_all,target_labels))\n","    window_tstamps_all = np.hstack((window_tstamps_all,window_tstamps))\n","    block_labels_all = np.hstack((block_labels_all,block_labels))\n","    series_labels_all = np.hstack((series_labels_all,series_labels))\n","    subject_id_all = np.hstack((subject_id_all,np.ones((block_labels.size))*subject_id))"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["=======================\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/10\n","=======================\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/12\n","=======================\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/20\n","=======================\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/14\n","=======================\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/23\n","=======================\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/34\n"]}]},{"cell_type":"code","metadata":{"id":"h1H_ZqvuXzux","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636223617315,"user_tz":240,"elapsed":985763,"user":{"displayName":"Cesar Echavarria","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12535184235153277849"}},"outputId":"a03342ec-5508-454d-bdbe-b200a5e49ed1"},"source":["# EVALUATE TEST SUBJECTS\n","\n","model_dir = '/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/model_data/xsubject_transform_module/simple_NN/'\n","results_folder = '/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/results_data/xsubject_transform_module/simple_NN/'\n","#network training and evaluation args \n","verbose = 0\n","epochs = 200\n","batch_size = 2\n","es_patience = 5\n","n_splits = 2\n","# architecture hyper-parameters of model. useful to build untrained model with randomized weights\n","model_dict = {'tm_layers':1,'tm_activation':'linear',\\\n","              'fe_layers':1, 'fe_activation':'tanh'}\n","\n","#excluded labels\n","exclude = [0,7]\n","#performance metrics\n","score_list = ['f1','accuracy']\n","nreps = 10\n","\n","# load data scaler \n","scaler_fn = 'trained_scaler_all_training_data.pkl'#\n","with open(os.path.join(model_dir,scaler_fn), \"rb\") as output_file:\n","    scaler = pickle.load( output_file)\n","results_df = []\n","np.random.seed(1) #set seed for replicability\n","for rep in range(nreps):\n","    \n","    print('Rep %02d'%(rep+1))\n","    \n","    model_folder = os.path.join(model_dir,'rep_%i'%(rep+1))\n","    #load trained model\n","    model_fn = os.path.join(model_folder, 'trained_model_all_train_data_permuted_%s.h5'%(str(False)))\n","    trained_model = keras.models.load_model(model_fn)\n","    \n","    # evaluate with true data\n","    print('----True Data----')\n","    \n","    rep_results_df = nn_xsubject_transform_module_test_subject_eval(feature_matrix_all, target_labels_all, subject_id_all, block_labels_all,\\\n","                                                        series_labels_all, trained_model, scaler, model_dict, exclude, score_list,\\\n","                                                        n_splits = n_splits, verbose = verbose, epochs = epochs, batch_size = batch_size,\\\n","                                                        es_patience = es_patience)\n","    #fill in details and append to list\n","    rep_results_df['Shuffled'] = False\n","    rep_results_df['Rep'] = rep+1\n","    results_df.append(rep_results_df)\n","    # evaluate with permuted data\n","    print('----Permuted Data----')\n","    #load model trained with permuted data\n","    rep_results_df = nn_xsubject_transform_module_test_subject_eval(feature_matrix_all, target_labels_all, subject_id_all, block_labels_all,\\\n","                                                        series_labels_all, trained_model, scaler, model_dict, exclude, score_list,\\\n","                                                        n_splits = n_splits, verbose = verbose, epochs = epochs, batch_size = batch_size,\\\n","                                                        es_patience = es_patience, permute = True)\n","    #fill in details and append to list\n","    rep_results_df['Shuffled'] = True\n","    rep_results_df['Rep'] = rep+1\n","    results_df.append(rep_results_df)\n","\n","results_df = pd.concat(results_df,axis = 0).reset_index().drop(columns = ['index'])\n","#save results to file\n","results_fn = 'train_model_transform_module_all_testing_data_results.h5'\n","results_df.to_hdf(os.path.join(results_folder,results_fn), key='results_df', mode='w')  "],"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Rep 01\n","----True Data----\n","Test: Subject 01 out of 06\n","Test: Subject 02 out of 06\n","Test: Subject 03 out of 06\n","Test: Subject 04 out of 06\n","Test: Subject 05 out of 06\n","Test: Subject 06 out of 06\n","----Permuted Data----\n","Test: Subject 01 out of 06\n","Test: Subject 02 out of 06\n","Test: Subject 03 out of 06\n","Test: Subject 04 out of 06\n","Test: Subject 05 out of 06\n","Test: Subject 06 out of 06\n","Rep 02\n","----True Data----\n","Test: Subject 01 out of 06\n","Test: Subject 02 out of 06\n","Test: Subject 03 out of 06\n","Test: Subject 04 out of 06\n","Test: Subject 05 out of 06\n","Test: Subject 06 out of 06\n","----Permuted Data----\n","Test: Subject 01 out of 06\n","Test: Subject 02 out of 06\n","Test: Subject 03 out of 06\n","Test: Subject 04 out of 06\n","Test: Subject 05 out of 06\n","Test: Subject 06 out of 06\n","Rep 03\n","----True Data----\n","Test: Subject 01 out of 06\n","Test: Subject 02 out of 06\n","Test: Subject 03 out of 06\n","Test: Subject 04 out of 06\n","Test: Subject 05 out of 06\n","Test: Subject 06 out of 06\n","----Permuted Data----\n","Test: Subject 01 out of 06\n","Test: Subject 02 out of 06\n","Test: Subject 03 out of 06\n","Test: Subject 04 out of 06\n","Test: Subject 05 out of 06\n","Test: Subject 06 out of 06\n","Rep 04\n","----True Data----\n","Test: Subject 01 out of 06\n","Test: Subject 02 out of 06\n","Test: Subject 03 out of 06\n","Test: Subject 04 out of 06\n","Test: Subject 05 out of 06\n","Test: Subject 06 out of 06\n","----Permuted Data----\n","Test: Subject 01 out of 06\n","Test: Subject 02 out of 06\n","Test: Subject 03 out of 06\n","Test: Subject 04 out of 06\n","Test: Subject 05 out of 06\n","Test: Subject 06 out of 06\n","Rep 05\n","----True Data----\n","Test: Subject 01 out of 06\n","Test: Subject 02 out of 06\n","Test: Subject 03 out of 06\n","Test: Subject 04 out of 06\n","Test: Subject 05 out of 06\n","Test: Subject 06 out of 06\n","----Permuted Data----\n","Test: Subject 01 out of 06\n","Test: Subject 02 out of 06\n","Test: Subject 03 out of 06\n","Test: Subject 04 out of 06\n","Test: Subject 05 out of 06\n","Test: Subject 06 out of 06\n","Rep 06\n","----True Data----\n","Test: Subject 01 out of 06\n","Test: Subject 02 out of 06\n","Test: Subject 03 out of 06\n","Test: Subject 04 out of 06\n","Test: Subject 05 out of 06\n","Test: Subject 06 out of 06\n","----Permuted Data----\n","Test: Subject 01 out of 06\n","Test: Subject 02 out of 06\n","Test: Subject 03 out of 06\n","Test: Subject 04 out of 06\n","Test: Subject 05 out of 06\n","Test: Subject 06 out of 06\n","Rep 07\n","----True Data----\n","Test: Subject 01 out of 06\n","Test: Subject 02 out of 06\n","Test: Subject 03 out of 06\n","Test: Subject 04 out of 06\n","Test: Subject 05 out of 06\n","Test: Subject 06 out of 06\n","----Permuted Data----\n","Test: Subject 01 out of 06\n","Test: Subject 02 out of 06\n","Test: Subject 03 out of 06\n","Test: Subject 04 out of 06\n","Test: Subject 05 out of 06\n","Test: Subject 06 out of 06\n","Rep 08\n","----True Data----\n","Test: Subject 01 out of 06\n","Test: Subject 02 out of 06\n","Test: Subject 03 out of 06\n","Test: Subject 04 out of 06\n","Test: Subject 05 out of 06\n","Test: Subject 06 out of 06\n","----Permuted Data----\n","Test: Subject 01 out of 06\n","Test: Subject 02 out of 06\n","Test: Subject 03 out of 06\n","Test: Subject 04 out of 06\n","Test: Subject 05 out of 06\n","Test: Subject 06 out of 06\n","Rep 09\n","----True Data----\n","Test: Subject 01 out of 06\n","Test: Subject 02 out of 06\n","Test: Subject 03 out of 06\n","Test: Subject 04 out of 06\n","Test: Subject 05 out of 06\n","Test: Subject 06 out of 06\n","----Permuted Data----\n","Test: Subject 01 out of 06\n","Test: Subject 02 out of 06\n","Test: Subject 03 out of 06\n","Test: Subject 04 out of 06\n","Test: Subject 05 out of 06\n","Test: Subject 06 out of 06\n","Rep 10\n","----True Data----\n","Test: Subject 01 out of 06\n","Test: Subject 02 out of 06\n","Test: Subject 03 out of 06\n","Test: Subject 04 out of 06\n","Test: Subject 05 out of 06\n","Test: Subject 06 out of 06\n","----Permuted Data----\n","Test: Subject 01 out of 06\n","Test: Subject 02 out of 06\n","Test: Subject 03 out of 06\n","Test: Subject 04 out of 06\n","Test: Subject 05 out of 06\n","Test: Subject 06 out of 06\n"]}]},{"cell_type":"code","metadata":{"id":"_Tg2b3SqwZDt","colab":{"base_uri":"https://localhost:8080/","height":200},"executionInfo":{"status":"ok","timestamp":1636223661396,"user_tz":240,"elapsed":224,"user":{"displayName":"Cesar Echavarria","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12535184235153277849"}},"outputId":"2b2d4baf-7770-4941-c419-262b1e680dba"},"source":["results_df.groupby(['Shuffled','Type']).mean()"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th>Subject</th>\n","      <th>Fold</th>\n","      <th>Epochs</th>\n","      <th>Batch_Size</th>\n","      <th>Train_Loss</th>\n","      <th>Val_Loss</th>\n","      <th>Epochs_Trained</th>\n","      <th>f1_score</th>\n","      <th>accuracy_score</th>\n","      <th>Rep</th>\n","    </tr>\n","    <tr>\n","      <th>Shuffled</th>\n","      <th>Type</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">False</th>\n","      <th>Test</th>\n","      <td>18.833333</td>\n","      <td>1.5</td>\n","      <td>200.0</td>\n","      <td>2.0</td>\n","      <td>0.374142</td>\n","      <td>0.370099</td>\n","      <td>37.791667</td>\n","      <td>0.895771</td>\n","      <td>0.902171</td>\n","      <td>5.5</td>\n","    </tr>\n","    <tr>\n","      <th>Train</th>\n","      <td>18.833333</td>\n","      <td>1.5</td>\n","      <td>200.0</td>\n","      <td>2.0</td>\n","      <td>0.374142</td>\n","      <td>0.370099</td>\n","      <td>37.791667</td>\n","      <td>0.948425</td>\n","      <td>0.949725</td>\n","      <td>5.5</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">True</th>\n","      <th>Test</th>\n","      <td>18.833333</td>\n","      <td>1.5</td>\n","      <td>200.0</td>\n","      <td>2.0</td>\n","      <td>2.580333</td>\n","      <td>4.617162</td>\n","      <td>10.141667</td>\n","      <td>0.112291</td>\n","      <td>0.124739</td>\n","      <td>5.5</td>\n","    </tr>\n","    <tr>\n","      <th>Train</th>\n","      <td>18.833333</td>\n","      <td>1.5</td>\n","      <td>200.0</td>\n","      <td>2.0</td>\n","      <td>2.580333</td>\n","      <td>4.617162</td>\n","      <td>10.141667</td>\n","      <td>0.400852</td>\n","      <td>0.434168</td>\n","      <td>5.5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                  Subject  Fold  Epochs  ...  f1_score  accuracy_score  Rep\n","Shuffled Type                            ...                               \n","False    Test   18.833333   1.5   200.0  ...  0.895771        0.902171  5.5\n","         Train  18.833333   1.5   200.0  ...  0.948425        0.949725  5.5\n","True     Test   18.833333   1.5   200.0  ...  0.112291        0.124739  5.5\n","         Train  18.833333   1.5   200.0  ...  0.400852        0.434168  5.5\n","\n","[4 rows x 10 columns]"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"a3c52JVd1bJi"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FxheoGqe-_Uv"},"source":[""],"execution_count":null,"outputs":[]}]}