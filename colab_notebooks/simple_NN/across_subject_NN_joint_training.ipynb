{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"across_subject_NN_joint_training.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyOyauBn/MO9bCrSJqCX8COr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TyYD4oUuvm6h","executionInfo":{"status":"ok","timestamp":1636143293912,"user_tz":240,"elapsed":44693,"user":{"displayName":"Cesar Echavarria","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12535184235153277849"}},"outputId":"b1197524-5a52-4fc7-9e98-e660ed4ee30e"},"source":["#Run cell to mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"70TJl7fWKDaf","executionInfo":{"status":"ok","timestamp":1636143350067,"user_tz":240,"elapsed":24322,"user":{"displayName":"Cesar Echavarria","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12535184235153277849"}},"outputId":"eb875508-214c-4b92-b384-df8a2dd31fc7"},"source":["# install package to have access to custom functions\n","%pip install /content/drive/Othercomputers/'My MacBook Pro'/EMG_gestures/ --use-feature=in-tree-build"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing ./drive/Othercomputers/My MacBook Pro/EMG_gestures\n","Building wheels for collected packages: EMG-gestures\n","  Building wheel for EMG-gestures (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for EMG-gestures: filename=EMG_gestures-0.1.0-py3-none-any.whl size=30708 sha256=8e9601cdb56dbde26afaf1db88f6496589195e9465fa8f69067557c1247119b7\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-0oztsa0m/wheels/74/96/87/ceb916fceabb875209ae993e697bf574966ab592f4167a4958\n","Successfully built EMG-gestures\n","Installing collected packages: EMG-gestures\n","Successfully installed EMG-gestures-0.1.0\n"]}]},{"cell_type":"code","metadata":{"id":"RVmD2y3kvVQm","executionInfo":{"status":"ok","timestamp":1636143351266,"user_tz":240,"elapsed":607,"user":{"displayName":"Cesar Echavarria","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12535184235153277849"}}},"source":["#import necessary packages\n","\n","#our workhorses\n","import numpy as np\n","import pandas as pd\n","import scipy\n","\n","#to visualize\n","%matplotlib inline\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","#style params for figures\n","sns.set(font_scale = 2)\n","plt.style.use('seaborn-white')\n","plt.rc(\"axes\", labelweight=\"bold\")\n","from IPython.display import display, HTML\n","\n","#to load files\n","import os\n","import sys\n","import h5py\n","import pickle\n","from tensorflow import keras\n","\n","#append repo folder to search path\n","#import cusotm functions\n","from EMG_gestures.utils import *\n","from EMG_gestures.analysis import nn_xsubject_joint_data_train_frac_subjects,\\\n"," nn_xsubject_joint_data_train_all_subjects, evaluate_trained_nn\n","\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"gPa9nUbCMtQN"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AwDLfmBW2c8L"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BsqbYs0H6Tol"},"source":["#define hyper params for each model\n","model_dict = {0:{'fe_layers':0, 'fe_activation':''},\\\n","              1:{'fe_layers':1, 'fe_activation':'tanh'},\\\n","              2:{'fe_layers':1, 'fe_activation':'relu'},\\\n","              3:{'fe_layers':2, 'fe_activation':'tanh'},\\\n","              4:{'fe_layers':2, 'fe_activation':'relu'},\\\n","              }\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jWRLrkQFJA8m"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IouUsT8S59b0"},"source":["#define where the data files are located\n","data_folder = '/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/'\n","\n","nsubjects = 36\n","\n","#randomly-selected subjects to use as hold-out test data \n","test_subjects = [10, 12, 20, 14, 23, 34]\n","\n","# User-defined parameters\n","lo_freq = 20 #lower bound of bandpass filter\n","hi_freq = 450 #upper bound of bandpass filter\n","\n","win_size = 100 #define window size over which to compute time-domain features\n","step = win_size #keeping this parameter in case we want to re-run later with some overlap\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oDh_RNK2SztA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632345268198,"user_tz":240,"elapsed":12841,"user":{"displayName":"Cesar Echavarria","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12535184235153277849"}},"outputId":"d591e963-3d4a-46cd-c907-697a626e6755"},"source":["#intialize empty lists\n","feature_matrix_all = np.empty((0,0))\n","target_labels_all = np.empty((0,))\n","window_tstamps_all = np.empty((0,))\n","block_labels_all  = np.empty((0,))\n","subject_id_all = np.empty((0,))\n","block_count = 0\n","\n","for subject_id in range(1,nsubjects+1):\n","    if subject_id not in test_subjects:\n","        subject_folder = os.path.join(data_folder,'%02d'%(subject_id))\n","        print('=======================')\n","        print(subject_folder)\n","\n","        # Process data and get features \n","        #get features across segments and corresponding info\n","        feature_matrix, target_labels, window_tstamps, \\\n","        block_labels, series_labels = get_subject_data_for_classification(subject_folder, lo_freq, hi_freq, \\\n","                                                                        win_size, step)\n","\n","        #prevent repeat of block labels by increasing block count\n","        block_labels = block_labels+block_count\n","        block_count = np.max([block_count, np.max(block_labels)])\n","\n","        # concatenate lists\n","        feature_matrix_all = np.vstack((feature_matrix_all,feature_matrix)) if feature_matrix_all.size else feature_matrix\n","        target_labels_all = np.hstack((target_labels_all,target_labels))\n","        window_tstamps_all = np.hstack((window_tstamps_all,window_tstamps))\n","        block_labels_all = np.hstack((block_labels_all,block_labels))\n","        subject_id_all = np.hstack((subject_id_all,np.ones((block_labels.size))*subject_id))\n","        "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/01\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/02\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/03\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/04\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/05\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/06\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/07\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/08\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/09\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/11\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/13\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/15\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/16\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/17\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/18\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/19\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/21\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/22\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/24\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/25\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/26\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/27\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/28\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/29\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/30\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/31\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/32\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/33\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/35\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/36\n"]}]},{"cell_type":"code","metadata":{"id":"O6ylCMCgtoJe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632350878980,"user_tz":240,"elapsed":5606421,"user":{"displayName":"Cesar Echavarria","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12535184235153277849"}},"outputId":"07e957f1-1966-4878-a013-dfbc59124ca9"},"source":["results_folder = '/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/results_data/\\/xsubject_joint_data/simple_NN/'\n","\n","\n","#NN training args\n","verbose = 0\n","epochs = 1000\n","batch_size = 2\n","es_patience = 5\n","\n","# experiment params\n","n_splits = 4\n","nreps = 10\n","\n","#excluded labels\n","exclude = [0,7]\n","#performance metrics\n","score_list = ['f1','accuracy']\n","\n","model_id = 1\n","#for model_id in range(1,5+1):\n","np.random.seed(1)# Set seed for replicability\n","results_df = []\n","for rep in range(nreps):\n","    print('Model %d | Rep %d'%(model_id, rep+1))\n","    print('--True Data--')\n","\n","    rep_results_df = nn_xsubject_joint_data_train_frac_subjects(feature_matrix_all, target_labels_all, subject_id_all,\\\n","                                                                                    block_labels_all, model_dict[model_id], exclude,\\\n","                                                                                    score_list = score_list,\\\n","                                                                                    n_splits = n_splits,\\\n","                                                                                    verbose = 0, epochs = epochs, batch_size = batch_size,\\\n","                                                                                    es_patience = es_patience, mv = None, permute = False)\n","    #add details and concatenate dataframe\n","    rep_results_df['Shuffled'] = False\n","    rep_results_df['Rep'] =  rep+1\n","    results_df.append(rep_results_df)\n","\n","\n","\n","\n","    #repeat with shuffled data\n","    print('Model %d | Rep %d'%(model_id, rep+1))\n","    print('--Permuted Data--')\n","    rep_results_df  = nn_xsubject_joint_data_train_frac_subjects(feature_matrix_all, target_labels_all, subject_id_all,\\\n","                                                                                    block_labels_all, model_dict[model_id], exclude,\\\n","                                                                                    score_list = score_list,\\\n","                                                                                    n_splits = n_splits,\\\n","                                                                                    verbose = 0, epochs = epochs, batch_size = batch_size,\\\n","                                                                                    es_patience = es_patience, mv = None,permute = True)\n","    #add details and concatenate dataframe\n","    rep_results_df['Shuffled'] = True\n","    rep_results_df['Rep'] =  rep+1\n","    results_df.append(rep_results_df)\n","\n","#concatenate all data frames\n","results_df = pd.concat(results_df,axis = 0)\n","\n","# #save results to file\n","results_fn = 'model_%02d_results.h5'%(model_id)\n","results_df.to_hdf(os.path.join(results_folder,results_fn), key='results_df', mode='w')\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model 1 | Rep 1\n","--True Data--\n","Split Count: 1\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 3\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 4\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Model 1 | Rep 1\n","--Permuted Data--\n","Split Count: 1\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 3\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 4\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Model 1 | Rep 2\n","--True Data--\n","Split Count: 1\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 3\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 4\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Model 1 | Rep 2\n","--Permuted Data--\n","Split Count: 1\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 3\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 4\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Model 1 | Rep 3\n","--True Data--\n","Split Count: 1\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 3\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 4\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Model 1 | Rep 3\n","--Permuted Data--\n","Split Count: 1\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 3\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 4\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Model 1 | Rep 4\n","--True Data--\n","Split Count: 1\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 3\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 4\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Model 1 | Rep 4\n","--Permuted Data--\n","Split Count: 1\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 3\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 4\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Model 1 | Rep 5\n","--True Data--\n","Split Count: 1\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 3\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 4\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Model 1 | Rep 5\n","--Permuted Data--\n","Split Count: 1\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 3\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 4\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Model 1 | Rep 6\n","--True Data--\n","Split Count: 1\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 3\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 4\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Model 1 | Rep 6\n","--Permuted Data--\n","Split Count: 1\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 3\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 4\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Model 1 | Rep 7\n","--True Data--\n","Split Count: 1\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 3\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 4\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Model 1 | Rep 7\n","--Permuted Data--\n","Split Count: 1\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 3\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 4\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Model 1 | Rep 8\n","--True Data--\n","Split Count: 1\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 3\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 4\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Model 1 | Rep 8\n","--Permuted Data--\n","Split Count: 1\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 3\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 4\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Model 1 | Rep 9\n","--True Data--\n","Split Count: 1\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 3\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 4\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Model 1 | Rep 9\n","--Permuted Data--\n","Split Count: 1\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 3\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 4\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Model 1 | Rep 10\n","--True Data--\n","Split Count: 1\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 3\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 4\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Model 1 | Rep 10\n","--Permuted Data--\n","Split Count: 1\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 3\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 4\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n"]}]},{"cell_type":"code","metadata":{"id":"ESnzSvc4ydR-","colab":{"base_uri":"https://localhost:8080/","height":200},"executionInfo":{"status":"ok","timestamp":1632350879477,"user_tz":240,"elapsed":21,"user":{"displayName":"Cesar Echavarria","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12535184235153277849"}},"outputId":"5e47c083-1783-4acc-e019-4f0f2b86f11c"},"source":["\n","results_df.groupby(['Shuffled','Type']).mean()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th>Fold</th>\n","      <th>Epochs</th>\n","      <th>Batch_Size</th>\n","      <th>Train_Loss</th>\n","      <th>Val_Loss</th>\n","      <th>Epochs_Trained</th>\n","      <th>f1_score</th>\n","      <th>accuracy_score</th>\n","      <th>Rep</th>\n","    </tr>\n","    <tr>\n","      <th>Shuffled</th>\n","      <th>Type</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">False</th>\n","      <th>Test</th>\n","      <td>2.5</td>\n","      <td>1000.0</td>\n","      <td>2.0</td>\n","      <td>0.618248</td>\n","      <td>0.573725</td>\n","      <td>15.325</td>\n","      <td>0.769174</td>\n","      <td>0.770680</td>\n","      <td>5.5</td>\n","    </tr>\n","    <tr>\n","      <th>Train</th>\n","      <td>2.5</td>\n","      <td>1000.0</td>\n","      <td>2.0</td>\n","      <td>0.618248</td>\n","      <td>0.573725</td>\n","      <td>15.325</td>\n","      <td>0.821787</td>\n","      <td>0.822416</td>\n","      <td>5.5</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">True</th>\n","      <th>Test</th>\n","      <td>2.5</td>\n","      <td>1000.0</td>\n","      <td>2.0</td>\n","      <td>1.767145</td>\n","      <td>1.822614</td>\n","      <td>8.625</td>\n","      <td>0.146998</td>\n","      <td>0.160677</td>\n","      <td>5.5</td>\n","    </tr>\n","    <tr>\n","      <th>Train</th>\n","      <td>2.5</td>\n","      <td>1000.0</td>\n","      <td>2.0</td>\n","      <td>1.767145</td>\n","      <td>1.822614</td>\n","      <td>8.625</td>\n","      <td>0.205138</td>\n","      <td>0.218875</td>\n","      <td>5.5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                Fold  Epochs  Batch_Size  ...  f1_score  accuracy_score  Rep\n","Shuffled Type                             ...                               \n","False    Test    2.5  1000.0         2.0  ...  0.769174        0.770680  5.5\n","         Train   2.5  1000.0         2.0  ...  0.821787        0.822416  5.5\n","True     Test    2.5  1000.0         2.0  ...  0.146998        0.160677  5.5\n","         Train   2.5  1000.0         2.0  ...  0.205138        0.218875  5.5\n","\n","[4 rows x 9 columns]"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aJK8ovOaxK5S","executionInfo":{"status":"ok","timestamp":1632352275455,"user_tz":240,"elapsed":1395991,"user":{"displayName":"Cesar Echavarria","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12535184235153277849"}},"outputId":"461ff48b-5cb6-4cc2-abda-8d8f5e1333b0"},"source":["results_folder = '/content/drive/MyDrive/EMG_gestures/results_data/xsubject_joint_data/simple_NN/'\n","model_dir = '/content/drive/MyDrive/EMG_gestures/model_data/xsubject_joint_data/simple_NN/'\n","\n","#network training args \n","verbose = 0\n","epochs = 1000\n","batch_size = 2\n","es_patience = 5\n","validation_split = 0.25\n","nreps = 10\n","\n","exclude = [0,7]\n","\n","score_list = ['f1','accuracy']#performance metrics\n","\n","model_id = 1\n","results_df = []\n","np.random.seed(1)\n","for rep in range(nreps):\n","    model_folder = os.path.join(model_dir,'rep_%02d'%(rep+1))\n","    if not os.path.exists(model_folder):\n","        os.makedirs(model_folder)\n","\n","    \n","    print('Model %i || Rep %02d'%(model_id, rep+1))\n","    print('----True Data----')\n","    rep_results_df,trained_model, scaler = nn_xsubject_joint_data_train_all_subjects(feature_matrix_all, target_labels_all,\\\n","                                                                                     subject_id_all,\\\n","                                                                                     block_labels_all, model_dict[model_id],exclude,\\\n","                                                                                     score_list = score_list,\\\n","                                                                                     verbose = verbose, epochs = epochs, batch_size = batch_size,\\\n","                                                                                     es_patience = es_patience, validation_split = validation_split,\\\n","                                                                                     mv = None, permute = False)\n","    #add details and concatenate dataframe\n","    rep_results_df['Shuffled'] = False\n","    rep_results_df['Rep'] =  rep+1\n","    results_df.append(rep_results_df)\n","\n","\n","    #save trained model\n","    model_fn = os.path.join(model_folder, 'trained_model_rep_%i_all_train_data.h5'%(rep))\n","    keras.models.save_model(trained_model, model_fn, save_format= 'h5')\n","\n","    print('Model %i || Rep %02d'%(model_id, rep+1))\n","    print('----Permuted Data----')\n","    rep_results_df, b, c = nn_xsubject_joint_data_train_all_subjects(feature_matrix_all, target_labels_all,\\\n","                                                                                     subject_id_all,\\\n","                                                                                     block_labels_all, model_dict[model_id],exclude,\\\n","                                                                                     score_list = score_list,\\\n","                                                                                     verbose = verbose, epochs = epochs, batch_size = batch_size,\\\n","                                                                                     es_patience = es_patience, validation_split = validation_split,\\\n","                                                                                     mv = None, permute = True)\n","    #add details and concatenate dataframe\n","    rep_results_df['Shuffled'] = True\n","    rep_results_df['Rep'] =  rep+1\n","    results_df.append(rep_results_df)\n","\n","results_df = pd.concat(results_df, axis = 0).reset_index()\n","\n","results_fn = 'nn_joint_training_results.h5'\n","results_df.to_hdf(os.path.join(results_folder,results_fn), key='results_df', mode='w')\n","\n","#save scaler (outisde of rep loop b/c it will always be the same)\n","scaler_fn = 'trained_scaler_all_training_data.pkl'#\n","with open(os.path.join(model_dir,scaler_fn), \"wb\") as output_file:\n","    pickle.dump(scaler, output_file)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model 1 || Rep 01\n","----True Data----\n","Training Model\n","Evaluate Model on Trained Data\n","Model 1 || Rep 01\n","----Permuted Data----\n","Training Model\n","Evaluate Model on Trained Data\n","Model 1 || Rep 02\n","----True Data----\n","Training Model\n","Evaluate Model on Trained Data\n","Model 1 || Rep 02\n","----Permuted Data----\n","Training Model\n","Evaluate Model on Trained Data\n","Model 1 || Rep 03\n","----True Data----\n","Training Model\n","Evaluate Model on Trained Data\n","Model 1 || Rep 03\n","----Permuted Data----\n","Training Model\n","Evaluate Model on Trained Data\n","Model 1 || Rep 04\n","----True Data----\n","Training Model\n","Evaluate Model on Trained Data\n","Model 1 || Rep 04\n","----Permuted Data----\n","Training Model\n","Evaluate Model on Trained Data\n","Model 1 || Rep 05\n","----True Data----\n","Training Model\n","Evaluate Model on Trained Data\n","Model 1 || Rep 05\n","----Permuted Data----\n","Training Model\n","Evaluate Model on Trained Data\n","Model 1 || Rep 06\n","----True Data----\n","Training Model\n","Evaluate Model on Trained Data\n","Model 1 || Rep 06\n","----Permuted Data----\n","Training Model\n","Evaluate Model on Trained Data\n","Model 1 || Rep 07\n","----True Data----\n","Training Model\n","Evaluate Model on Trained Data\n","Model 1 || Rep 07\n","----Permuted Data----\n","Training Model\n","Evaluate Model on Trained Data\n","Model 1 || Rep 08\n","----True Data----\n","Training Model\n","Evaluate Model on Trained Data\n","Model 1 || Rep 08\n","----Permuted Data----\n","Training Model\n","Evaluate Model on Trained Data\n","Model 1 || Rep 09\n","----True Data----\n","Training Model\n","Evaluate Model on Trained Data\n","Model 1 || Rep 09\n","----Permuted Data----\n","Training Model\n","Evaluate Model on Trained Data\n","Model 1 || Rep 10\n","----True Data----\n","Training Model\n","Evaluate Model on Trained Data\n","Model 1 || Rep 10\n","----Permuted Data----\n","Training Model\n","Evaluate Model on Trained Data\n"]}]},{"cell_type":"code","metadata":{"id":"tltKSYg2LD3c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636145012833,"user_tz":240,"elapsed":33209,"user":{"displayName":"Cesar Echavarria","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12535184235153277849"}},"outputId":"fd1eebdf-4193-4232-a2d9-07bf03c3fe96"},"source":["#define where the data files are located\n","data_folder = '/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/'\n","results_folder = '/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/results_data/xsubject_joint_data/simple_NN/'\n","model_dir = '/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/model_data/xsubject_joint_data/simple_NN/'\n","\n","\n","#randomly-selected subjects to use as hold-out test data \n","test_subjects = [10, 12, 20, 14, 23, 34]\n","\n","# User-defined parameters\n","lo_freq = 20 #lower bound of bandpass filter\n","hi_freq = 450 #upper bound of bandpass filter\n","\n","win_size = 100 #define window size over which to compute time-domain features\n","step = win_size #keeping this parameter in case we want to re-run later with some overlap\n","\n","\n","# excluded labels\n","exclude = [0,7]\n","# performance metrics\n","score_list = ['f1','accuracy']\n","\n","nreps = 10\n","# load data scaler \n","scaler_fn = 'trained_scaler_all_training_data.pkl'#\n","with open(os.path.join(model_dir,scaler_fn), \"rb\") as output_file:\n","    scaler = pickle.load( output_file)\n","#empty list for dataframes\n","results_df = []\n","for rep in range(nreps):\n","    print('========== Rep %02d ============='%(rep))\n","    model_folder = os.path.join(model_dir,'rep_%02d'%(rep+1))\n","    # load trained model\n","    model_fn = os.path.join(model_folder, 'trained_model_rep_%i_all_train_data.h5'%(rep))\n","    trained_model = keras.models.load_model(model_fn)\n","    # empty list\n","    test_scores = np.empty((len(test_subjects),len(score_list)))\n","    test_scores_perm = np.empty((len(test_subjects),len(score_list)))\n","    for idx, subject_id in enumerate(test_subjects):\n","        subject_folder = os.path.join(data_folder,'%02d'%(subject_id))\n","        print(subject_folder)\n","        # Process data and get features \n","        #get features across segments and corresponding info\n","        feature_matrix, target_labels, window_tstamps, \\\n","                block_labels, series_labels = get_subject_data_for_classification(subject_folder, lo_freq, hi_freq,\n","                                                                                  win_size, step)\n","        # Evaluate trained model on subjects' data\n","        test_idxs = np.arange(feature_matrix.shape[0])\n","        test_scores[idx,:] = evaluate_trained_nn(feature_matrix, target_labels, test_idxs, exclude, trained_model,\\\n","                                                 score_list,scaler)\n","\n","        \n","        #permute while ignoring excluded blocks\n","        target_labels = permute_class_within_sub(target_labels, block_labels, np.ones(target_labels.shape[0]), exclude)\n","        test_scores_perm[idx,:] = evaluate_trained_nn(feature_matrix, target_labels, test_idxs, exclude, trained_model,\\\n","                                                 score_list,scaler)\n","    # append true data results to dataframe\n","    data_dict = {'Test_Subject':test_subjects,\\\n","                 'Shuffled':[False for x in range(len(test_subjects))],\\\n","                'Rep':[rep for x in range(len(test_subjects))]}\n","    for sidx in range(len(score_list)):\n","        data_dict['%s_score'%(score_list[sidx])] = test_scores[:,sidx]\n","    results_df.append(pd.DataFrame(data_dict))\n","    # append shuffled data results to dataframe\n","    data_dict = {'Test_Subject':test_subjects,\\\n","                 'Shuffled':[True for x in range(len(test_subjects))],\\\n","                'Rep':[rep for x in range(len(test_subjects))]}\n","    for sidx in range(len(score_list)):\n","        data_dict['%s_score'%(score_list[sidx])] = test_scores_perm[:,sidx]\n","    results_df.append(pd.DataFrame(data_dict))\n","# concatenate dataframes\n","results_df = pd.concat(results_df, axis = 0).reset_index().drop(columns = ['index'])\n","# save to file\n","results_fn = 'nn_joint_testing_results.h5'\n","results_df.to_hdf(os.path.join(results_folder,results_fn), key='results_df', mode='w')"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["========== Rep 00 =============\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/10\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/12\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/20\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/14\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/23\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/34\n","Evaluate Model\n","Evaluate Model\n","========== Rep 01 =============\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/10\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/12\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/20\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/14\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/23\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/34\n","Evaluate Model\n","Evaluate Model\n","========== Rep 02 =============\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/10\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/12\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/20\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/14\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/23\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/34\n","Evaluate Model\n","Evaluate Model\n","========== Rep 03 =============\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/10\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/12\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/20\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/14\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/23\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/34\n","Evaluate Model\n","Evaluate Model\n","========== Rep 04 =============\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/10\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/12\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/20\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/14\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/23\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/34\n","Evaluate Model\n","Evaluate Model\n","========== Rep 05 =============\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/10\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/12\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/20\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/14\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/23\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/34\n","Evaluate Model\n","Evaluate Model\n","========== Rep 06 =============\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/10\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/12\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/20\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/14\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/23\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/34\n","Evaluate Model\n","Evaluate Model\n","========== Rep 07 =============\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/10\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/12\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/20\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/14\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/23\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/34\n","Evaluate Model\n","Evaluate Model\n","========== Rep 08 =============\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/10\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/12\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/20\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/14\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/23\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/34\n","Evaluate Model\n","Evaluate Model\n","========== Rep 09 =============\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/10\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/12\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/20\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/14\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/23\n","Evaluate Model\n","Evaluate Model\n","/content/drive/Othercomputers/My MacBook Pro/EMG_gestures/EMG_data/34\n","Evaluate Model\n","Evaluate Model\n"]}]},{"cell_type":"code","metadata":{"id":"Z8wxpMPetY8L","colab":{"base_uri":"https://localhost:8080/","height":441},"executionInfo":{"status":"ok","timestamp":1636145061750,"user_tz":240,"elapsed":162,"user":{"displayName":"Cesar Echavarria","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12535184235153277849"}},"outputId":"467d0aee-f702-4463-bbfc-e37ef26fd99b"},"source":["results_df.groupby(['Shuffled','Test_Subject']).mean()"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th>Rep</th>\n","      <th>f1_score</th>\n","      <th>accuracy_score</th>\n","    </tr>\n","    <tr>\n","      <th>Shuffled</th>\n","      <th>Test_Subject</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"6\" valign=\"top\">False</th>\n","      <th>10</th>\n","      <td>4.5</td>\n","      <td>0.792622</td>\n","      <td>0.837410</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>4.5</td>\n","      <td>0.873210</td>\n","      <td>0.876674</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>4.5</td>\n","      <td>0.704791</td>\n","      <td>0.735476</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>4.5</td>\n","      <td>0.906695</td>\n","      <td>0.909339</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>4.5</td>\n","      <td>0.855682</td>\n","      <td>0.860586</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>4.5</td>\n","      <td>0.925804</td>\n","      <td>0.926144</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"6\" valign=\"top\">True</th>\n","      <th>10</th>\n","      <td>4.5</td>\n","      <td>0.167128</td>\n","      <td>0.174580</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>4.5</td>\n","      <td>0.144125</td>\n","      <td>0.150115</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>4.5</td>\n","      <td>0.183371</td>\n","      <td>0.208740</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>4.5</td>\n","      <td>0.175920</td>\n","      <td>0.180182</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>4.5</td>\n","      <td>0.207338</td>\n","      <td>0.205631</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>4.5</td>\n","      <td>0.162543</td>\n","      <td>0.162963</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                       Rep  f1_score  accuracy_score\n","Shuffled Test_Subject                               \n","False    10            4.5  0.792622        0.837410\n","         12            4.5  0.873210        0.876674\n","         14            4.5  0.704791        0.735476\n","         20            4.5  0.906695        0.909339\n","         23            4.5  0.855682        0.860586\n","         34            4.5  0.925804        0.926144\n","True     10            4.5  0.167128        0.174580\n","         12            4.5  0.144125        0.150115\n","         14            4.5  0.183371        0.208740\n","         20            4.5  0.175920        0.180182\n","         23            4.5  0.207338        0.205631\n","         34            4.5  0.162543        0.162963"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"-HNuVLM10EtW"},"source":[""],"execution_count":null,"outputs":[]}]}