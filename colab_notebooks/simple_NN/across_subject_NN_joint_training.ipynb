{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"across_subject_NN_joint_training.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyMt35nVwpCpQG7zMijFKgRg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TyYD4oUuvm6h","executionInfo":{"status":"ok","timestamp":1632345102150,"user_tz":240,"elapsed":188,"user":{"displayName":"Cesar Echavarria","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12535184235153277849"}},"outputId":"68c0946b-0753-489b-da05-0ccce528f800"},"source":["#Run cell to mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"70TJl7fWKDaf","executionInfo":{"status":"ok","timestamp":1632345119487,"user_tz":240,"elapsed":11278,"user":{"displayName":"Cesar Echavarria","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12535184235153277849"}},"outputId":"2d4e7b0a-f33c-452a-b7a3-fed7793b9d0b"},"source":["# install package to have access to custom functions\n","%pip install /content/drive/MyDrive/EMG_gestures/ --use-feature=in-tree-build"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing ./drive/MyDrive/EMG_gestures\n","Building wheels for collected packages: EMG-gestures\n","  Building wheel for EMG-gestures (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for EMG-gestures: filename=EMG_gestures-0.1.0-py3-none-any.whl size=45273 sha256=7fceb92eea8c1ba0f524946c4f06717535b3d73987a9ea83881f975a13a73894\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-qm2daevy/wheels/a2/b7/61/2147fa082a9e51bef5dcc38dd3f0898fe0554d62203c0e383e\n","Successfully built EMG-gestures\n","Installing collected packages: EMG-gestures\n","  Attempting uninstall: EMG-gestures\n","    Found existing installation: EMG-gestures 0.1.0\n","    Uninstalling EMG-gestures-0.1.0:\n","      Successfully uninstalled EMG-gestures-0.1.0\n","Successfully installed EMG-gestures-0.1.0\n"]}]},{"cell_type":"code","metadata":{"id":"RVmD2y3kvVQm","executionInfo":{"status":"ok","timestamp":1632345209166,"user_tz":240,"elapsed":198,"user":{"displayName":"Cesar Echavarria","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12535184235153277849"}}},"source":["#import necessary packages\n","\n","#our workhorses\n","import numpy as np\n","import pandas as pd\n","import scipy\n","\n","#to visualize\n","%matplotlib inline\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","#style params for figures\n","sns.set(font_scale = 2)\n","plt.style.use('seaborn-white')\n","plt.rc(\"axes\", labelweight=\"bold\")\n","from IPython.display import display, HTML\n","\n","#to load files\n","import os\n","import sys\n","import h5py\n","import pickle\n","from tensorflow import keras\n","\n","#append repo folder to search path\n","#import cusotm functions\n","from EMG_gestures.utils import *\n","from EMG_gestures.analysis import nn_xsubject_joint_data_train_frac_subjects,\\\n"," nn_xsubject_joint_data_train_all_subjects\n","\n"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"gPa9nUbCMtQN"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AwDLfmBW2c8L"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BsqbYs0H6Tol","executionInfo":{"status":"ok","timestamp":1632345247084,"user_tz":240,"elapsed":145,"user":{"displayName":"Cesar Echavarria","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12535184235153277849"}}},"source":["#define hyper params for each model\n","model_dict = {0:{'fe_layers':0, 'fe_activation':''},\\\n","              1:{'fe_layers':1, 'fe_activation':'tanh'},\\\n","              2:{'fe_layers':1, 'fe_activation':'relu'},\\\n","              3:{'fe_layers':2, 'fe_activation':'tanh'},\\\n","              4:{'fe_layers':2, 'fe_activation':'relu'},\\\n","              }\n"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"jWRLrkQFJA8m"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IouUsT8S59b0","executionInfo":{"status":"ok","timestamp":1632345250895,"user_tz":240,"elapsed":165,"user":{"displayName":"Cesar Echavarria","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12535184235153277849"}}},"source":["#define where the data files are located\n","data_folder = '/content/drive/MyDrive/EMG_gestures/EMG_data/'\n","\n","nsubjects = 36\n","\n","#randomly-selected subjects to use as hold-out test data \n","test_subjects = [10, 12, 20, 14, 23, 34,  0]\n","\n","# User-defined parameters\n","lo_freq = 20 #lower bound of bandpass filter\n","hi_freq = 450 #upper bound of bandpass filter\n","\n","win_size = 100 #define window size over which to compute time-domain features\n","step = win_size #keeping this parameter in case we want to re-run later with some overlap\n"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"oDh_RNK2SztA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632345268198,"user_tz":240,"elapsed":12841,"user":{"displayName":"Cesar Echavarria","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12535184235153277849"}},"outputId":"d591e963-3d4a-46cd-c907-697a626e6755"},"source":["#intialize empty lists\n","feature_matrix_all = np.empty((0,0))\n","target_labels_all = np.empty((0,))\n","window_tstamps_all = np.empty((0,))\n","block_labels_all  = np.empty((0,))\n","subject_id_all = np.empty((0,))\n","block_count = 0\n","\n","for subject_id in range(1,nsubjects+1):\n","    if subject_id not in test_subjects:\n","        subject_folder = os.path.join(data_folder,'%02d'%(subject_id))\n","        print('=======================')\n","        print(subject_folder)\n","\n","        # Process data and get features \n","        #get features across segments and corresponding info\n","        feature_matrix, target_labels, window_tstamps, \\\n","        block_labels, series_labels = get_subject_data_for_classification(subject_folder, lo_freq, hi_freq, \\\n","                                                                        win_size, step)\n","\n","        #prevent repeat of block labels by increasing block count\n","        block_labels = block_labels+block_count\n","        block_count = np.max([block_count, np.max(block_labels)])\n","\n","        # concatenate lists\n","        feature_matrix_all = np.vstack((feature_matrix_all,feature_matrix)) if feature_matrix_all.size else feature_matrix\n","        target_labels_all = np.hstack((target_labels_all,target_labels))\n","        window_tstamps_all = np.hstack((window_tstamps_all,window_tstamps))\n","        block_labels_all = np.hstack((block_labels_all,block_labels))\n","        subject_id_all = np.hstack((subject_id_all,np.ones((block_labels.size))*subject_id))\n","        "],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/01\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/02\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/03\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/04\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/05\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/06\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/07\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/08\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/09\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/11\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/13\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/15\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/16\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/17\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/18\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/19\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/21\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/22\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/24\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/25\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/26\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/27\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/28\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/29\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/30\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/31\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/32\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/33\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/35\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/36\n"]}]},{"cell_type":"code","metadata":{"id":"O6ylCMCgtoJe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632350878980,"user_tz":240,"elapsed":5606421,"user":{"displayName":"Cesar Echavarria","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12535184235153277849"}},"outputId":"07e957f1-1966-4878-a013-dfbc59124ca9"},"source":["results_folder = '/content/drive/MyDrive/EMG_gestures/results_data/xsubject_joint_data/vanilla_NN/'\n","\n","\n","#NN training args\n","verbose = 0\n","epochs = 1000\n","batch_size = 2\n","es_patience = 5\n","\n","# experiment params\n","n_splits = 4\n","nreps = 10\n","\n","#excluded labels\n","exclude = [0,7]\n","#performance metrics\n","score_list = ['f1','accuracy']\n","\n","model_id = 1\n","#for model_id in range(1,5+1):\n","np.random.seed(1)# Set seed for replicability\n","results_df = []\n","for rep in range(nreps):\n","    print('Model %d | Rep %d'%(model_id, rep+1))\n","    print('--True Data--')\n","\n","    rep_results_df = nn_xsubject_joint_data_train_frac_subjects(feature_matrix_all, target_labels_all, subject_id_all,\\\n","                                                                                    block_labels_all, model_dict[model_id], exclude,\\\n","                                                                                    score_list = score_list,\\\n","                                                                                    n_splits = n_splits,\\\n","                                                                                    verbose = 0, epochs = epochs, batch_size = batch_size,\\\n","                                                                                    es_patience = es_patience, mv = None, permute = False)\n","    #add details and concatenate dataframe\n","    rep_results_df['Shuffled'] = False\n","    rep_results_df['Rep'] =  rep+1\n","    results_df.append(rep_results_df)\n","\n","\n","\n","\n","    #repeat with shuffled data\n","    print('Model %d | Rep %d'%(model_id, rep+1))\n","    print('--Permuted Data--')\n","    rep_results_df  = nn_xsubject_joint_data_train_frac_subjects(feature_matrix_all, target_labels_all, subject_id_all,\\\n","                                                                                    block_labels_all, model_dict[model_id], exclude,\\\n","                                                                                    score_list = score_list,\\\n","                                                                                    n_splits = n_splits,\\\n","                                                                                    verbose = 0, epochs = epochs, batch_size = batch_size,\\\n","                                                                                    es_patience = es_patience, mv = None,permute = True)\n","    #add details and concatenate dataframe\n","    rep_results_df['Shuffled'] = True\n","    rep_results_df['Rep'] =  rep+1\n","    results_df.append(rep_results_df)\n","\n","#concatenate all data frames\n","results_df = pd.concat(results_df,axis = 0)\n","\n","# #save results to file\n","results_fn = 'model_%02d_results.h5'%(model_id)\n","results_df.to_hdf(os.path.join(results_folder,results_fn), key='results_df', mode='w')\n"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Model 1 | Rep 1\n","--True Data--\n","Split Count: 1\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 3\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 4\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Model 1 | Rep 1\n","--Permuted Data--\n","Split Count: 1\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 3\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 4\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Model 1 | Rep 2\n","--True Data--\n","Split Count: 1\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 3\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 4\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Model 1 | Rep 2\n","--Permuted Data--\n","Split Count: 1\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 3\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 4\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Model 1 | Rep 3\n","--True Data--\n","Split Count: 1\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 3\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 4\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Model 1 | Rep 3\n","--Permuted Data--\n","Split Count: 1\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 3\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 4\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Model 1 | Rep 4\n","--True Data--\n","Split Count: 1\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 3\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 4\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Model 1 | Rep 4\n","--Permuted Data--\n","Split Count: 1\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 3\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 4\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Model 1 | Rep 5\n","--True Data--\n","Split Count: 1\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 3\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 4\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Model 1 | Rep 5\n","--Permuted Data--\n","Split Count: 1\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 3\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 4\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Model 1 | Rep 6\n","--True Data--\n","Split Count: 1\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 3\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 4\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Model 1 | Rep 6\n","--Permuted Data--\n","Split Count: 1\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 3\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 4\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Model 1 | Rep 7\n","--True Data--\n","Split Count: 1\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 3\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 4\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Model 1 | Rep 7\n","--Permuted Data--\n","Split Count: 1\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 3\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 4\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Model 1 | Rep 8\n","--True Data--\n","Split Count: 1\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 3\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 4\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Model 1 | Rep 8\n","--Permuted Data--\n","Split Count: 1\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 3\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 4\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Model 1 | Rep 9\n","--True Data--\n","Split Count: 1\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 3\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 4\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Model 1 | Rep 9\n","--Permuted Data--\n","Split Count: 1\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 3\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 4\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Model 1 | Rep 10\n","--True Data--\n","Split Count: 1\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 3\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 4\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Model 1 | Rep 10\n","--Permuted Data--\n","Split Count: 1\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 3\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n","Split Count: 4\n","Training Model\n","Evaluate Model on Trained Data\n","Evaluate Model\n"]}]},{"cell_type":"code","metadata":{"id":"ESnzSvc4ydR-","colab":{"base_uri":"https://localhost:8080/","height":200},"executionInfo":{"status":"ok","timestamp":1632350879477,"user_tz":240,"elapsed":21,"user":{"displayName":"Cesar Echavarria","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12535184235153277849"}},"outputId":"5e47c083-1783-4acc-e019-4f0f2b86f11c"},"source":["\n","results_df.groupby(['Shuffled','Type']).mean()"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th>Fold</th>\n","      <th>Epochs</th>\n","      <th>Batch_Size</th>\n","      <th>Train_Loss</th>\n","      <th>Val_Loss</th>\n","      <th>Epochs_Trained</th>\n","      <th>f1_score</th>\n","      <th>accuracy_score</th>\n","      <th>Rep</th>\n","    </tr>\n","    <tr>\n","      <th>Shuffled</th>\n","      <th>Type</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">False</th>\n","      <th>Test</th>\n","      <td>2.5</td>\n","      <td>1000.0</td>\n","      <td>2.0</td>\n","      <td>0.618248</td>\n","      <td>0.573725</td>\n","      <td>15.325</td>\n","      <td>0.769174</td>\n","      <td>0.770680</td>\n","      <td>5.5</td>\n","    </tr>\n","    <tr>\n","      <th>Train</th>\n","      <td>2.5</td>\n","      <td>1000.0</td>\n","      <td>2.0</td>\n","      <td>0.618248</td>\n","      <td>0.573725</td>\n","      <td>15.325</td>\n","      <td>0.821787</td>\n","      <td>0.822416</td>\n","      <td>5.5</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">True</th>\n","      <th>Test</th>\n","      <td>2.5</td>\n","      <td>1000.0</td>\n","      <td>2.0</td>\n","      <td>1.767145</td>\n","      <td>1.822614</td>\n","      <td>8.625</td>\n","      <td>0.146998</td>\n","      <td>0.160677</td>\n","      <td>5.5</td>\n","    </tr>\n","    <tr>\n","      <th>Train</th>\n","      <td>2.5</td>\n","      <td>1000.0</td>\n","      <td>2.0</td>\n","      <td>1.767145</td>\n","      <td>1.822614</td>\n","      <td>8.625</td>\n","      <td>0.205138</td>\n","      <td>0.218875</td>\n","      <td>5.5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                Fold  Epochs  Batch_Size  ...  f1_score  accuracy_score  Rep\n","Shuffled Type                             ...                               \n","False    Test    2.5  1000.0         2.0  ...  0.769174        0.770680  5.5\n","         Train   2.5  1000.0         2.0  ...  0.821787        0.822416  5.5\n","True     Test    2.5  1000.0         2.0  ...  0.146998        0.160677  5.5\n","         Train   2.5  1000.0         2.0  ...  0.205138        0.218875  5.5\n","\n","[4 rows x 9 columns]"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aJK8ovOaxK5S","executionInfo":{"status":"ok","timestamp":1632352275455,"user_tz":240,"elapsed":1395991,"user":{"displayName":"Cesar Echavarria","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12535184235153277849"}},"outputId":"461ff48b-5cb6-4cc2-abda-8d8f5e1333b0"},"source":["results_folder = '/content/drive/MyDrive/EMG_gestures/results_data/xsubject_joint_data/vanilla_NN/'\n","model_dir = '/content/drive/MyDrive/EMG_gestures/model_data/xsubject_joint_data/vanilla_NN/'\n","\n","#network training args \n","verbose = 0\n","epochs = 1000\n","batch_size = 2\n","es_patience = 5\n","validation_split = 0.25\n","nreps = 10\n","\n","exclude = [0,7]\n","\n","score_list = ['f1','accuracy']#performance metrics\n","\n","model_id = 1\n","results_df = []\n","np.random.seed(1)\n","for rep in range(nreps):\n","    model_folder = os.path.join(model_dir,'rep_%02d'%(rep+1))\n","    if not os.path.exists(model_folder):\n","        os.makedirs(model_folder)\n","\n","    \n","    print('Model %i || Rep %02d'%(model_id, rep+1))\n","    print('----True Data----')\n","    rep_results_df,trained_model, scaler = nn_xsubject_joint_data_train_all_subjects(feature_matrix_all, target_labels_all,\\\n","                                                                                     subject_id_all,\\\n","                                                                                     block_labels_all, model_dict[model_id],exclude,\\\n","                                                                                     score_list = score_list,\\\n","                                                                                     verbose = verbose, epochs = epochs, batch_size = batch_size,\\\n","                                                                                     es_patience = es_patience, validation_split = validation_split,\\\n","                                                                                     mv = None, permute = False)\n","    #add details and concatenate dataframe\n","    rep_results_df['Shuffled'] = False\n","    rep_results_df['Rep'] =  rep+1\n","    results_df.append(rep_results_df)\n","\n","\n","    #save trained model\n","    model_fn = os.path.join(model_folder, 'trained_model_rep_%i_all_train_data.h5'%(rep))\n","    keras.models.save_model(trained_model, model_fn, save_format= 'h5')\n","\n","    print('Model %i || Rep %02d'%(model_id, rep+1))\n","    print('----Permuted Data----')\n","    rep_results_df, b, c = nn_xsubject_joint_data_train_all_subjects(feature_matrix_all, target_labels_all,\\\n","                                                                                     subject_id_all,\\\n","                                                                                     block_labels_all, model_dict[model_id],exclude,\\\n","                                                                                     score_list = score_list,\\\n","                                                                                     verbose = verbose, epochs = epochs, batch_size = batch_size,\\\n","                                                                                     es_patience = es_patience, validation_split = validation_split,\\\n","                                                                                     mv = None, permute = True)\n","    #add details and concatenate dataframe\n","    rep_results_df['Shuffled'] = True\n","    rep_results_df['Rep'] =  rep+1\n","    results_df.append(rep_results_df)\n","\n","results_df = pd.concat(results_df, axis = 0).reset_index()\n","\n","results_fn = 'nn_joint_training_results.h5'\n","results_df.to_hdf(os.path.join(results_folder,results_fn), key='results_df', mode='w')\n","\n","#save scaler (outisde of rep loop b/c it will always be the same)\n","scaler_fn = 'trained_scaler_all_training_data.pkl'#\n","with open(os.path.join(model_dir,scaler_fn), \"wb\") as output_file:\n","    pickle.dump(scaler, output_file)"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Model 1 || Rep 01\n","----True Data----\n","Training Model\n","Evaluate Model on Trained Data\n","Model 1 || Rep 01\n","----Permuted Data----\n","Training Model\n","Evaluate Model on Trained Data\n","Model 1 || Rep 02\n","----True Data----\n","Training Model\n","Evaluate Model on Trained Data\n","Model 1 || Rep 02\n","----Permuted Data----\n","Training Model\n","Evaluate Model on Trained Data\n","Model 1 || Rep 03\n","----True Data----\n","Training Model\n","Evaluate Model on Trained Data\n","Model 1 || Rep 03\n","----Permuted Data----\n","Training Model\n","Evaluate Model on Trained Data\n","Model 1 || Rep 04\n","----True Data----\n","Training Model\n","Evaluate Model on Trained Data\n","Model 1 || Rep 04\n","----Permuted Data----\n","Training Model\n","Evaluate Model on Trained Data\n","Model 1 || Rep 05\n","----True Data----\n","Training Model\n","Evaluate Model on Trained Data\n","Model 1 || Rep 05\n","----Permuted Data----\n","Training Model\n","Evaluate Model on Trained Data\n","Model 1 || Rep 06\n","----True Data----\n","Training Model\n","Evaluate Model on Trained Data\n","Model 1 || Rep 06\n","----Permuted Data----\n","Training Model\n","Evaluate Model on Trained Data\n","Model 1 || Rep 07\n","----True Data----\n","Training Model\n","Evaluate Model on Trained Data\n","Model 1 || Rep 07\n","----Permuted Data----\n","Training Model\n","Evaluate Model on Trained Data\n","Model 1 || Rep 08\n","----True Data----\n","Training Model\n","Evaluate Model on Trained Data\n","Model 1 || Rep 08\n","----Permuted Data----\n","Training Model\n","Evaluate Model on Trained Data\n","Model 1 || Rep 09\n","----True Data----\n","Training Model\n","Evaluate Model on Trained Data\n","Model 1 || Rep 09\n","----Permuted Data----\n","Training Model\n","Evaluate Model on Trained Data\n","Model 1 || Rep 10\n","----True Data----\n","Training Model\n","Evaluate Model on Trained Data\n","Model 1 || Rep 10\n","----Permuted Data----\n","Training Model\n","Evaluate Model on Trained Data\n"]}]},{"cell_type":"code","metadata":{"id":"tltKSYg2LD3c","executionInfo":{"status":"ok","timestamp":1632344806474,"user_tz":240,"elapsed":172,"user":{"displayName":"Cesar Echavarria","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12535184235153277849"}}},"source":["\n","\n","\n"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z8wxpMPetY8L"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"26-AW_Ulh3C-"},"source":[""],"execution_count":null,"outputs":[]}]}