{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.13"},"colab":{"name":"RNN_notebook_v02.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"f2423c02"},"source":["#import necessary packages\n","%matplotlib inline\n","\n","import numpy as np\n","import pandas as pd\n","import scipy\n","import scipy.signal\n","from collections import defaultdict\n","\n","\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","#style params for figures\n","sns.set(font_scale = 2)\n","plt.style.use('seaborn-white')\n","\n","#to load files\n","import os\n","import h5py\n","\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import StratifiedKFold\n","from itertools import groupby\n","\n","from tensorflow import keras\n","from tensorflow.keras.metrics import Precision, Recall\n","from tensorflow.keras.models import Sequential, Model, load_model, Sequential, save_model\n","from tensorflow. keras.layers import Dense, Activation, Dropout, Input,  TimeDistributed, GRU, Masking, LSTM\n","\n","from tensorflow.keras.utils import to_categorical\n","\n"],"id":"f2423c02","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"da36d8a4"},"source":[""],"id":"da36d8a4","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"efa475c3"},"source":["\n","#!/usr/bin/env python2\n","# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Sat Jun 12 2021\n","@author: cechava\n","\"\"\"\n","from itertools import groupby\n","import numpy as np\n","import pandas as pd\n","import scipy\n","import scipy.signal\n","\n","#to visualize \n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from matplotlib.lines import Line2D\n","#style params for figures\n","sns.set(font_scale = 2)\n","plt.style.use('seaborn-white')\n","plt.rc(\"axes\", labelweight=\"bold\")\n","\n","\n","#to load files\n","import os\n","import h5py\n","\n","#ML packages\n","from sklearn.linear_model import  LogisticRegression\n","from sklearn.metrics import f1_score,make_scorer, log_loss\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import make_pipeline\n","from sklearn.manifold import TSNE\n","\n","\n","from tensorflow import keras\n","from tensorflow.keras.metrics import Precision, Recall\n","from tensorflow.keras.models import Sequential, Model, load_model, Sequential, save_model\n","from tensorflow. keras.layers import Dense, Activation, Dropout, Input,  TimeDistributed, GRU, Masking, LSTM\n","from tensorflow.keras.utils import to_categorical\n","\n","\n","# ~~~~~~~ DATA WRANGLING FUNCTIONS ~~~~~~~\n","def get_gesture_times(data_df):\n","    \"\"\"\n","    Get start times, end times, and event labels of each block of time with a given label\n","    \n","    Args:\n","        data_df: dataframe with columns for 'class' and 'time' \n","            \n","    Returns:\n","        start times, end times, and event labels: 1-d numpy arrays \n","        \n","    \"\"\"\n","\n","    #get start indices of each condition \n","    \n","    #taking advantage that every gesture is preceded by a period with 'undefined' class label (value 0)\n","    start_idxs = np.hstack([0,np.where(np.abs(np.diff(data_df['class']))>0)[0]+1])\n","    \n","    #end indices correspond to just before the start of the next condition\n","    end_idxs = np.hstack((start_idxs[1:]-1,data_df.time.size-1))\n","    \n","\n","    #create arrays with start times and class labels for each hand gesture\n","    start_times = data_df.time[start_idxs].values\n","    end_times = data_df.time[end_idxs].values\n","    event_labels = data_df['class'][start_idxs].values\n","    \n","    return start_times, end_times, event_labels\n","\n","def get_steady_samp_rate_data(data_df):\n","    \n","    \"\"\"\n","    Resample time series data for a steady sampling rate by performing linear interpolation\n","    between missing samples\n","    \n","    Args:\n","        data_df: dataframe with a 'time' column and timeseries of interest on other columns\n","            \n","    Returns:\n","        data_df: dataframe with interpolated \n","    \"\"\"\n","    \n","    #retrieve time value\n","    time = data_df.time.values\n","    #define time points on which we want to interpolate (i.e., a sample every ms)\n","    time_new = np.arange(time[0],time[-1]+1,1)\n","    \n","    #create separate dataframe with new time points and set these as index\n","    steady_time_df = pd.DataFrame({'time_constant':time_new})\n","    steady_time_df = steady_time_df.set_index('time_constant')\n","    \n","    #set time coulumn of original dataframe to index\n","    data_df = data_df.set_index('time')\n","\n","    #perform a right join with the steady time dataframe then linearly interpolate missing values\n","    data_df = data_df.join(steady_time_df, how = 'right')\n","    data_df = data_df.interpolate().reset_index().rename(columns={'time_constant':'time'})\n","    \n","    return data_df\n","\n","def butter_bandpass_filter(input_signal, lowcut, highcut, fs, order=4, axis = -1):\n","    #lowcut = lower bound of desired freq band\n","    #hicut = upperbound bound of desired freq band\n","    #fs = sampling rate\n","    #order = order of filter\n","    #axis = axis of data matrix on which to apply filters\n","\n","    low = float(lowcut)# / nyq\n","    high = float(highcut)# / nyq\n","    b, a = scipy.signal.butter(order, [low, high],fs = fs, btype='band')\n","    \n","    output_signal = scipy.signal.filtfilt(b, a, input_signal,axis = axis)\n","    \n","    return output_signal\n","    \n","def get_window_features(signal):\n","    #signal: EMG signal matrix with dims time x channels\n","    #return: Mean Absolute Value and Wavelength features for each channel\n","\n","    MAV = np.mean(np.absolute(signal),axis = 0) #Mean Absolute Value\n","\n","    WL = np.sum(np.absolute(np.diff(signal,axis = 0)),axis = 0) #Wavelength\n","    \n","    return MAV, WL\n","\n","def window_and_get_features(parsed_df,win_size,step):\n","    \"\"\"\n","    Compute features (Mean Absolute Value and Wavelength) for time series segments with given length \n","    and amount of overlap\n","    \n","    Args:\n","        parsed_df: dataframe containing timeseries data for each block. expects a 'Block' column\n","        and the channel data in the first columns of dataframe\n","        \n","            \n","    Returns:\n","        feat_matrix: 2D numpy array of size [number of segments, number of channels * number of features]\n","        target_labels: 1D numpy array with class label for each segment\n","        window_tstamps: 1D numpy array with timestamp for each timeseries segment used to compute features\n","        block_labels: 1D numpy array indicating block provenance of each segment (useful for RNN data prep)\n","    \"\"\"\n","    #set empty lists\n","    feat_matrix = []\n","    target_labels = []\n","    window_tstamps = []\n","    block_labels = []\n","\n","    #get number of channels\n","    nchannels = np.sum(['Channel' in col_name for col_name in parsed_df.columns])\n","\n","    for block in parsed_df.Block.unique():\n","        #get relevant subset of dataframe\n","        block_df = parsed_df.loc[parsed_df.Block == block]\n","\n","        #extract relevant info\n","        block_data_matrix = block_df.iloc[:,0:8].values\n","        block_class = block_df['Class'][0]\n","        tstamps = block_df['Time'].values\n","\n","        #compute desired features over segments of the data\n","        for win_start_idx in range(0, block_df.shape[0], step):\n","            win_end_idx = win_start_idx + win_size\n","            if win_end_idx< block_df.shape[0]: #exclude window if not enough timepoints before end of block\n","\n","                #compute features within this segment\n","                MAV, WL = get_window_features(block_data_matrix[win_start_idx:win_end_idx,:])\n","\n","                #append info to matrices\n","                feat_matrix.append(np.hstack((MAV,WL)))\n","                target_labels.append(block_class)\n","                window_tstamps.append(np.mean([tstamps[win_start_idx],tstamps[win_end_idx]]))\n","                block_labels.append(block)\n","                \n","    return np.array(feat_matrix), np.array(target_labels), np.array(window_tstamps), np.array(block_labels)\n","\n","\n","\n","\n","\n","def parse_data_blocks(start_times, end_times, event_labels, data_matrix, tstamps, pre_tpts = 0, exclude_class=[]):\n","    \"\"\"\n","    Function to parse timeseries into blocks corresponding to each event. \n","    Returns a dataframe - seemed most convenient given variable length of event blocks\n","    \n","    Args:\n","        start_times: 1D numpy array with start times of event blocks\n","        end_times: 1D numpy array with start times of event blocks\n","        event_labels: 1D numpy array with start times of event blocks\n","        data_matrix: 2D numpy array with of dimension [ntimepoints, nchannels] containing signal values\n","        pre_tpts: how many timepoints before event onset to include(int)\n","        exclude_class: list with class labels to exclude in parsing blocks\n","            \n","    Returns:\n","        parsed_df: dataframe with parsed data\n","        block_length: 1D numpy array with timepoints in each event block\n","    \"\"\"\n","    \n","    parsed_df = []\n","\n","    #note characterisitcs of matrix\n","    ntpts, nchannels = data_matrix.shape\n","\n","    parsed_df = []\n","    block_lengths = []\n","    for block,c in enumerate(event_labels):\n","        if c not in exclude_class:\n","            # get relevant indives to get dara from matrix\n","            start_idx = np.where(tstamps>start_times[block])[0][0]\n","            end_idx = np.where(tstamps>=end_times[block])[0][0]\n","\n","            # append block length to list\n","            block_lengths.append(end_idx-start_idx)\n","\n","            # get timestamps relative to event onset\n","            t_ase = np.arange(-pre_tpts,end_idx-start_idx)\n","\n","            # put data matrix values into a dataframe\n","            block_df = pd.DataFrame(data_matrix[start_idx-pre_tpts:end_idx,:], columns = ['Channel_%i'%(c+1) for c in range(nchannels)])\n","\n","            # add relevant value columns\n","            block_df['Block'] = block\n","            block_df['Class'] = c \n","            block_df['Time_ASE'] = t_ase\n","            block_df['Time'] = np.arange(tstamps[start_idx]-pre_tpts,tstamps[end_idx])\n","\n","            #append to collecting datafram\n","            parsed_df.append(block_df)\n","\n","    #merge all dataframes together\n","    parsed_df = pd.concat(parsed_df,axis = 0)\n","    \n","    return parsed_df, block_lengths\n","\n","def get_file_data_for_classification(data_fn, lo_freq, hi_freq, win_size, step, remove_file_mean = True):\n","    \"\"\"\n","    Get the relevant info for classification from indicated file\n","    \n","    Args:\n","        data_fn: filename\n","        lo_freq: lower bound of bandpass filter\n","        hi_freq: higher bound of bandpass filter\n","        win_size: length of segment over which to compute features\n","        step: amount of overlap between neighboring segments\n","        remove_file_mean: Boolean indicating removal of mean value for each channel in the series\n","            \n","    Returns:\n","        feature_matrix: 2D numpy array of size [number of segments, number of channels * number of features]\n","        target_labels: 1D numpy array with class label for each segment\n","        window_tstamps: 1D numpy array with timestamp for each timeseries segment used to compute features\n","        block_labels: 1D numpy array indicating block provenance of each segment (useful for RNN data prep)\n","    \"\"\"\n","    \n","    # load file\n","    data_df = pd.DataFrame(pd.read_csv(data_fn, sep='\\t'))\n","    \n","    # retrieve start times, end times, and labels for each condition block (will make it easier to parse traces later)\n","    start_times, end_times, event_labels  = get_gesture_times(data_df)\n","\n","    # interpolate data to steady frame rate\n","    data_df = get_steady_samp_rate_data(data_df)\n","    samp_period = np.diff(data_df.time)[0]/1000.0\n","    samp_rate = 1/samp_period\n","    \n","    # Unpack values into numpy arrays\n","    data_matrix = data_df.iloc[:,1:-1].values\n","    class_labels = data_df.iloc[:,-1].values\n","    tstamps = data_df.time.values\n","    \n","    #remove series offset for each channel, if indicated\n","    if remove_file_mean:\n","        data_matrix = data_matrix- np.mean(data_matrix,0)\n","\n","    # filter data\n","    filt_data_matrix = butter_bandpass_filter(data_matrix, lo_freq, hi_freq, samp_rate,axis = 0)\n","\n","    # parse timeseries into block corresponding to different blocks of time\n","    parsed_df, block_lengths = parse_data_blocks(start_times,end_times,event_labels,filt_data_matrix, tstamps,\n","                                                 pre_tpts = 0, exclude_class=[])\n","\n","    # compute desired features over individual time segments\n","    feature_matrix, target_labels, window_tstamps, block_labels = window_and_get_features(parsed_df,win_size,step)\n","    \n","    return feature_matrix, target_labels, window_tstamps, block_labels\n","\n","\n","def get_subject_data_for_classification(data_folder, lo_freq, hi_freq, win_size, step):\n","    \"\"\"\n","    Get the relevant info for classification from indicated file\n","    \n","    Args:\n","        data_fn: filename\n","        lo_freq: lower bound of bandpass filter\n","        hi_freq: higher bound of bandpass filter\n","        win_size: length of segment over which to compute features\n","        step: amount of overlap between neighboring segments\n","            \n","    Returns:\n","        feature_matrix: 2D numpy array of size [number of segments, number of channels * number of features]\n","        target_labels: 1D numpy array with class label for each segment\n","        window_tstamps: 1D numpy array with timestamp for each timeseries segment used to compute features\n","        block_labels: 1D numpy array indicating block provenance of each segment (useful for RNN data prep)\n","        series_labels: 1D numpy array indicating block provenance of each segment (useful for visualization)\n","    \"\"\"\n","    \n","    #find files in subject folder\n","    file_list = [f for f in os.listdir(data_folder) if os.path.isfile(os.path.join(data_folder, f))]\n","\n","\n","    #initialize empty matrices\n","    feature_matrix = np.empty((0,0))\n","    target_labels = np.empty((0,))\n","    window_tstamps = np.empty((0,))\n","    block_labels = np.empty((0,))\n","    series_labels = np.empty((0,))\n","    max_block_id = 0\n","\n","    for series_id,file in enumerate(file_list):\n","\n","        #get relevant info from each file\n","        feature_matrix_sub, target_labels_sub,\\\n","        window_tstamps_sub, block_labels_sub = get_file_data_for_classification(os.path.join(data_folder,file),\\\n","                                                                                 lo_freq, hi_freq, win_size, step)\n","        nsamples,nfeats = feature_matrix_sub.shape\n","\n","        #offset block labels\n","        block_labels_sub = block_labels_sub+max_block_id\n","        max_block_id = np.max(block_labels_sub)#update\n","\n","        series_labels_sub = np.ones((nsamples,))*series_id#make array with series ID of samples\n","\n","        #append file samples\n","        feature_matrix = np.vstack((feature_matrix,feature_matrix_sub)) if feature_matrix.size else feature_matrix_sub\n","        target_labels = np.hstack((target_labels,target_labels_sub))\n","        window_tstamps = np.hstack((window_tstamps,window_tstamps_sub))\n","        block_labels = np.hstack((block_labels,block_labels_sub))\n","        series_labels = np.hstack((series_labels,series_labels_sub))\n","        \n","    return feature_matrix, target_labels, window_tstamps, block_labels, series_labels\n","\n","\n","def get_data_cube(X, window_blocks, train = True, scaler = None, magic_value = -100):\n","    \"\"\"\n","    Create data cube for use with Keras RNN. Standardize data then pad and reshape data to have\n","    [samples, timesteps, features] dimensions with an equal number of timesteps for each slice\n","    I use a Masking layer in the RNN architecture to allow for sequences of different length\n","    \n","    Args:\n","        X: 2D nuumpy array with data, dimensions [features, samples]\n","        window_blocks: 1D numpy array indicating block of provenance for input segment values\n","        train: Boolean indicating whether the input data is training data\n","        scaler: StandardScaler to transform data\n","        magic_value: integer indicating value with which to pad samples\n","            \n","    Returns:\n","        X_cube: 3D numpy array of size [samples, timesteps, features]\n","        scaler: 1D numpy array with class label for each segment\n","    \"\"\"\n","    #standardize across each feature dimension\n","    if train:\n","        scaler = StandardScaler()\n","        scaler = scaler.fit(X.T)\n","        X = scaler.transform(X.T).T\n","    else:\n","        #for testing data, we want to use same transform as was fit to training data\n","        X = scaler.transform(X.T).T\n","        \n","    # common number of time steps\n","    common_timesteps = np.max(np.bincount(window_blocks.astype('int')))\n","    \n","    # get each block, pad, and stack to form a data cube\n","    X_cube = []\n","    for b_count, b_idx in enumerate(np.unique(window_blocks)):\n","       #slice\n","        X_slice = X[:,np.where(window_blocks==b_idx)[0]]\n","        #pad\n","        pad_size = common_timesteps-X_slice.shape[1]\n","        X_slice_pad = np.pad(X_slice,pad_width=((0,0),(0,pad_size)), mode='constant', constant_values= magic_value)\n","        #stack\n","        if b_count == 0:\n","            X_cube  = X_slice_pad\n","        else:\n","            X_cube = np.dstack((X_cube,X_slice_pad))\n","\n","    # swap dimension to get [samples, timesteps, features]\n","    X_cube = np.swapaxes(X_cube,0,2)\n","    \n","    return X_cube, scaler\n","\n","#~~~~~ VISUALIZATION FUNCTIONS ~~~~~~\n","\n","def plot_sensor_values(data_fn, x_limits = []):\n","    \"\"\"\n","    Plot signal timecourse for all channels using data in indicated file\n","    \n","    Args:\n","        data_fn: filename\n","        x_limits: minimum and maximum limits for x-axis (useful to looking at specific sections)\n"," \n","    Returns:\n","        fig: figure handle\n","    \"\"\"\n","\n","    # load file\n","    data_df = pd.DataFrame(pd.read_csv(data_fn, sep='\\t'))\n","\n","    # retrieve start times, end times, and labels for each condition block (will make it easier to parse traces later)\n","    start_times, end_times, event_labels  = get_gesture_times(data_df)\n","\n","    # interpolate data to steady frame rate\n","    data_df = get_steady_samp_rate_data(data_df)\n","\n","    # Unpack values into numpy arrays\n","    data_matrix = data_df.iloc[:,1:-1].values\n","    class_labels = data_df.iloc[:,-1].values\n","    tstamps = data_df.time.values\n","\n","    # define color palette\n","    palette = sns.color_palette('deep',8)\n","\n","    # define class legend\n","    labels = []\n","    custom_lines = []\n","\n","    classes = np.unique(event_labels)[1:]#exclude 'unmarked' label\n","    for c in classes.astype('int'):\n","        labels.append('Class %i'%(c))\n","        custom_lines.append(Line2D([0], [0], color=palette[c-1], lw=4))\n","\n","    #make figure\n","    nrows = 8\n","    ncols = 1\n","\n","    fig,ax = plt.subplots(nrows,ncols,figsize=(15,30),sharex = True)\n","\n","    #plot each channel\n","    for ch in range(8):\n","        ax[ch//ncols].plot(tstamps,data_matrix[:,ch]);\n","        ax[ch//ncols].axhline(y = 0, xmin = 0, xmax = 1, color = 'k', linestyle = '--', alpha = 0.5)\n","        #label subplot\n","        ax[ch//ncols].set_title('Channel %i'%(ch+1))\n","\n","        #mark events\n","        ymin,ymax = ax[ch//ncols].get_ylim()\n","        for idx,c in enumerate(event_labels):\n","            if c>0:#eclude 'unmarked label'\n","                ax[ch//ncols].hlines(y = ymax + .001, xmin = start_times[idx], xmax = end_times[idx], color = palette[int(c-1)],linewidth = 10)\n","\n","        if len(x_limits):\n","            ax[ch//ncols].set_xlim(x_limits)\n","\n","\n","    #set legend with events\n","    ax[0].legend(custom_lines, labels,bbox_to_anchor=(1, 1), loc='upper left', ncol=1)\n","\n","\n","    #label axes\n","    ax[0].set_ylabel('Sensor Voltage')\n","    ax[ch].set_xlabel('Time (ms)')\n","\n","    #despine\n","    sns.despine(fig= plt.gcf(), left = False, right = True, top = True, bottom = True)\n","\n","\n","    fig.tight_layout() \n","\n","    return fig\n","\n","def plot_signal_pspec(data_fn):\n","    \"\"\"\n","    Plot power spectrum of signal for each channel using data in datafile indicated\n","    \n","    Args:\n","        data_fn: filename\n"," \n","    Returns:\n","        fig: figure handle\n","    \"\"\"\n","\n","    # load file\n","    data_df = pd.DataFrame(pd.read_csv(data_fn, sep='\\t'))\n","\n","    # retrieve start times, end times, and labels for each condition block (will make it easier to parse traces later)\n","    start_times, end_times, event_labels  = get_gesture_times(data_df)\n","\n","    # interpolate data to steady sampling rate\n","    data_df = get_steady_samp_rate_data(data_df)\n","    samp_period = np.diff(data_df.time)[0]/1000.0\n","    samp_rate = 1/samp_period\n","\n","    # Unpack values into numpy arrays\n","    data_matrix = data_df.iloc[:,1:-1].values\n","    class_labels = data_df.iloc[:,-1].values\n","    tstamps = data_df.time.values\n","\n","    #Calculate the Welch's PSD of the data - yields a smoother, more informative, spectrum \n","    f,pspec = scipy.signal.welch(data_matrix, fs=samp_rate, window='hanning', nperseg=2*samp_rate, noverlap=samp_rate/2,\n","                              nfft=None, detrend='linear', return_onesided=True, scaling='density',axis = 0)\n","\n","    #make figure\n","    nrows = 4\n","    ncols = 2\n","    fig,ax = plt.subplots(nrows,ncols,figsize=(16,10),sharey = True, sharex = True)\n","\n","    for ch in range(data_matrix.shape[1]):\n","        ax[ch//ncols][ch%ncols].loglog(f[1:200*2],pspec[1:200*2,ch])#line noise will be obvious under 100 Hz\n","        #label subplot\n","\n","        ax[ch//ncols][ch%ncols].set_title('Channel %i'%(ch+1))\n","    #label axes\n","    ax[0][0].set_ylabel('Power')\n","    ax[ch//ncols][0].set_xlabel('Frequency')\n","\n","    #despine\n","    sns.despine(fig= plt.gcf(), left = False, right = True, top = True, bottom = False)\n","\n","    fig.tight_layout() \n","\n","    return fig\n","\n","def visualize_time_series_prob(data_folder, prob_class, times, series_labels):\n","    \"\"\"\n","    Visualize probability of each class across time for individual files\n","    \n","    Args:\n","        data_folder: folder with subject data\n","        prob_class: array with probability of each class for each sample\n","        times: array with timestamps for each signal segment\n","        series: array with file of provenance for each singla segment\n","            \n","    Returns:\n","        figure\n","    \"\"\"\n","\n","    #find files in subject folder\n","    file_list = [f for f in os.listdir(data_folder) if os.path.isfile(os.path.join(data_folder, f))]\n","\n","    for file_idx in range(len(file_list)):\n","\n","        # load file\n","        data_df = pd.DataFrame(pd.read_csv(os.path.join(data_folder,file_list[file_idx]), sep='\\t'))\n","\n","        # retrieve start times, end times, and labels for each condition block (will make it easier to parse traces later)\n","        start_times, end_times, event_labels  = get_gesture_times(data_df)\n","\n","        series_idxs = np.where(series_labels==file_idx)[0]\n","\n","        prob_series = prob_class[series_idxs,:]\n","        time_series = times[series_idxs]\n","\n","        classes = np.unique(event_labels)[1:]#exclude 'unmarked' label\n","        labels = []\n","        for c in classes.astype('int'):\n","            labels.append('Class %i'%(c))\n","\n","        # define color palette\n","        palette = sns.color_palette('deep',8)[1:]\n","\n","        plt.figure(figsize=(15,6))\n","        plt.gca().set_prop_cycle(plt.cycler('color',palette))\n","        plt.plot(time_series,prob_series, linewidth = 2);\n","\n","        #mark events\n","        for idx,c in enumerate(event_labels):\n","            if c>0:\n","                plt.hlines(y = 1.1, xmin = start_times[idx], xmax = end_times[idx], color = palette[c-1],linewidth = 10)\n","\n","        #label axes\n","        plt.ylabel('Class Probability')\n","        plt.xlabel('Time (ms)')\n","\n","        plt.legend(labels, bbox_to_anchor=(1, 1), loc='upper left', ncol=1)\n","\n","        sns.despine(fig= plt.gcf(), left = False, right = True, top = True, bottom = False)\n","\n","        plt.gcf().tight_layout() \n","\n","        plt.gcf().suptitle('%s'%(file_list[file_idx]), y= 1.05)\n","\n","    return plt.gcf()\n","\n","def dim_reduction_visualization(X, target_labels):\n","    \"\"\"\n","    Perform dimensionality reduction with tSNE and visualize results.\n","    \n","    Args:\n","        X: 2D numpy array with data [samples, features]\n","        target_labels: array. used to color points in embedded space\n"," \n","    Returns:\n","        fig: figure handle\n","    \"\"\"\n","    \n","    #make pipeline\n","    tsne_pipe = make_pipeline(StandardScaler(),#standardize\n","                              TSNE(n_components=2, perplexity = 50))\n","    #perform embedding\n","    X_embedded = tsne_pipe.fit_transform(X)\n","    \n","    # visualize\n","    palette = sns.color_palette('deep',8)\n","\n","    # define class legend\n","    labels = []\n","    custom_lines = []\n","\n","    classes = np.unique(target_labels)#exclude 'unmarked' label\n","    for c in classes.astype('int'):\n","        labels.append('Class %i'%(c))\n","        custom_lines.append(Line2D([0], [0], color=palette[c], lw=4))\n","\n","    sns.set_context('paper',font_scale = 2)\n","    fig,ax = plt.subplots(1,1,figsize=(8,8))\n","    \n","    #plot\n","    for s in range(X_embedded.shape[0]):\n","        ax.scatter(X_embedded[s,0],X_embedded[s,1],\\\n","                        color = palette[int(target_labels[s])],s = 100,linewidth = 2,alpha = 0.8)\n","    ax.axhline(y=0 ,xmin = 0,xmax = 1,color = 'k',linestyle = '--')    \n","    ax.axvline(x=0 ,ymin = 0,ymax = 1,color = 'k',linestyle = '--') \n","    #add legend\n","    ax.legend(custom_lines, labels,bbox_to_anchor=(1, 1), loc='upper left', ncol=1)\n","    #label\n","    ax.set_xlabel('Dimension 1')\n","    ax.set_ylabel('Dimension 2')\n","    sns.despine(trim=False, offset=0, bottom=False,top = True, left=False, ax=ax)\n","    \n","    return fig\n","    \n","\n","# ~~~~~~~~ LOGISTIC REGRESSION FUNCTIONS ~~~~~~~~\n","\n","def log_reg_on_all_data(X, Y, nsplits, penalty = 'none', multiclass = 'multinomial',permute = False):\n","    \"\"\"\n","    Train and evaluate a classifier based on logistic regression using all available classes in data\n","    \n","    Args:\n","        X: 2D numpy array with shape [samples, features]\n","        Y: array with class label for each sample\n","        nsplits: number of splits for K-fold cross-validation\n","        permute: Boolean to shuffle class labels (useful to test performance under null hypothesis) \n","        -parameters for logistic regression\n","        penalty: type of penalty for classifier\n","        multiclass: approach for multiclass classification\n","            \n","    Returns:\n","        train_f1_scores: training scores for each split\n","        test_f1_scores: test scores for each split\n","        prob_class: 2D numpy array with probabiliy of each class for each sample\n","    \"\"\"\n","    \n","    #retrieve some values from input\n","    nclass = np.unique(Y).size\n","    nsamples, nfeat = X.shape\n","    \n","    #initialize empty arrays\n","    test_f1_scores =  np.empty((nsplits,))\n","    train_f1_scores =  np.empty((nsplits,))\n","    prob_class = np.empty((nsamples,nclass))\n","    \n","    #permute class labels, if indicated\n","    if permute:\n","        Y = np.random.permutation(Y)\n","    \n","    \n","    #stratify split to retain ratio of class labels\n","    skf = StratifiedKFold(n_splits=nsplits,shuffle = True)\n","\n","\n","    #systematically use one fold of the data as a held-out test set\n","    for split_count, (train_index, test_index) in enumerate(skf.split(X, Y)):\n","\n","        trainX = X[train_index,:]\n","        testX = X[test_index,:]\n","\n","        trainY = Y[train_index]\n","        testY = Y[test_index]\n","\n","        #define model\n","        #note LogisticRegressionCV uses StratifiedKFold by default in cross-validation\n","        model = make_pipeline(StandardScaler(),\\\n","                              LogisticRegression(penalty = penalty, multi_class = multiclass ,max_iter = 10000))\n","        #fit model\n","        model.fit(trainX, trainY)\n","\n","        #predict labels on train set\n","        ypred = model.predict(trainX)\n","        #get F1 score\n","        train_f1_scores[split_count] = f1_score(trainY,ypred,average = 'macro')\n","\n","        #predict labels on test set\n","        ypred = model.predict(testX)\n","        #get F1 score\n","        test_f1_scores[split_count] = f1_score(testY,ypred,average = 'macro')\n","\n","\n","        #get prediction probabiliity on test set samples\n","        pred_prob = model.predict_proba(testX)\n","        prob_class[test_index,:] = pred_prob \n","\n","    return train_f1_scores, test_f1_scores, prob_class\n","\n","def log_reg_on_labeled_data(X, Y, times, series, nsplits, unmarked = 0,penalty = 'none', multiclass = 'multinomial',permute = False):\n","    \"\"\"\n","    Train and evaluate a classifier based on logistic regression using all available classes in data\n","    \n","    Args:\n","        X: 2D numpy array with shape [samples, features]\n","        Y: array with class label for each sample\n","        times: array with timestamps for each signal segment\n","        series: array with file of provenance for each singla segment\n","        nsplits: number of splits for K-fold cross-validation\n","        exclude_label: label to eclude\n","        permute: Boolean to shuffle class labels (useful to test performance under null hypothesis) \n","        -parameters for logistic regression\n","        penalty: type of penalty for classifier\n","        multiclass: approach for multiclass classification\n","            \n","    Returns:\n","        train_f1_scores: training scores for each split\n","        test_f1_scores: test scores for each split\n","        prob_class: 2D numpy array with probabiliy of each class for each sample\n","    \"\"\"\n","    \n","    #change timestamps so that there's no overlapping timestamps across series\n","    times_abs = np.empty((0,))\n","    max_time = 0\n","    for s in np.unique(series):\n","        series_idxs = np.where(series==0)[0]\n","        times_abs = np.hstack((times_abs,times[series_idxs]+max_time))\n","        max_time = np.max(times_abs)\n","\n","    #select \n","    in_samples = np.where(Y != unmarked)[0]\n","    out_samples = np.where(Y == unmarked)[0]\n","    X_in = X[in_samples,:]\n","    Y_in = Y[in_samples]\n","    X_out = X[out_samples,:]\n","    times_in = times_abs[in_samples]\n","    times_out = times_abs[out_samples]\n","    \n","    #retrieve some values from input\n","    nclass = np.unique(Y_in).size\n","    nsamples, nfeat = X_in.shape\n","    \n","    #initialize empty arrays\n","    test_f1_scores =  np.empty((nsplits,))\n","    train_f1_scores =  np.empty((nsplits,))\n","    prob_class_in = np.empty((nsamples,nclass))\n","    prob_class_out = np.empty((nsplits,out_samples.size,nclass))\n","    \n","    #permute class labels, if indicated\n","    if permute:\n","        Y_in = np.random.permutation(Y_in)\n","    \n","    \n","    #stratify split to retain ratio of class labels\n","    skf = StratifiedKFold(n_splits=nsplits,shuffle = True)\n","\n","\n","    #systematically use one fold of the data as a held-out test set\n","    for split_count, (train_index, test_index) in enumerate(skf.split(X_in, Y_in)):\n","\n","        trainX = X_in[train_index,:]\n","        testX = X_in[test_index,:]\n","\n","        trainY = Y_in[train_index]\n","        testY = Y_in[test_index]\n","\n","        #define model\n","        #note LogisticRegressionCV uses StratifiedKFold by default in cross-validation\n","        model = make_pipeline(StandardScaler(),\\\n","                              LogisticRegression(penalty = penalty, multi_class = multiclass ,max_iter = 10000))\n","        #fit model\n","        model.fit(trainX, trainY)\n","\n","        #predict labels on train set\n","        ypred = model.predict(trainX)\n","        #get F1 score\n","        train_f1_scores[split_count] = f1_score(trainY,ypred,average = 'macro')\n","\n","        #predict labels on test set\n","        ypred = model.predict(testX)\n","        #get F1 score\n","        test_f1_scores[split_count] = f1_score(testY,ypred,average = 'macro')\n","\n","\n","        #get prediction probabiliity on test set samples\n","        pred_prob = model.predict_proba(testX)\n","        prob_class_in[test_index,:] = pred_prob \n","        \n","        #get prediction probability on 'unmarked' samples\n","        pred_prob = model.predict_proba(X_out)\n","        prob_class_out[split_count,:,:] = pred_prob\n","    \n","    #get probability of each class over time\n","    # average over multiple splits\n","    prob_class_out = np.mean(prob_class_out,0)\n","    \n","    #concatenate and sort, using window timestamps as a guide\n","    T_all = np.hstack((times_in,times_out))\n","    prob_class = np.vstack((prob_class_in,prob_class_out))\n","    sort_idxs = np.argsort(T_all)\n","    prob_class = prob_class[sort_idxs,:]\n","    \n","    return train_f1_scores, test_f1_scores, prob_class\n","\n","# ~~~~~~~~ RNN CLASSIFIER FUNCTIONS ~~~~~~~~\n","def get_data_cube(X, Y, window_blocks, train = True, scaler = None, magic_value = -100):\n","    \"\"\"\n","    Create data cube for use with Keras RNN. Standardize data then pad and reshape data to have\n","    [samples, timesteps, features] dimensions with an equal number of timesteps for each slice\n","    I use a Masking layer in the RNN architecture to allow for sequences of different length\n","    \n","    Args:\n","        X: 2D nuumpy array with data, dimensions [features, samples]\n","        window_blocks: 1D numpy array indicating block of provenance for input segment values\n","        train: Boolean indicating whether the input data is training data\n","        scaler: StandardScaler to transform data\n","        magic_value: integer indicating value with which to pad samples\n","            \n","    Returns:\n","        X_cube: 3D numpy array of size [samples, timesteps, features]\n","        scaler: 1D numpy array with class label for each segment\n","    \"\"\"\n","    #standardize across each feature dimension\n","    if train:\n","        scaler = StandardScaler()\n","        scaler = scaler.fit(X.T)\n","        X = scaler.transform(X.T).T\n","    else:\n","        #for testing data, we want to use same transform as was fit to training data\n","        X = scaler.transform(X.T).T\n","\n","    # common number of time steps\n","    common_timesteps = np.max(np.bincount(window_blocks.astype('int')))\n","    \n","    # get each block, pad, and stack to form a data cube\n","    X_cube = []\n","    Y_cube = []\n","    for b_count, b_idx in enumerate(np.unique(window_blocks)):\n","       #slice\n","        X_slice = X[:,np.where(window_blocks==b_idx)[0]]\n","        Y_slice = Y[np.where(window_blocks==b_idx)[0],:].T\n","        #pad - can just use keras padding function\n","        pad_size = common_timesteps-X_slice.shape[1]\n","        X_slice_pad = np.pad(X_slice,pad_width=((0,0),(0,pad_size)), mode='constant', constant_values= magic_value)\n","        Y_slice_pad = np.pad(Y_slice,pad_width=((0,0),(0,pad_size)), mode='constant', constant_values= 0)\n","        #stack\n","        if b_count == 0:\n","            X_cube  = X_slice_pad\n","            Y_cube = Y_slice_pad\n","        else:\n","            X_cube = np.dstack((X_cube,X_slice_pad))\n","            Y_cube = np.dstack((Y_cube,Y_slice_pad))\n","    # swap dimension to get [samples, timesteps, features]\n","    X_cube = np.swapaxes(X_cube,0,2)\n","    Y_cube = np.swapaxes(Y_cube,0,2)\n","    \n","    return X_cube, Y_cube, scaler\n","\n","def many_to_many_model(input_shape, n_outputs, mask_value = -100):\n","    \"\"\"\n","    Create simple RNN model\n","    \n","    Args:\n","        input_shape\n","        n_outputs: number of output classes\n","        mask_value: value indicating which timepoints to mask out\n","            \n","    Returns:\n","        model\n","    \"\"\"\n","    \n","    #define model architecture\n","    X_input = Input(shape = input_shape)\n","    X = Masking(mask_value=mask_value)(X_input)\n","    X = GRU(24, return_sequences= True, stateful = False)(X)\n","    X = Dropout(0.5)(X)\n","    X = TimeDistributed(Dense(n_outputs,activation = 'softmax'))(X)\n","    model = Model(inputs = X_input, outputs = X)\n","    return model\n","\n","def RNN_on_labeled_data(feature_matrix, target_labels, window_tstamps, block_labels, n_splits = 4,\\\n","                       verbose = 0, epochs = 40, batch_size = 2, permute = False):\n","    \"\"\"\n","    Train and evaluate RNN model on labeled data\n","    \n","    Args:\n","        feature_matrix: 2D nuumpy array with data, dimensions [features, samples]\n","        window_blocks: 1D numpy array indicating block of provenance for input segment values\n","        train: Boolean indicating whether the input data is training data\n","        scaler: StandardScaler to transform data\n","        magic_value: integer indicating value with which to pad samples\n","            \n","    Returns:\n","        train_f1_scores: training scores for each split\n","        test_f1_scores: test scores for each split\n","        train_loss: training loss metric for each split\n","        test_loss_scores: test loss metric for each split\n","\n","    \"\"\"\n","    \n","    # transpose data\n","    #feature_matrix = feature_matrix.T\n","    \n","    #initialize empty array\n","    train_f1_scores = np.empty((n_splits,))\n","    test_f1_scores = np.empty((n_splits,))\n","    train_loss = np.empty((n_splits,))\n","    test_loss = np.empty((n_splits,))\n","\n","    #get block_ids and corresponding classes in block. there are the units over which we will do train/test split\n","    blocks = np.array([k for k,g in groupby(block_labels) if k!=0])\n","    classes = np.array([k for k,g in groupby(target_labels) if k!=0])\n","    \n","    #permute class labels, if indicated\n","    if permute:\n","        classes_perm = np.random.permutation(classes)\n","        target_labels_shuffled = np.empty((0,))\n","        for i,b in enumerate(blocks):\n","            idxs = np.where(block_labels==b)[0]\n","            target_labels_shuffled = np.hstack((target_labels_shuffled,classes_perm[i]*np.ones((idxs.size,))))\n","        target_labels = target_labels_shuffled\n","        classes = classes_perm\n","\n","    #stratify split to retain ratio of class labels\n","    skf = StratifiedKFold(n_splits=n_splits,shuffle = True)\n","\n","    #systematically use one fold of the data as a held-out test set\n","    for split_count, (blocks_train_idxs, blocks_test_idxs) in enumerate(skf.split(blocks, classes)):\n","        print('Split Count: %i'% (split_count+1))\n","        print(classes[blocks_test_idxs])\n","\n","        #get train and test indices\n","        blocks_train = blocks[blocks_train_idxs]\n","        blocks_test = blocks[blocks_test_idxs]\n","        train_idxs =np.where(np.isin(block_labels,blocks_train))[0]\n","        test_idxs =np.where(np.isin(block_labels,blocks_test))[0]\n","\n","        # select training data and pad to get an array where each sample has same number of timesteps\n","        X_train = feature_matrix[:,train_idxs]\n","        y_train = target_labels[train_idxs]\n","        #one-hot encoding of class labels\n","        y_train = to_categorical(y_train-np.min(y_train))\n","        #get block labels of given samples\n","        win_blocks_train = block_labels[train_idxs]\n","\n","        #get cube\n","        X_train_cube, Y_train_cube, scaler = get_data_cube(X_train, y_train,win_blocks_train, train = True, magic_value = -100)\n","        print(X_train_cube.shape, Y_train_cube.shape)\n","\n","        # select test data and pad to get an array where each sample has same number of timesteps\n","        X_test = feature_matrix[:,test_idxs]\n","        y_test = target_labels[test_idxs]\n","        print(np.unique(y_test))\n","        #one-hot encoding of class labels\n","        y_test = to_categorical(y_test-np.min(y_test))\n","\n","\n","\n","        #get block labels of given samples\n","        win_blocks_test = block_labels[test_idxs]\n","        #get data cube\n","        X_test_cube, Y_test_cube, scaler = get_data_cube(X_test, y_test, win_blocks_test, train = False, scaler = scaler, magic_value = -100)\n","        print(X_test_cube.shape, Y_test_cube.shape)\n","\n","        n_timesteps, n_features, n_outputs = X_train_cube.shape[1], X_train_cube.shape[2], Y_test_cube.shape[2]\n","\n","        #setting timestep dimension to None \n","        model = many_to_many_model((None,n_features),n_outputs,mask_value = -100)\n","        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy',Precision(), Recall()])\n","        #model.summary\n","\n","        print('Training Model')\n","        # fit network\n","        model.fit(X_train_cube, Y_train_cube, epochs=epochs, batch_size=batch_size, verbose=verbose)\n","\n","        print('Evaluating Model')\n","\n","        #evaluate on trained data\n","        loss, accuracy, precision, recall = model.evaluate(X_train_cube, Y_train_cube, batch_size=batch_size, verbose=verbose)\n","        #compute f1 score and store\n","        if precision + recall == 0:\n","            f1_score = 0\n","        else:\n","          f1_score = 2* ((precision * recall)/(precision + recall))\n","        train_f1_scores[split_count] = f1_score\n","        train_loss[split_count] = loss\n","\n","        #evaluate on trained data\n","        loss, accuracy, precision, recall = model.evaluate(X_test_cube, Y_test_cube, batch_size=batch_size, verbose=verbose)\n","        #compute f1 score and store\n","        if precision + recall == 0:\n","            f1_score = 0\n","        else:\n","          f1_score = 2* ((precision * recall)/(precision + recall))\n","        test_f1_scores[split_count] = f1_score\n","        test_loss[split_count] = loss\n","    return train_f1_scores, test_f1_scores, train_loss, test_loss"],"id":"efa475c3","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f282fdc3","executionInfo":{"status":"ok","timestamp":1623648325716,"user_tz":240,"elapsed":19,"user":{"displayName":"Cesar Echavarria","photoUrl":"","userId":"12535184235153277849"}},"outputId":"43bb9b6a-1711-45b1-9017-d70f3f969d01"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"f282fdc3","execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"acc91a8e"},"source":[""],"id":"acc91a8e","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f0928cf8"},"source":["#function template\n","\n","def f():\n","    \"\"\"\n","    Description\n","    \n","    Args:\n","        inputs\n","            \n","    Returns:\n","        outputs\n","    \"\"\"\n","    pass"],"id":"f0928cf8","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"235af840"},"source":[""],"id":"235af840","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"854c47bb"},"source":[""],"id":"854c47bb","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ec6ee904"},"source":["#define where the data file are located\n","data_folder = '/content/drive/MyDrive/EMG_data/01'\n","\n","\n","#fot filtering\n","lo_freq = 20\n","hi_freq = 450\n","\n","win_size = 100 #define window size over which to compute time-domain features\n","step = win_size #keeping this parameter in case I want to re-run later with some overlap\n","\n","\n","feature_matrix, target_labels, window_tstamps, \\\n","block_labels, series_labels = get_subject_data_for_classification(data_folder, lo_freq, hi_freq, \\\n","                                                                  win_size, step)"],"id":"ec6ee904","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ce9b7dc7"},"source":["#exclude blocks with 'unknown' label\n","in_samples = np.where(target_labels != 0)[0]\n","out_samples = np.where(target_labels == 0)[0]\n","\n","feature_matrix_in = feature_matrix[in_samples,:]\n","\n","\n","target_labels_in = target_labels[in_samples]\n","\n","\n","window_tstamps_in = window_tstamps[in_samples]\n","\n","\n","block_labels_in = block_labels[in_samples]\n"],"id":"ce9b7dc7","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2a2dc166"},"source":["epoch_list = np.array([15, 40])"],"id":"2a2dc166","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d2b08635"},"source":["#initialize empty matrices\n","train_f1_scores = np.empty((0,0))\n","test_f1_scores = np.empty((0,0))\n","\n","train_f1_scores_perm = np.empty((0,0))\n","test_f1_scores_perm = np.empty((0,0))\n"],"id":"d2b08635","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"79afcb5e","executionInfo":{"status":"ok","timestamp":1623649816014,"user_tz":240,"elapsed":138348,"user":{"displayName":"Cesar Echavarria","photoUrl":"","userId":"12535184235153277849"}},"outputId":"89340ed1-0e1a-49a0-97ee-719911475c05"},"source":["for e in epoch_list:\n","    train_f1, test_f1, train_loss, test_loss = RNN_on_labeled_data(feature_matrix_in.T, target_labels_in, window_tstamps_in,\\\n","                                                          block_labels_in, epochs = e)\n","\n","\n","    train_f1_scores_rep, test_f1_scores_rep, train_loss_rep, test_loss_rep = RNN_on_labeled_data(feature_matrix_in.T, target_labels_in, window_tstamps_in,\\\n","                                                          block_labels_in, epochs = e, permute = True)\n","    #append to list\n","    train_f1_scores = np.vstack((train_f1_scores, train_f1)) if train_f1_scores.size else train_f1\n","    test_f1_scores = np.vstack((test_f1_scores, test_f1)) if test_f1_scores.size else test_f1\n","    train_f1_scores_perm = np.vstack((train_f1_scores_perm, train_f1_scores_rep)) if train_f1_scores_perm.size else train_f1_scores_rep\n","    test_f1_scores_perm = np.vstack((test_f1_scores_perm, test_f1_scores_rep)) if test_f1_scores_perm.size else test_f1_scores_rep"],"id":"79afcb5e","execution_count":null,"outputs":[{"output_type":"stream","text":["Split Count: 1\n","[4. 6. 3. 5. 1. 2.]\n","(18, 21, 16) (18, 21, 6)\n","[1. 2. 3. 4. 5. 6.]\n","(6, 18, 16) (6, 18, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","[5. 3. 4. 1. 2. 6.]\n","(18, 21, 16) (18, 21, 6)\n","[1. 2. 3. 4. 5. 6.]\n","(6, 20, 16) (6, 20, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 3\n","[1. 3. 2. 5. 4. 6.]\n","(18, 20, 16) (18, 20, 6)\n","[1. 2. 3. 4. 5. 6.]\n","(6, 21, 16) (6, 21, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","[2. 6. 1. 4. 3. 5.]\n","(18, 21, 16) (18, 21, 6)\n","[1. 2. 3. 4. 5. 6.]\n","(6, 20, 16) (6, 20, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 1\n","[6. 5. 1. 2. 3. 4.]\n","(18, 20, 16) (18, 20, 6)\n","[1. 2. 3. 4. 5. 6.]\n","(6, 21, 16) (6, 21, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","[4. 1. 6. 5. 2. 3.]\n","(18, 21, 16) (18, 21, 6)\n","[1. 2. 3. 4. 5. 6.]\n","(6, 20, 16) (6, 20, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 3\n","[6. 1. 3. 5. 2. 4.]\n","(18, 21, 16) (18, 21, 6)\n","[1. 2. 3. 4. 5. 6.]\n","(6, 20, 16) (6, 20, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","[3. 1. 2. 6. 5. 4.]\n","(18, 21, 16) (18, 21, 6)\n","[1. 2. 3. 4. 5. 6.]\n","(6, 18, 16) (6, 18, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 1\n","[5. 1. 2. 3. 4. 6.]\n","(18, 21, 16) (18, 21, 6)\n","[1. 2. 3. 4. 5. 6.]\n","(6, 20, 16) (6, 20, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","[2. 3. 4. 6. 5. 1.]\n","(18, 21, 16) (18, 21, 6)\n","[1. 2. 3. 4. 5. 6.]\n","(6, 20, 16) (6, 20, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 3\n","[1. 3. 5. 4. 6. 2.]\n","(18, 21, 16) (18, 21, 6)\n","[1. 2. 3. 4. 5. 6.]\n","(6, 18, 16) (6, 18, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","[1. 4. 6. 2. 3. 5.]\n","(18, 20, 16) (18, 20, 6)\n","[1. 2. 3. 4. 5. 6.]\n","(6, 21, 16) (6, 21, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 1\n","[5. 3. 6. 2. 1. 4.]\n","(18, 21, 16) (18, 21, 6)\n","[1. 2. 3. 4. 5. 6.]\n","(6, 18, 16) (6, 18, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","[4. 5. 2. 3. 1. 6.]\n","(18, 20, 16) (18, 20, 6)\n","[1. 2. 3. 4. 5. 6.]\n","(6, 21, 16) (6, 21, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 3\n","[1. 5. 4. 2. 3. 6.]\n","(18, 21, 16) (18, 21, 6)\n","[1. 2. 3. 4. 5. 6.]\n","(6, 20, 16) (6, 20, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","[5. 4. 3. 1. 6. 2.]\n","(18, 21, 16) (18, 21, 6)\n","[1. 2. 3. 4. 5. 6.]\n","(6, 20, 16) (6, 20, 6)\n","Training Model\n","Evaluating Model\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f6d6f662","executionInfo":{"status":"ok","timestamp":1623649821500,"user_tz":240,"elapsed":599,"user":{"displayName":"Cesar Echavarria","photoUrl":"","userId":"12535184235153277849"}},"outputId":"ac3d5642-818f-4a4a-8401-0de43fd39512"},"source":["train_f1_scores_perm"],"id":"f6d6f662","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.07121662, 0.        , 0.15342465, 0.11461318],\n","       [0.45637584, 0.3392405 , 0.21606649, 0.40291263]])"]},"metadata":{"tags":[]},"execution_count":90}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":293},"id":"dda55e7d","executionInfo":{"status":"ok","timestamp":1623649824822,"user_tz":240,"elapsed":373,"user":{"displayName":"Cesar Echavarria","photoUrl":"","userId":"12535184235153277849"}},"outputId":"67464bc1-a3b5-475d-efc8-649e883885e5"},"source":["plt.plot(np.nanmean(test_f1_scores,1),'b')\n","plt.plot(np.nanmean(test_f1_scores_perm,1),'r')"],"id":"dda55e7d","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f01002e4e90>]"]},"metadata":{"tags":[]},"execution_count":91},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":292},"id":"1bfce47b","executionInfo":{"status":"ok","timestamp":1623649832739,"user_tz":240,"elapsed":460,"user":{"displayName":"Cesar Echavarria","photoUrl":"","userId":"12535184235153277849"}},"outputId":"98d580ab-0f54-4b9b-b256-45306993d2ed"},"source":["plt.plot(np.nanmean(train_f1_scores,1),'b')\n","plt.plot(np.nanmean(train_f1_scores_perm,1),'r')"],"id":"1bfce47b","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f00f84f4810>]"]},"metadata":{"tags":[]},"execution_count":92},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"60c5b10c","outputId":"e8091b4f-8f1a-46e1-f5f3-c661c50b7d26"},"source":["train_f1_scores, test_f1_scores, train_loss, test_loss = RNN_on_labeled_data(feature_matrix_in.T, target_labels_in, window_tstamps_in,\\\n","                                                      block_labels_in, epochs = 5)"],"id":"60c5b10c","execution_count":null,"outputs":[{"output_type":"stream","text":["(16, 428)\n","Split Count: 1\n","(18, 21, 16) (18, 21, 6)\n","(6, 20, 16) (6, 20, 6)\n","Training Model\n","Evaluating Model\n"],"name":"stdout"},{"output_type":"stream","text":["/Users/cesar/anaconda2/envs/EMG/lib/python3.6/site-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in float_scalars\n","/Users/cesar/anaconda2/envs/EMG/lib/python3.6/site-packages/ipykernel_launcher.py:171: RuntimeWarning: invalid value encountered in float_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["Split Count: 2\n","(18, 20, 16) (18, 20, 6)\n","(6, 21, 16) (6, 21, 6)\n","Training Model\n","Evaluating Model\n"],"name":"stdout"},{"output_type":"stream","text":["/Users/cesar/anaconda2/envs/EMG/lib/python3.6/site-packages/ipykernel_launcher.py:171: RuntimeWarning: invalid value encountered in float_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["Split Count: 3\n","(18, 21, 16) (18, 21, 6)\n","(6, 20, 16) (6, 20, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","(18, 21, 16) (18, 21, 6)\n","(6, 20, 16) (6, 20, 6)\n","Training Model\n","Evaluating Model\n"],"name":"stdout"},{"output_type":"stream","text":["/Users/cesar/anaconda2/envs/EMG/lib/python3.6/site-packages/ipykernel_launcher.py:171: RuntimeWarning: invalid value encountered in float_scalars\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"0f83d8cd","outputId":"39f957c8-bfe2-4626-ce66-b247c7585263"},"source":["print(train_f1_scores, test_f1_scores)"],"id":"0f83d8cd","execution_count":null,"outputs":[{"output_type":"stream","text":["[       nan 0.0125     0.27100271 0.11078716] [       nan        nan 0.22764227        nan]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ee646e67","outputId":"15c4f7fb-c46a-4a7d-9268-8b68138784ae"},"source":["#initialize empty matrices\n","train_f1_scores_perm = np.empty((0,0))\n","test_f1_scores_perm = np.empty((0,0))\n","\n","nreps = 1\n","for rep in range(nreps):\n","    print('Rep %i'%(rep+1))\n","    train_f1_scores_rep, test_f1_scores_rep, train_loss_rep, test_loss_rep = RNN_on_labeled_data(feature_matrix_in.T, target_labels_in, window_tstamps_in,\\\n","                                                          block_labels_in, n_splits = 4,epochs = 5, permute = True)\n","    #append to list\n","    train_f1_scores_perm = np.vstack((train_f1_scores_perm, train_f1_scores_rep)) if train_f1_scores_perm.size else train_f1_scores_rep\n","    test_f1_scores_perm = np.vstack((test_f1_scores_perm, test_f1_scores_rep)) if test_f1_scores_perm.size else test_f1_scores_rep"],"id":"ee646e67","execution_count":null,"outputs":[{"output_type":"stream","text":["Rep 1\n","(16, 428)\n","Split Count: 1\n","(12, 21, 16) (12, 21, 6)\n","(12, 20, 16) (12, 20, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","(12, 20, 16) (12, 20, 6)\n","(12, 21, 16) (12, 21, 6)\n","Training Model\n","Evaluating Model\n"],"name":"stdout"},{"output_type":"stream","text":["/Users/cesar/anaconda2/envs/EMG/lib/python3.6/site-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in float_scalars\n","/Users/cesar/anaconda2/envs/EMG/lib/python3.6/site-packages/ipykernel_launcher.py:171: RuntimeWarning: invalid value encountered in float_scalars\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"53a57527"},"source":[""],"id":"53a57527","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5a0a84d9"},"source":[""],"id":"5a0a84d9","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b9d57219"},"source":[""],"id":"b9d57219","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a0a287b0"},"source":[""],"id":"a0a287b0","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1a20bac0","outputId":"cd1356f1-87b4-441d-d7b9-be854ede9791"},"source":["train_f1_scores_perm"],"id":"1a20bac0","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.07174888,        nan])"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"8d7ca68e","outputId":"e4e9d6db-24a6-4cf3-a7e7-ecbcd1e2e9eb"},"source":["test_f1_scores_perm"],"id":"8d7ca68e","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.0093458,       nan])"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"c6bb7fba"},"source":["#average scores across splits\n","train_f1_scores_perm = np.mean(train_f1_scores_perm, axis = 1)\n","test_f1_scores_perm = np.mean(test_f1_scores_perm, axis = 1)\n","\n","#Put results in a dataframe\n","results_df = []\n","results_df.append(pd.DataFrame({'F1_score':train_f1_scores_perm,\\\n","                               'Shuffled':[True for x in range(train_f1_scores_perm.size)],\\\n","                               'Type':['Train' for x in range(train_f1_scores_perm.size)]}))\n","\n","results_df.append(pd.DataFrame({'F1_score':test_f1_scores_perm,\\\n","                               'Shuffled':[True for x in range(test_f1_scores_perm.size)],\\\n","                               'Type':['Test' for x in range(test_f1_scores_perm.size)]}))\n","\n","results_df.append(pd.DataFrame({'F1_score':train_f1_scores,\\\n","                               'Shuffled':[False for x in range(train_f1_scores.size)],\\\n","                               'Type':['Train' for x in range(train_f1_scores.size)]}))\n","\n","results_df.append(pd.DataFrame({'F1_score':test_f1_scores,\\\n","                               'Shuffled':[False for x in range(test_f1_scores.size)],\\\n","                               'Type':['Test' for x in range(test_f1_scores.size)]}))\n","\n","results_df = pd.concat(results_df,axis = 0)\n","\n","#Compare real and null distributions. Output t-test\n","tstat, pval_train = scipy.stats.ttest_ind(train_f1_scores, train_f1_scores_perm)\n","tstat, pval_test = scipy.stats.ttest_ind(test_f1_scores, test_f1_scores_perm)\n","print('Train data pval: %.09f' %(pval_train))\n","print('Test data pval: %.09f' %(pval_test))\n","\n","#Visualize results\n","g = sns.catplot(data = results_df, x= 'Shuffled', y = 'F1_score', hue = 'Shuffled',\\\n","            col = 'Type',kind = 'box', order = [True,False])\n","#Label axes and subpots\n","for ax in g.axes[0]:\n","    ax.set_xlabel('Shuffled Labels')\n","g.axes[0][0].set_ylabel('F1 Score')\n","g.axes[0][0].set_title('Training Data',fontweight = 'bold');\n","g.axes[0][1].set_title('Test Data',fontweight = 'bold');"],"id":"c6bb7fba","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8be08053"},"source":[""],"id":"8be08053","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d2cab63e"},"source":[""],"id":"d2cab63e","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f309fe45"},"source":["feature_matrix_in.shape"],"id":"f309fe45","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"99cfb92e"},"source":["#exclude blocks with 'unknown' label\n","in_samples = np.where(target_labels != 0)[0]\n","out_samples = np.where(target_labels == 0)[0]\n","\n","feature_matrix_in = feature_matrix[in_samples,:]\n","feature_matrix_out = feature_matrix[out_samples,:]\n","\n","target_labels_in = target_labels[in_samples]\n","target_labels_out = target_labels[out_samples]\n","\n","window_tstamps_in = window_tstamps[in_samples]\n","window_tstamps_out = window_tstamps[out_samples]\n","\n","block_labels_in = block_labels[in_samples]\n","block_labels_out = block_labels[out_samples]\n","\n","series_labels_in = series_labels[in_samples]\n","series_labels_out = series_labels[out_samples]\n","\n","# transpose data\n","feature_matrix_in = feature_matrix_in.T"],"id":"99cfb92e","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"271023c0"},"source":["verbose, epochs, batch_size = 0, 10, 2"],"id":"271023c0","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"539a7793"},"source":["#def prep_data_for_RNN():\n","n_splits = 4\n","\n","#initialize empty array\n","train_f1_scores = np.empty((n_splits,))\n","test_f1_scores = np.empty((n_splits,))\n","train_loss = np.empty((n_splits,))\n","test_loss = np.empty((n_splits,))\n","\n","#get block_ids and corresponding classes in block. there are the units over which we will do train/test split\n","blocks = np.array([k for k,g in groupby(block_labels_in) if k!=0])\n","classes = np.array([k for k,g in groupby(target_labels_in) if k!=0])\n","\n","\n","#stratify split to retain ratio of class labels\n","skf = StratifiedKFold(n_splits=n_splits,shuffle = True)\n","\n","#systematically use one fold of the data as a held-out test set\n","for split_count, (blocks_train_idxs, blocks_test_idxs) in enumerate(skf.split(blocks, classes)):\n","    print('Split Count: %i'% (split_count))\n","\n","    #get train and test indices\n","    blocks_train = blocks[blocks_train_idxs]\n","    blocks_test = blocks[blocks_test_idxs]\n","    train_idxs =np.where(np.isin(block_labels_in,blocks_train))[0]\n","    test_idxs =np.where(np.isin(block_labels_in,blocks_test))[0]\n","\n","    # select training data and pad to get an array where each sample has same number of timesteps\n","    X_train = feature_matrix_in[:,train_idxs]\n","    y_train = target_labels_in[train_idxs]\n","    #one-hot encoding of class labels\n","    y_train = to_categorical(y_train-np.min(y_train))\n","    #get block labels of given samples\n","    win_blocks_train = block_labels_in[train_idxs]\n","\n","    #get cube\n","    X_train_cube, Y_train_cube, scaler = get_data_cube(X_train, y_train,win_blocks_train, train = True, magic_value = -100)\n","\n","\n","    # select test data and pad to get an array where each sample has same number of timesteps\n","    X_test = feature_matrix_in[:,test_idxs]\n","    y_test = target_labels_in[test_idxs]\n","    #one-hot encoding of class labels\n","    y_test = to_categorical(y_test-np.min(y_test))\n","    #get block labels of given samples\n","    win_blocks_test = block_labels_in[test_idxs]\n","    #get data cube\n","    X_test_cube, Y_test_cube, scaler = get_data_cube(X_test, y_test, win_blocks_test, train = False, scaler = scaler, magic_value = -100)\n","\n","\n","    n_timesteps, n_features, n_outputs = X_train_cube.shape[1], X_train_cube.shape[2], Y_test_cube.shape[2]\n","\n","    #setting timestep dimension to None \n","    model = many_to_many_model((None,n_features),mask_value = -100)\n","    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy',Precision(), Recall()])\n","    #model.summary\n","    \n","    print('Training Model')\n","    # fit network\n","    model.fit(X_train_cube, Y_train_cube, epochs=epochs, batch_size=batch_size, verbose=verbose)\n","    \n","    print('Evaluating Model')\n","\n","    #evaluate on trained data\n","    loss, accuracy, precision, recall = model.evaluate(X_train_cube, Y_train_cube, batch_size=batch_size, verbose=verbose)\n","    #compute f1 score and store\n","    f1_score = 2* ((precision * recall)/(precision + recall))\n","    train_f1_scores[split_count] = f1_score\n","    train_lis[split_count] = f1_score\n","    \n","    #evaluate on trained data\n","    loss, accuracy, precision, recall = model.evaluate(X_test_cube, Y_test_cube, batch_size=batch_size, verbose=verbose)\n","    #compute f1 score and store\n","    f1_score = 2* ((precision * recall)/(precision + recall))\n","    test_f1_scores[split_count] = f1_score\n","\n","    #preds = model.predict(X_test_cube)"],"id":"539a7793","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5c935fe7"},"source":["print(train_f1_scores, test_f1_scores)"],"id":"5c935fe7","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"87f3db6f"},"source":["print(train_f1_scores, test_f1_scores)"],"id":"87f3db6f","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"585d0ce9"},"source":["preds.shape"],"id":"585d0ce9","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3c8dd834"},"source":["blocks_test_idxs"],"id":"3c8dd834","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"da4b073e"},"source":[""],"id":"da4b073e","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c8d9c4cc"},"source":[""],"id":"c8d9c4cc","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a9ad8a58"},"source":[""],"id":"a9ad8a58","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"20df2306"},"source":["# fit network\n","model.fit(X_train_cube, Y_train_cube, epochs=40, batch_size=batch_size, verbose=verbose)"],"id":"20df2306","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"40996d34"},"source":["_, accuracy, precision, recall = model.evaluate(X_test_cube, Y_test_cube, batch_size=batch_size, verbose=1)"],"id":"40996d34","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"99eff927"},"source":["f1_score = 2* ((precision * recall)/(precision + recall))\n","print(f1_score)\n","\n","preds = model.predict(X_test_cube)"],"id":"99eff927","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1f92a16b"},"source":["plt.plot(preds[5,:,:]);"],"id":"1f92a16b","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"761ef4a4"},"source":["X_train_cube[1,:,0]"],"id":"761ef4a4","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"84b90544"},"source":[""],"id":"84b90544","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a346c576"},"source":[""],"id":"a346c576","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"229957a6"},"source":[""],"id":"229957a6","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9d5a693a"},"source":[""],"id":"9d5a693a","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"70280407"},"source":[""],"id":"70280407","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"53d76893"},"source":[""],"id":"53d76893","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a8023b18"},"source":[""],"id":"a8023b18","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5d4007bf"},"source":[""],"id":"5d4007bf","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"41b61afa"},"source":[""],"id":"41b61afa","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5227e668"},"source":[""],"id":"5227e668","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1b6a57d3"},"source":[""],"id":"1b6a57d3","execution_count":null,"outputs":[]}]}