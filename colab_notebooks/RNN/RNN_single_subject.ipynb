{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RNN_single_subject.ipynb","provenance":[],"authorship_tag":"ABX9TyMBdFLcyyMWoIO6abgdYDqD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_AVQfT829MJ9","executionInfo":{"status":"ok","timestamp":1625667966996,"user_tz":240,"elapsed":25617,"user":{"displayName":"Cesar Echavarria","photoUrl":"","userId":"12535184235153277849"}},"outputId":"d66aff91-2f1f-4319-d6b5-723da90df5cf"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2uTD0z_H8MF3","executionInfo":{"status":"ok","timestamp":1625667978680,"user_tz":240,"elapsed":2724,"user":{"displayName":"Cesar Echavarria","photoUrl":"","userId":"12535184235153277849"}}},"source":["#import necessary packages\n","\n","#our workhorses\n","import numpy as np\n","import pandas as pd\n","import scipy\n","\n","#to visualize\n","%matplotlib inline\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","#style params for figures\n","sns.set(font_scale = 2)\n","plt.style.use('seaborn-white')\n","plt.rc(\"axes\", labelweight=\"bold\")\n","from IPython.display import display, HTML\n","\n","#to load files\n","import os\n","import h5py\n","\n","\n","#ML packages\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import StratifiedKFold\n","from itertools import groupby\n","\n","from tensorflow import keras\n","from tensorflow.keras.metrics import Precision, Recall\n","from tensorflow.keras.models import Sequential, Model, load_model, Sequential, save_model\n","from tensorflow. keras.layers import Dense, Activation, Dropout, Input,  TimeDistributed, GRU, Masking, LSTM\n","from tensorflow.keras.utils import to_categorical\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"VtGVnIGI9Gk4"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Iankel4O8eL4","executionInfo":{"status":"ok","timestamp":1625677438453,"user_tz":240,"elapsed":5485,"user":{"displayName":"Cesar Echavarria","photoUrl":"","userId":"12535184235153277849"}}},"source":["#load custom functions\n","\n","#!/usr/bin/env python2\n","# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Sat Jun 12 2021\n","@author: cechava\n","\"\"\"\n","from itertools import groupby\n","import numpy as np\n","import pandas as pd\n","import scipy\n","import scipy.signal\n","\n","#to visualize \n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from matplotlib.lines import Line2D\n","#style params for figures\n","sns.set(font_scale = 2)\n","plt.style.use('seaborn-white')\n","plt.rc(\"axes\", labelweight=\"bold\")\n","\n","\n","#to load files\n","import os\n","import h5py\n","\n","#ML packages\n","from sklearn.linear_model import  LogisticRegression\n","from sklearn.metrics import f1_score,make_scorer, log_loss\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import make_pipeline\n","from sklearn.manifold import TSNE\n","\n","\n","from tensorflow import keras\n","from tensorflow.keras.metrics import Precision, Recall\n","from tensorflow.keras.models import Sequential, Model, load_model, Sequential, save_model\n","from tensorflow. keras.layers import Dense, Activation, Dropout, Input,  TimeDistributed, GRU, Masking, LSTM\n","from tensorflow.keras.utils import to_categorical\n","\n","\n","# ~~~~~~~ DATA WRANGLING FUNCTIONS ~~~~~~~\n","def get_gesture_times(data_df):\n","    \"\"\"\n","    Get start times, end times, and event labels of each block of time with a given label\n","    \n","    Args:\n","        data_df: dataframe with columns for 'class' and 'time' \n","            \n","    Returns:\n","        start times, end times, and event labels: 1-d numpy arrays \n","        \n","    \"\"\"\n","\n","    #get start indices of each condition \n","    \n","    #taking advantage that every gesture is preceded by a period with 'undefined' class label (value 0)\n","    start_idxs = np.hstack([0,np.where(np.abs(np.diff(data_df['class']))>0)[0]+1])\n","    \n","    #end indices correspond to just before the start of the next condition\n","    end_idxs = np.hstack((start_idxs[1:]-1,data_df.time.size-1))\n","    \n","\n","    #create arrays with start times and class labels for each hand gesture\n","    start_times = data_df.time[start_idxs].values\n","    end_times = data_df.time[end_idxs].values\n","    event_labels = data_df['class'][start_idxs].values\n","    \n","    return start_times, end_times, event_labels\n","\n","def get_steady_samp_rate_data(data_df):\n","    \n","    \"\"\"\n","    Resample time series data for a steady sampling rate by performing linear interpolation\n","    between missing samples\n","    \n","    Args:\n","        data_df: dataframe with a 'time' column and timeseries of interest on other columns\n","            \n","    Returns:\n","        data_df: dataframe with interpolated \n","    \"\"\"\n","    \n","    #retrieve time value\n","    time = data_df.time.values\n","    #define time points on which we want to interpolate (i.e., a sample every ms)\n","    time_new = np.arange(time[0],time[-1]+1,1)\n","    \n","    #create separate dataframe with new time points and set these as index\n","    steady_time_df = pd.DataFrame({'time_constant':time_new})\n","    steady_time_df = steady_time_df.set_index('time_constant')\n","    \n","    #set time coulumn of original dataframe to index\n","    data_df = data_df.set_index('time')\n","\n","    #perform a right join with the steady time dataframe then linearly interpolate missing values\n","    data_df = data_df.join(steady_time_df, how = 'right')\n","    data_df = data_df.interpolate().reset_index().rename(columns={'time_constant':'time'})\n","    \n","    return data_df\n","\n","def butter_bandpass_filter(input_signal, lowcut, highcut, fs, order=4, axis = -1):\n","    #lowcut = lower bound of desired freq band\n","    #hicut = upperbound bound of desired freq band\n","    #fs = sampling rate\n","    #order = order of filter\n","    #axis = axis of data matrix on which to apply filters\n","\n","    low = float(lowcut)# / nyq\n","    high = float(highcut)# / nyq\n","    b, a = scipy.signal.butter(order, [low, high],fs = fs, btype='band')\n","    \n","    output_signal = scipy.signal.filtfilt(b, a, input_signal,axis = axis)\n","    \n","    return output_signal\n","    \n","def get_window_features(signal):\n","    #signal: EMG signal matrix with dims time x channels\n","    #return: Mean Absolute Value and Wavelength features for each channel\n","\n","    MAV = np.mean(np.absolute(signal),axis = 0) #Mean Absolute Value\n","\n","    WL = np.sum(np.absolute(np.diff(signal,axis = 0)),axis = 0) #Wavelength\n","    \n","    return MAV, WL\n","\n","def window_and_get_features(parsed_df,win_size,step):\n","    \"\"\"\n","    Compute features (Mean Absolute Value and Wavelength) for time series segments with given length \n","    and amount of overlap\n","    \n","    Args:\n","        parsed_df: dataframe containing timeseries data for each block. expects a 'Block' column\n","        and the channel data in the first columns of dataframe\n","        \n","            \n","    Returns:\n","        feat_matrix: 2D numpy array of size [number of segments, number of channels * number of features]\n","        target_labels: 1D numpy array with class label for each segment\n","        window_tstamps: 1D numpy array with timestamp for each timeseries segment used to compute features\n","        block_labels: 1D numpy array indicating block provenance of each segment (useful for RNN data prep)\n","    \"\"\"\n","    #set empty lists\n","    feat_matrix = []\n","    target_labels = []\n","    window_tstamps = []\n","    block_labels = []\n","\n","    #get number of channels\n","    nchannels = np.sum(['Channel' in col_name for col_name in parsed_df.columns])\n","\n","    for block in parsed_df.Block.unique():\n","        #get relevant subset of dataframe\n","        block_df = parsed_df.loc[parsed_df.Block == block]\n","\n","        #extract relevant info\n","        block_data_matrix = block_df.iloc[:,0:8].values\n","        block_class = block_df['Class'][0]\n","        tstamps = block_df['Time'].values\n","\n","        #compute desired features over segments of the data\n","        for win_start_idx in range(0, block_df.shape[0], step):\n","            win_end_idx = win_start_idx + win_size\n","            if win_end_idx< block_df.shape[0]: #exclude window if not enough timepoints before end of block\n","\n","                #compute features within this segment\n","                MAV, WL = get_window_features(block_data_matrix[win_start_idx:win_end_idx,:])\n","\n","                #append info to matrices\n","                feat_matrix.append(np.hstack((MAV,WL)))\n","                target_labels.append(block_class)\n","                window_tstamps.append(np.mean([tstamps[win_start_idx],tstamps[win_end_idx]]))\n","                block_labels.append(block)\n","                \n","    return np.array(feat_matrix), np.array(target_labels), np.array(window_tstamps), np.array(block_labels)\n","\n","\n","\n","\n","\n","def parse_data_blocks(start_times, end_times, event_labels, data_matrix, tstamps, pre_tpts = 0, exclude_class=[]):\n","    \"\"\"\n","    Function to parse timeseries into blocks corresponding to each event. \n","    Returns a dataframe - seemed most convenient given variable length of event blocks\n","    \n","    Args:\n","        start_times: 1D numpy array with start times of event blocks\n","        end_times: 1D numpy array with start times of event blocks\n","        event_labels: 1D numpy array with start times of event blocks\n","        data_matrix: 2D numpy array with of dimension [ntimepoints, nchannels] containing signal values\n","        pre_tpts: how many timepoints before event onset to include(int)\n","        exclude_class: list with class labels to exclude in parsing blocks\n","            \n","    Returns:\n","        parsed_df: dataframe with parsed data\n","        block_length: 1D numpy array with timepoints in each event block\n","    \"\"\"\n","    \n","    parsed_df = []\n","\n","    #note characterisitcs of matrix\n","    ntpts, nchannels = data_matrix.shape\n","\n","    parsed_df = []\n","    block_lengths = []\n","    for block,c in enumerate(event_labels):\n","        if c not in exclude_class:\n","            # get relevant indives to get dara from matrix\n","            start_idx = np.where(tstamps>start_times[block])[0][0]\n","            end_idx = np.where(tstamps>=end_times[block])[0][0]\n","\n","            # append block length to list\n","            block_lengths.append(end_idx-start_idx)\n","\n","            # get timestamps relative to event onset\n","            t_ase = np.arange(-pre_tpts,end_idx-start_idx)\n","\n","            # put data matrix values into a dataframe\n","            block_df = pd.DataFrame(data_matrix[start_idx-pre_tpts:end_idx,:], columns = ['Channel_%i'%(c+1) for c in range(nchannels)])\n","\n","            # add relevant value columns\n","            block_df['Block'] = block\n","            block_df['Class'] = c \n","            block_df['Time_ASE'] = t_ase\n","            block_df['Time'] = np.arange(tstamps[start_idx]-pre_tpts,tstamps[end_idx])\n","\n","            #append to collecting datafram\n","            parsed_df.append(block_df)\n","\n","    #merge all dataframes together\n","    parsed_df = pd.concat(parsed_df,axis = 0)\n","    \n","    return parsed_df, block_lengths\n","\n","def get_file_data_for_classification(data_fn, lo_freq, hi_freq, win_size, step, remove_file_mean = True):\n","    \"\"\"\n","    Get the relevant info for classification from indicated file\n","    \n","    Args:\n","        data_fn: filename\n","        lo_freq: lower bound of bandpass filter\n","        hi_freq: higher bound of bandpass filter\n","        win_size: length of segment over which to compute features\n","        step: amount of overlap between neighboring segments\n","        remove_file_mean: Boolean indicating removal of mean value for each channel in the series\n","            \n","    Returns:\n","        feature_matrix: 2D numpy array of size [number of segments, number of channels * number of features]\n","        target_labels: 1D numpy array with class label for each segment\n","        window_tstamps: 1D numpy array with timestamp for each timeseries segment used to compute features\n","        block_labels: 1D numpy array indicating block provenance of each segment (useful for RNN data prep)\n","    \"\"\"\n","    \n","    # load file\n","    data_df = pd.DataFrame(pd.read_csv(data_fn, sep='\\t'))\n","    \n","    # retrieve start times, end times, and labels for each condition block (will make it easier to parse traces later)\n","    start_times, end_times, event_labels  = get_gesture_times(data_df)\n","\n","    # interpolate data to steady frame rate\n","    data_df = get_steady_samp_rate_data(data_df)\n","    samp_period = np.diff(data_df.time)[0]/1000.0\n","    samp_rate = 1/samp_period\n","    \n","    # Unpack values into numpy arrays\n","    data_matrix = data_df.iloc[:,1:-1].values\n","    class_labels = data_df.iloc[:,-1].values\n","    tstamps = data_df.time.values\n","    \n","    #remove series offset for each channel, if indicated\n","    if remove_file_mean:\n","        data_matrix = data_matrix- np.mean(data_matrix,0)\n","\n","    # filter data\n","    filt_data_matrix = butter_bandpass_filter(data_matrix, lo_freq, hi_freq, samp_rate,axis = 0)\n","\n","    # parse timeseries into block corresponding to different blocks of time\n","    parsed_df, block_lengths = parse_data_blocks(start_times,end_times,event_labels,filt_data_matrix, tstamps,\n","                                                 pre_tpts = 0, exclude_class=[])\n","\n","    # compute desired features over individual time segments\n","    feature_matrix, target_labels, window_tstamps, block_labels = window_and_get_features(parsed_df,win_size,step)\n","    \n","    return feature_matrix, target_labels, window_tstamps, block_labels\n","\n","\n","def get_subject_data_for_classification(data_folder, lo_freq, hi_freq, win_size, step):\n","    \"\"\"\n","    Get the relevant info for classification from indicated file\n","    \n","    Args:\n","        data_fn: filename\n","        lo_freq: lower bound of bandpass filter\n","        hi_freq: higher bound of bandpass filter\n","        win_size: length of segment over which to compute features\n","        step: amount of overlap between neighboring segments\n","            \n","    Returns:\n","        feature_matrix: 2D numpy array of size [number of segments, number of channels * number of features]\n","        target_labels: 1D numpy array with class label for each segment\n","        window_tstamps: 1D numpy array with timestamp for each timeseries segment used to compute features\n","        block_labels: 1D numpy array indicating block provenance of each segment (useful for RNN data prep)\n","        series_labels: 1D numpy array indicating block provenance of each segment (useful for visualization)\n","    \"\"\"\n","    \n","    #find files in subject folder\n","    file_list = [f for f in os.listdir(data_folder) if os.path.isfile(os.path.join(data_folder, f))]\n","\n","\n","    #initialize empty matrices\n","    feature_matrix = np.empty((0,0))\n","    target_labels = np.empty((0,))\n","    window_tstamps = np.empty((0,))\n","    block_labels = np.empty((0,))\n","    series_labels = np.empty((0,))\n","    max_block_id = 0\n","\n","    for series_id,file in enumerate(file_list):\n","\n","        #get relevant info from each file\n","        feature_matrix_sub, target_labels_sub,\\\n","        window_tstamps_sub, block_labels_sub = get_file_data_for_classification(os.path.join(data_folder,file),\\\n","                                                                                 lo_freq, hi_freq, win_size, step)\n","        nsamples,nfeats = feature_matrix_sub.shape\n","\n","        #offset block labels\n","        block_labels_sub = block_labels_sub+max_block_id\n","        max_block_id = np.max(block_labels_sub)#update\n","\n","        series_labels_sub = np.ones((nsamples,))*series_id#make array with series ID of samples\n","\n","        #append file samples\n","        feature_matrix = np.vstack((feature_matrix,feature_matrix_sub)) if feature_matrix.size else feature_matrix_sub\n","        target_labels = np.hstack((target_labels,target_labels_sub))\n","        window_tstamps = np.hstack((window_tstamps,window_tstamps_sub))\n","        block_labels = np.hstack((block_labels,block_labels_sub))\n","        series_labels = np.hstack((series_labels,series_labels_sub))\n","        \n","    return feature_matrix, target_labels, window_tstamps, block_labels, series_labels\n","\n","\n","def get_data_cube(X, window_blocks, train = True, scaler = None, magic_value = -100):\n","    \"\"\"\n","    Create data cube for use with Keras RNN. Standardize data then pad and reshape data to have\n","    [samples, timesteps, features] dimensions with an equal number of timesteps for each slice\n","    I use a Masking layer in the RNN architecture to allow for sequences of different length\n","    \n","    Args:\n","        X: 2D nuumpy array with data, dimensions [features, samples]\n","        window_blocks: 1D numpy array indicating block of provenance for input segment values\n","        train: Boolean indicating whether the input data is training data\n","        scaler: StandardScaler to transform data\n","        magic_value: integer indicating value with which to pad samples\n","            \n","    Returns:\n","        X_cube: 3D numpy array of size [samples, timesteps, features]\n","        scaler: 1D numpy array with class label for each segment\n","    \"\"\"\n","    #standardize across each feature dimension\n","    if train:\n","        scaler = StandardScaler()\n","        scaler = scaler.fit(X.T)\n","        X = scaler.transform(X.T).T\n","    else:\n","        #for testing data, we want to use same transform as was fit to training data\n","        X = scaler.transform(X.T).T\n","        \n","    # common number of time steps\n","    common_timesteps = np.max(np.bincount(window_blocks.astype('int')))\n","    \n","    # get each block, pad, and stack to form a data cube\n","    X_cube = []\n","    for b_count, b_idx in enumerate(np.unique(window_blocks)):\n","       #slice\n","        X_slice = X[:,np.where(window_blocks==b_idx)[0]]\n","        #pad\n","        pad_size = common_timesteps-X_slice.shape[1]\n","        X_slice_pad = np.pad(X_slice,pad_width=((0,0),(0,pad_size)), mode='constant', constant_values= magic_value)\n","        #stack\n","        if b_count == 0:\n","            X_cube  = X_slice_pad\n","        else:\n","            X_cube = np.dstack((X_cube,X_slice_pad))\n","\n","    # swap dimension to get [samples, timesteps, features]\n","    X_cube = np.swapaxes(X_cube,0,2)\n","    \n","    return X_cube, scaler\n","\n","#~~~~~ VISUALIZATION FUNCTIONS ~~~~~~\n","\n","def plot_sensor_values(data_fn, x_limits = []):\n","    \"\"\"\n","    Plot signal timecourse for all channels using data in indicated file\n","    \n","    Args:\n","        data_fn: filename\n","        x_limits: minimum and maximum limits for x-axis (useful to looking at specific sections)\n"," \n","    Returns:\n","        fig: figure handle\n","    \"\"\"\n","\n","    # load file\n","    data_df = pd.DataFrame(pd.read_csv(data_fn, sep='\\t'))\n","\n","    # retrieve start times, end times, and labels for each condition block (will make it easier to parse traces later)\n","    start_times, end_times, event_labels  = get_gesture_times(data_df)\n","\n","    # interpolate data to steady frame rate\n","    data_df = get_steady_samp_rate_data(data_df)\n","\n","    # Unpack values into numpy arrays\n","    data_matrix = data_df.iloc[:,1:-1].values\n","    class_labels = data_df.iloc[:,-1].values\n","    tstamps = data_df.time.values\n","\n","    # define color palette\n","    palette = sns.color_palette('deep',8)\n","\n","    # define class legend\n","    labels = []\n","    custom_lines = []\n","\n","    classes = np.unique(event_labels)[1:]#exclude 'unmarked' label\n","    for c in classes.astype('int'):\n","        labels.append('Class %i'%(c))\n","        custom_lines.append(Line2D([0], [0], color=palette[c-1], lw=4))\n","\n","    #make figure\n","    nrows = 8\n","    ncols = 1\n","\n","    fig,ax = plt.subplots(nrows,ncols,figsize=(15,30),sharex = True)\n","\n","    #plot each channel\n","    for ch in range(8):\n","        ax[ch//ncols].plot(tstamps,data_matrix[:,ch]);\n","        ax[ch//ncols].axhline(y = 0, xmin = 0, xmax = 1, color = 'k', linestyle = '--', alpha = 0.5)\n","        #label subplot\n","        ax[ch//ncols].set_title('Channel %i'%(ch+1))\n","\n","        #mark events\n","        ymin,ymax = ax[ch//ncols].get_ylim()\n","        for idx,c in enumerate(event_labels):\n","            if c>0:#eclude 'unmarked label'\n","                ax[ch//ncols].hlines(y = ymax + .001, xmin = start_times[idx], xmax = end_times[idx], color = palette[int(c-1)],linewidth = 10)\n","\n","        if len(x_limits):\n","            ax[ch//ncols].set_xlim(x_limits)\n","\n","\n","    #set legend with events\n","    ax[0].legend(custom_lines, labels,bbox_to_anchor=(1, 1), loc='upper left', ncol=1)\n","\n","\n","    #label axes\n","    ax[0].set_ylabel('Sensor Voltage')\n","    ax[ch].set_xlabel('Time (ms)')\n","\n","    #despine\n","    sns.despine(fig= plt.gcf(), left = False, right = True, top = True, bottom = True)\n","\n","\n","    fig.tight_layout() \n","\n","    return fig\n","\n","def plot_signal_pspec(data_fn):\n","    \"\"\"\n","    Plot power spectrum of signal for each channel using data in datafile indicated\n","    \n","    Args:\n","        data_fn: filename\n"," \n","    Returns:\n","        fig: figure handle\n","    \"\"\"\n","\n","    # load file\n","    data_df = pd.DataFrame(pd.read_csv(data_fn, sep='\\t'))\n","\n","    # retrieve start times, end times, and labels for each condition block (will make it easier to parse traces later)\n","    start_times, end_times, event_labels  = get_gesture_times(data_df)\n","\n","    # interpolate data to steady sampling rate\n","    data_df = get_steady_samp_rate_data(data_df)\n","    samp_period = np.diff(data_df.time)[0]/1000.0\n","    samp_rate = 1/samp_period\n","\n","    # Unpack values into numpy arrays\n","    data_matrix = data_df.iloc[:,1:-1].values\n","    class_labels = data_df.iloc[:,-1].values\n","    tstamps = data_df.time.values\n","\n","    #Calculate the Welch's PSD of the data - yields a smoother, more informative, spectrum \n","    f,pspec = scipy.signal.welch(data_matrix, fs=samp_rate, window='hanning', nperseg=2*samp_rate, noverlap=samp_rate/2,\n","                              nfft=None, detrend='linear', return_onesided=True, scaling='density',axis = 0)\n","\n","    #make figure\n","    nrows = 4\n","    ncols = 2\n","    fig,ax = plt.subplots(nrows,ncols,figsize=(16,10),sharey = True, sharex = True)\n","\n","    for ch in range(data_matrix.shape[1]):\n","        ax[ch//ncols][ch%ncols].loglog(f[1:200*2],pspec[1:200*2,ch])#line noise will be obvious under 100 Hz\n","        #label subplot\n","\n","        ax[ch//ncols][ch%ncols].set_title('Channel %i'%(ch+1))\n","    #label axes\n","    ax[0][0].set_ylabel('Power')\n","    ax[ch//ncols][0].set_xlabel('Frequency')\n","\n","    #despine\n","    sns.despine(fig= plt.gcf(), left = False, right = True, top = True, bottom = False)\n","\n","    fig.tight_layout() \n","\n","    return fig\n","\n","def visualize_time_series_prob(data_folder, prob_class, times, series_labels):\n","    \"\"\"\n","    Visualize probability of each class across time for individual files\n","    \n","    Args:\n","        data_folder: folder with subject data\n","        prob_class: array with probability of each class for each sample\n","        times: array with timestamps for each signal segment\n","        series: array with file of provenance for each singla segment\n","            \n","    Returns:\n","        figure\n","    \"\"\"\n","\n","    #find files in subject folder\n","    file_list = [f for f in os.listdir(data_folder) if os.path.isfile(os.path.join(data_folder, f))]\n","\n","    for file_idx in range(len(file_list)):\n","\n","        # load file\n","        data_df = pd.DataFrame(pd.read_csv(os.path.join(data_folder,file_list[file_idx]), sep='\\t'))\n","\n","        # retrieve start times, end times, and labels for each condition block (will make it easier to parse traces later)\n","        start_times, end_times, event_labels  = get_gesture_times(data_df)\n","\n","        series_idxs = np.where(series_labels==file_idx)[0]\n","\n","        prob_series = prob_class[series_idxs,:]\n","        time_series = times[series_idxs]\n","\n","        classes = np.unique(event_labels)[1:]#exclude 'unmarked' label\n","        labels = []\n","        for c in classes.astype('int'):\n","            labels.append('Class %i'%(c))\n","\n","        # define color palette\n","        palette = sns.color_palette('deep',8)[1:]\n","\n","        plt.figure(figsize=(15,6))\n","        plt.gca().set_prop_cycle(plt.cycler('color',palette))\n","        plt.plot(time_series,prob_series, linewidth = 2);\n","\n","        #mark events\n","        for idx,c in enumerate(event_labels):\n","            if c>0:\n","                plt.hlines(y = 1.1, xmin = start_times[idx], xmax = end_times[idx], color = palette[c-1],linewidth = 10)\n","\n","        #label axes\n","        plt.ylabel('Class Probability')\n","        plt.xlabel('Time (ms)')\n","\n","        plt.legend(labels, bbox_to_anchor=(1, 1), loc='upper left', ncol=1)\n","\n","        sns.despine(fig= plt.gcf(), left = False, right = True, top = True, bottom = False)\n","\n","        plt.gcf().tight_layout() \n","\n","        plt.gcf().suptitle('%s'%(file_list[file_idx]), y= 1.05)\n","\n","    return plt.gcf()\n","\n","def dim_reduction_visualization(X, target_labels):\n","    \"\"\"\n","    Perform dimensionality reduction with tSNE and visualize results.\n","    \n","    Args:\n","        X: 2D numpy array with data [samples, features]\n","        target_labels: array. used to color points in embedded space\n"," \n","    Returns:\n","        fig: figure handle\n","    \"\"\"\n","    \n","    #make pipeline\n","    tsne_pipe = make_pipeline(StandardScaler(),#standardize\n","                              TSNE(n_components=2, perplexity = 50))\n","    #perform embedding\n","    X_embedded = tsne_pipe.fit_transform(X)\n","    \n","    # visualize\n","    palette = sns.color_palette('deep',8)\n","\n","    # define class legend\n","    labels = []\n","    custom_lines = []\n","\n","    classes = np.unique(target_labels)#exclude 'unmarked' label\n","    for c in classes.astype('int'):\n","        labels.append('Class %i'%(c))\n","        custom_lines.append(Line2D([0], [0], color=palette[c], lw=4))\n","\n","    sns.set_context('paper',font_scale = 2)\n","    fig,ax = plt.subplots(1,1,figsize=(8,8))\n","    \n","    #plot\n","    for s in range(X_embedded.shape[0]):\n","        ax.scatter(X_embedded[s,0],X_embedded[s,1],\\\n","                        color = palette[int(target_labels[s])],s = 100,linewidth = 2,alpha = 0.8)\n","    ax.axhline(y=0 ,xmin = 0,xmax = 1,color = 'k',linestyle = '--')    \n","    ax.axvline(x=0 ,ymin = 0,ymax = 1,color = 'k',linestyle = '--') \n","    #add legend\n","    ax.legend(custom_lines, labels,bbox_to_anchor=(1, 1), loc='upper left', ncol=1)\n","    #label\n","    ax.set_xlabel('Dimension 1')\n","    ax.set_ylabel('Dimension 2')\n","    sns.despine(trim=False, offset=0, bottom=False,top = True, left=False, ax=ax)\n","    \n","    return fig\n","    \n","\n","# ~~~~~~~~ LOGISTIC REGRESSION FUNCTIONS ~~~~~~~~\n","\n","def log_reg_on_all_data(X, Y, nsplits, penalty = 'none', multiclass = 'multinomial',permute = False):\n","    \"\"\"\n","    Train and evaluate a classifier based on logistic regression using all available classes in data\n","    \n","    Args:\n","        X: 2D numpy array with shape [samples, features]\n","        Y: array with class label for each sample\n","        nsplits: number of splits for K-fold cross-validation\n","        permute: Boolean to shuffle class labels (useful to test performance under null hypothesis) \n","        -parameters for logistic regression\n","        penalty: type of penalty for classifier\n","        multiclass: approach for multiclass classification\n","            \n","    Returns:\n","        train_f1_scores: training scores for each split\n","        test_f1_scores: test scores for each split\n","        prob_class: 2D numpy array with probabiliy of each class for each sample\n","    \"\"\"\n","    \n","    #retrieve some values from input\n","    nclass = np.unique(Y).size\n","    nsamples, nfeat = X.shape\n","    \n","    #initialize empty arrays\n","    test_f1_scores =  np.empty((nsplits,))\n","    train_f1_scores =  np.empty((nsplits,))\n","    prob_class = np.empty((nsamples,nclass))\n","    \n","    #permute class labels, if indicated\n","    if permute:\n","        Y = np.random.permutation(Y)\n","    \n","    \n","    #stratify split to retain ratio of class labels\n","    skf = StratifiedKFold(n_splits=nsplits,shuffle = True)\n","\n","\n","    #systematically use one fold of the data as a held-out test set\n","    for split_count, (train_index, test_index) in enumerate(skf.split(X, Y)):\n","\n","        trainX = X[train_index,:]\n","        testX = X[test_index,:]\n","\n","        trainY = Y[train_index]\n","        testY = Y[test_index]\n","\n","        #define model\n","        #note LogisticRegressionCV uses StratifiedKFold by default in cross-validation\n","        model = make_pipeline(StandardScaler(),\\\n","                              LogisticRegression(penalty = penalty, multi_class = multiclass ,max_iter = 10000))\n","        #fit model\n","        model.fit(trainX, trainY)\n","\n","        #predict labels on train set\n","        ypred = model.predict(trainX)\n","        #get F1 score\n","        train_f1_scores[split_count] = f1_score(trainY,ypred,average = 'macro')\n","\n","        #predict labels on test set\n","        ypred = model.predict(testX)\n","        #get F1 score\n","        test_f1_scores[split_count] = f1_score(testY,ypred,average = 'macro')\n","\n","\n","        #get prediction probabiliity on test set samples\n","        pred_prob = model.predict_proba(testX)\n","        prob_class[test_index,:] = pred_prob \n","\n","    return train_f1_scores, test_f1_scores, prob_class\n","\n","def log_reg_on_labeled_data(X, Y, times, series, nsplits, unmarked = 0,penalty = 'none', multiclass = 'multinomial',permute = False):\n","    \"\"\"\n","    Train and evaluate a classifier based on logistic regression using all available classes in data\n","    \n","    Args:\n","        X: 2D numpy array with shape [samples, features]\n","        Y: array with class label for each sample\n","        times: array with timestamps for each signal segment\n","        series: array with file of provenance for each singla segment\n","        nsplits: number of splits for K-fold cross-validation\n","        exclude_label: label to eclude\n","        permute: Boolean to shuffle class labels (useful to test performance under null hypothesis) \n","        -parameters for logistic regression\n","        penalty: type of penalty for classifier\n","        multiclass: approach for multiclass classification\n","            \n","    Returns:\n","        train_f1_scores: training scores for each split\n","        test_f1_scores: test scores for each split\n","        prob_class: 2D numpy array with probabiliy of each class for each sample\n","    \"\"\"\n","    \n","    #change timestamps so that there's no overlapping timestamps across series\n","    times_abs = np.empty((0,))\n","    max_time = 0\n","    for s in np.unique(series):\n","        series_idxs = np.where(series==s)[0]\n","        times_abs = np.hstack((times_abs,times[series_idxs]+max_time))\n","        max_time = np.max(times_abs)\n","\n","    #select \n","    in_samples = np.where(Y != unmarked)[0]\n","    out_samples = np.where(Y == unmarked)[0]\n","    X_in = X[in_samples,:]\n","    Y_in = Y[in_samples]\n","    X_out = X[out_samples,:]\n","    times_in = times_abs[in_samples]\n","    times_out = times_abs[out_samples]\n","    \n","    #retrieve some values from input\n","    nclass = np.unique(Y_in).size\n","    nsamples, nfeat = X_in.shape\n","    \n","    #initialize empty arrays\n","    test_f1_scores =  np.empty((nsplits,))\n","    train_f1_scores =  np.empty((nsplits,))\n","    prob_class_in = np.empty((nsamples,nclass))\n","    prob_class_out = np.empty((nsplits,out_samples.size,nclass))\n","    \n","    #permute class labels, if indicated\n","    if permute:\n","        Y_in = np.random.permutation(Y_in)\n","    \n","    \n","    #stratify split to retain ratio of class labels\n","    skf = StratifiedKFold(n_splits=nsplits,shuffle = True)\n","\n","\n","    #systematically use one fold of the data as a held-out test set\n","    for split_count, (train_index, test_index) in enumerate(skf.split(X_in, Y_in)):\n","\n","        trainX = X_in[train_index,:]\n","        testX = X_in[test_index,:]\n","\n","        trainY = Y_in[train_index]\n","        testY = Y_in[test_index]\n","\n","        #define model\n","        #note LogisticRegressionCV uses StratifiedKFold by default in cross-validation\n","        model = make_pipeline(StandardScaler(),\\\n","                              LogisticRegression(penalty = penalty, multi_class = multiclass ,max_iter = 10000))\n","        #fit model\n","        model.fit(trainX, trainY)\n","\n","        #predict labels on train set\n","        ypred = model.predict(trainX)\n","        #get F1 score (weighted to account for slight class imbalance)\n","        train_f1_scores[split_count] = f1_score(trainY,ypred,average = 'weighted')\n","\n","        #predict labels on test set\n","        ypred = model.predict(testX)\n","        #get F1 score (weighted to account for slight class imbalance)\n","        test_f1_scores[split_count] = f1_score(testY,ypred,average = 'weighted')\n","\n","\n","        #get prediction probabiliity on test set samples\n","        pred_prob = model.predict_proba(testX)\n","        prob_class_in[test_index,:] = pred_prob \n","        \n","        #get prediction probability on 'unmarked' samples\n","        pred_prob = model.predict_proba(X_out)\n","        prob_class_out[split_count,:,:] = pred_prob\n","    \n","    #get probability of each class over time\n","    # average over multiple splits\n","    prob_class_out = np.mean(prob_class_out,0)\n","    \n","    #concatenate and sort, using window timestamps as a guide\n","    T_all = np.hstack((times_in,times_out))\n","    prob_class = np.vstack((prob_class_in,prob_class_out))\n","    sort_idxs = np.argsort(T_all)\n","    prob_class = prob_class[sort_idxs,:]\n","    \n","    return train_f1_scores, test_f1_scores, prob_class\n","\n","# ~~~~~~~~ RNN CLASSIFIER FUNCTIONS ~~~~~~~~\n","def get_data_cube(X, Y, window_blocks, train = True, scaler = None, magic_value = -100):\n","    \"\"\"\n","    Create data cube for use with Keras RNN. Standardize data then pad and reshape data to have\n","    [samples, timesteps, features] dimensions with an equal number of timesteps for each slice\n","    I use a Masking layer in the RNN architecture to allow for sequences of different length\n","    \n","    Args:\n","        X: 2D nuumpy array with data, dimensions [features, samples]\n","        window_blocks: 1D numpy array indicating block of provenance for input segment values\n","        train: Boolean indicating whether the input data is training data\n","        scaler: StandardScaler to transform data\n","        magic_value: integer indicating value with which to pad samples\n","            \n","    Returns:\n","        X_cube: 3D numpy array of size [samples, timesteps, features]\n","        scaler: 1D numpy array with class label for each segment\n","    \"\"\"\n","    #standardize across each feature dimension\n","    if train:\n","        scaler = StandardScaler()\n","        scaler = scaler.fit(X.T)\n","        X = scaler.transform(X.T).T\n","    else:\n","        #for testing data, we want to use same transform as was fit to training data\n","        X = scaler.transform(X.T).T\n","\n","    # common number of time steps\n","    common_timesteps = np.max(np.bincount(window_blocks.astype('int')))\n","    \n","    # get each block, pad, and stack to form a data cube\n","    X_cube = []\n","    Y_cube = []\n","    for b_count, b_idx in enumerate(np.unique(window_blocks)):\n","       #slice\n","        X_slice = X[:,np.where(window_blocks==b_idx)[0]]\n","        Y_slice = Y[np.where(window_blocks==b_idx)[0],:].T\n","        #pad - can just use keras padding function\n","        pad_size = common_timesteps-X_slice.shape[1]\n","        X_slice_pad = np.pad(X_slice,pad_width=((0,0),(0,pad_size)), mode='constant', constant_values= magic_value)\n","        Y_slice_pad = np.pad(Y_slice,pad_width=((0,0),(0,pad_size)), mode='constant', constant_values= 0)\n","        #stack\n","        if b_count == 0:\n","            X_cube  = X_slice_pad\n","            Y_cube = Y_slice_pad\n","        else:\n","            X_cube = np.dstack((X_cube,X_slice_pad))\n","            Y_cube = np.dstack((Y_cube,Y_slice_pad))\n","    # swap dimension to get [samples, timesteps, features]\n","    X_cube = np.swapaxes(X_cube,0,2)\n","    Y_cube = np.swapaxes(Y_cube,0,2)\n","    \n","    return X_cube, Y_cube, scaler\n","\n","def many_to_many_model(input_shape, n_outputs, mask_value = -100):\n","    \"\"\"\n","    Create simple RNN model\n","    \n","    Args:\n","        input_shape\n","        n_outputs: number of output classes\n","        mask_value: value indicating which timepoints to mask out\n","            \n","    Returns:\n","        model\n","    \"\"\"\n","    \n","    #define model architecture\n","    X_input = Input(shape = input_shape)\n","    X = Masking(mask_value=mask_value)(X_input)\n","    X = GRU(24, return_sequences= True, stateful = False)(X)\n","    X = Dropout(0.5)(X)\n","    X = TimeDistributed(Dense(n_outputs,activation = 'softmax'))(X)\n","    model = Model(inputs = X_input, outputs = X)\n","    return model\n","\n","def get_RNN_f1(X, Y, model, average = 'weighted', mask_value = -100):\n","    \"\"\"\n","    Get f1 score for an RNN model using masked timepoint data\n","\n","    Args:\n","        X: 3D numpy array with shape [samples, timepoints, features]\n","        Y: 3D numpy array with shape [samples, timepoints, classes]. one-hot coding of classes\n","        model: RNN model object\n","        average: string argument for f1_score function. Usually 'macro' or 'weighted'\n","        mask_value: value indicating which timepoints to mask out\n","\n","    Returns:\n","        f1: f1 score\n","    \"\"\"\n","    # Mask out indices based on mask value\n","    nonmasked_idxs = np.where(X[:,:,0].flatten()!=mask_value)[0]\n","    # Get target labels for non-masked timepoints\n","    y_true = np.argmax(Y,2).flatten()[nonmasked_idxs]\n","    # Get model predictions for non-masked timepoints\n","    preds = model.predict(X)\n","    y_pred = np.argmax(preds,2).flatten()[nonmasked_idxs]\n","    # Get F1 score\n","    f1 = f1_score(y_true,y_pred,average = average)\n","\n","    return f1\n","\n","def RNN_on_labeled_data(feature_matrix, target_labels, window_tstamps, block_labels, n_splits = 4,\\\n","                       verbose = 0, epochs = 40, batch_size = 2, permute = False):\n","    \"\"\"\n","    Train and evaluate RNN model on labeled data\n","    \n","    Args:\n","        feature_matrix: 2D nuumpy array with data, dimensions [features, samples]\n","        window_blocks: 1D numpy array indicating block of provenance for input segment values\n","        train: Boolean indicating whether the input data is training data\n","        scaler: StandardScaler to transform data\n","        magic_value: integer indicating value with which to pad samples\n","            \n","    Returns:\n","        train_f1_scores: training scores for each split\n","        test_f1_scores: test scores for each split\n","\n","\n","    \"\"\"\n","    \n","    # transpose data\n","    #feature_matrix = feature_matrix.T\n","    \n","    #initialize empty array\n","    train_f1_scores = np.empty((n_splits,))\n","    test_f1_scores = np.empty((n_splits,))\n","\n","\n","    #get block_ids and corresponding classes in block. there are the units over which we will do train/test split\n","    blocks = np.array([k for k,g in groupby(block_labels)])\n","    classes = np.array([k for k,g in groupby(target_labels) if k!=0])\n","    \n","    #permute class labels, if indicated\n","    if permute:\n","        #using indexing tricks to have this work out\n","        classes_perm = np.random.permutation(classes)\n","        target_labels_shuffled = np.empty((0,))\n","        for i,b in enumerate(blocks):\n","            idxs = np.where(block_labels==b)[0]\n","            target_labels_shuffled = np.hstack((target_labels_shuffled,classes_perm[i]*np.ones((idxs.size,))))\n","        target_labels = target_labels_shuffled\n","        classes = classes_perm\n","     \n","    \n","    #stratify split to retain ratio of class labels\n","    skf = StratifiedKFold(n_splits=n_splits,shuffle = True)\n","    print(block_labels.shape)\n","    print(target_labels.shape)\n","    print(blocks.shape,classes.shape)\n","\n","    #systematically use one fold of the data as a held-out test set\n","    for split_count, (blocks_train_idxs, blocks_test_idxs) in enumerate(skf.split(blocks, classes)):\n","        print('Split Count: %i'% (split_count+1))\n","\n","        #get train and test indices\n","        blocks_train = blocks[blocks_train_idxs]\n","        blocks_test = blocks[blocks_test_idxs]\n","        train_idxs =np.where(np.isin(block_labels,blocks_train))[0]\n","        test_idxs =np.where(np.isin(block_labels,blocks_test))[0]\n","\n","        # select training data and pad to get an array where each sample has same number of timesteps\n","        X_train = feature_matrix[:,train_idxs]\n","        y_train = target_labels[train_idxs]\n","        #one-hot encoding of class labels\n","        y_train = to_categorical(y_train-np.min(y_train))\n","        #get block labels of given samples\n","        win_blocks_train = block_labels[train_idxs]\n","\n","        #get cube\n","        X_train_cube, Y_train_cube, scaler = get_data_cube(X_train, y_train,win_blocks_train, train = True, magic_value = -100)\n","        print(X_train_cube.shape, Y_train_cube.shape)\n","\n","        # select test data and pad to get an array where each sample has same number of timesteps\n","        X_test = feature_matrix[:,test_idxs]\n","        y_test = target_labels[test_idxs]\n","        #one-hot encoding of class labels\n","        y_test = to_categorical(y_test-np.min(y_test))\n","        #get block labels of given samples\n","        win_blocks_test = block_labels[test_idxs]\n","        #get data cube\n","        X_test_cube, Y_test_cube, scaler = get_data_cube(X_test, y_test, win_blocks_test, train = False, scaler = scaler, magic_value = -100)\n","        print(X_test_cube.shape, Y_test_cube.shape)\n","\n","        n_timesteps, n_features, n_outputs = X_train_cube.shape[1], X_train_cube.shape[2], Y_test_cube.shape[2]\n","\n","        #setting timestep dimension to None \n","        model = many_to_many_model((None,n_features),n_outputs,mask_value = -100)\n","        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","        #model.summary\n","\n","        print('Training Model')\n","        # fit network\n","        model.fit(X_train_cube, Y_train_cube, epochs=epochs, batch_size=batch_size, verbose=verbose)\n","\n","        print('Evaluating Model')\n","        #evaluate model on train and test data\n","        train_f1_scores[split_count] = get_RNN_f1(X_train_cube, Y_train_cube, model)\n","        test_f1_scores[split_count] = get_RNN_f1(X_test_cube, Y_test_cube, model)\n","\n","    return train_f1_scores, test_f1_scores"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"7GR4lp889Vzf","executionInfo":{"status":"ok","timestamp":1625677438456,"user_tz":240,"elapsed":7,"user":{"displayName":"Cesar Echavarria","photoUrl":"","userId":"12535184235153277849"}}},"source":["\n","#define where the data files are located\n","data_folder = '/content/drive/MyDrive/limb-position-EMG-Repo/EMG_data/'\n","\n","nsubjects = 36\n","\n","# User-defined parameters\n","\n","lo_freq = 20 #lower bound of bandpass filter\n","hi_freq = 450 #upper bound of bandpass filter\n","\n","win_size = 100 #define window size over which to compute time-domain features\n","step = win_size #keeping this parameter in case we want to re-run later with some overlap"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zb4qdvlg9izz","executionInfo":{"status":"ok","timestamp":1625678903250,"user_tz":240,"elapsed":1464800,"user":{"displayName":"Cesar Echavarria","photoUrl":"","userId":"12535184235153277849"}},"outputId":"d7b387b6-0250-4159-88ff-535c095765e8"},"source":["#subject_id = 2\n","\n","for subject_id in range(26,27+1):\n","  subject_folder = os.path.join(data_folder,'%02d'%(subject_id))\n","  print('=======================')\n","  print(subject_folder)\n","\n","  # Process data and get features \n","  #get features across segments and corresponding info\n","  feature_matrix, target_labels, window_tstamps, \\\n","  block_labels, series_labels = get_subject_data_for_classification(subject_folder, lo_freq, hi_freq, \\\n","                                                                    win_size, step)\n","\n","  #exclude timepoints block with 'unknown' label\n","  in_samples = np.where(target_labels != 0)[0]\n","  feature_matrix_in = feature_matrix[in_samples,:]\n","  target_labels_in = target_labels[in_samples]\n","  window_tstamps_in = window_tstamps[in_samples]\n","  block_labels_in = block_labels[in_samples]\n","  #initialize empty list\n","  rnn_results_df = []\n","\n","  # Set seed for replicability\n","  np.random.seed(1)\n","\n","  # Repeat analysis over multiple repetitions to take into account stochasticity of experiment\n","  nreps = 10\n","  for rep in range(nreps):\n","      print('**Repetition %i'%(rep+1))\n","\n","      #trained and evalute RNN model on labeled data\n","      train_f1, test_f1 = RNN_on_labeled_data(feature_matrix_in.T, target_labels_in, window_tstamps_in,\\\n","                                                            block_labels_in, epochs = 40)\n","      \n","      # Put results in dataframe\n","      rnn_results_df.append(pd.DataFrame({'F1_score':train_f1,\\\n","                                      'Rep':[rep+1 for x in range(train_f1.size)],\\\n","                                      'Fold': np.arange(train_f1.size)+1,\\\n","                                'Shuffled':[False for x in range(train_f1.size)],\\\n","                                'Type':['Train' for x in range(train_f1.size)]}))\n","      \n","      rnn_results_df.append(pd.DataFrame({'F1_score':test_f1,\\\n","                                      'Rep':[rep+1 for x in range(test_f1.size)],\\\n","                                      'Fold': np.arange(test_f1.size)+1,\\\n","                                'Shuffled':[False for x in range(test_f1.size)],\\\n","                                'Type':['Test' for x in range(test_f1.size)]}))\n","\n","      \n","      print('---Permuted Data---')\n","      train_f1, test_f1 = RNN_on_labeled_data(feature_matrix_in.T, target_labels_in, window_tstamps_in,\\\n","                                                            block_labels_in, epochs = 40, permute = True)\n","      \n","      # Put results in dataframe\n","      rnn_results_df.append(pd.DataFrame({'F1_score':train_f1,\\\n","                                      'Rep':[rep+1 for x in range(train_f1.size)],\\\n","                                      'Fold': np.arange(train_f1.size)+1,\\\n","                                'Shuffled':[True for x in range(train_f1.size)],\\\n","                                'Type':['Train' for x in range(train_f1.size)]}))\n","      \n","      rnn_results_df.append(pd.DataFrame({'F1_score':test_f1,\\\n","                                      'Rep':[rep+1 for x in range(test_f1.size)],\\\n","                                      'Fold': np.arange(test_f1.size)+1,\\\n","                                'Shuffled':[True for x in range(test_f1.size)],\\\n","                                'Type':['Test' for x in range(test_f1.size)]}))\n","      \n","  #concatenate all dataframes\n","  rnn_results_df = pd.concat(rnn_results_df, axis =0)\n","\n","  #save results\n","  results_folder =  os.path.join(data_folder,'..','results_data','RNN')\n","  results_fn = 'subject_%02d_within_subject_results.h5'%(subject_id)\n","  rnn_results_df.to_hdf(os.path.join(results_folder,results_fn), key='results_df', mode='w')"],"execution_count":34,"outputs":[{"output_type":"stream","text":["=======================\n","/content/drive/MyDrive/limb-position-EMG-Repo/EMG_data/26\n","**Repetition 1\n","(404,)\n","(404,)\n","(24,) (24,)\n","Split Count: 1\n","(18, 45, 16) (18, 45, 6)\n","(6, 17, 16) (6, 17, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","(18, 45, 16) (18, 45, 6)\n","(6, 21, 16) (6, 21, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 3\n","(18, 45, 16) (18, 45, 6)\n","(6, 16, 16) (6, 16, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","(18, 21, 16) (18, 21, 6)\n","(6, 45, 16) (6, 45, 6)\n","Training Model\n","Evaluating Model\n","---Permuted Data---\n","(404,)\n","(404,)\n","(24,) (24,)\n","Split Count: 1\n","(18, 17, 16) (18, 17, 6)\n","(6, 45, 16) (6, 45, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","(18, 45, 16) (18, 45, 6)\n","(6, 17, 16) (6, 17, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 3\n","(18, 45, 16) (18, 45, 6)\n","(6, 17, 16) (6, 17, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","(18, 45, 16) (18, 45, 6)\n","(6, 17, 16) (6, 17, 6)\n","Training Model\n","Evaluating Model\n","**Repetition 2\n","(404,)\n","(404,)\n","(24,) (24,)\n","Split Count: 1\n","(18, 45, 16) (18, 45, 6)\n","(6, 16, 16) (6, 16, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","(18, 45, 16) (18, 45, 6)\n","(6, 21, 16) (6, 21, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 3\n","(18, 21, 16) (18, 21, 6)\n","(6, 45, 16) (6, 45, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","(18, 45, 16) (18, 45, 6)\n","(6, 17, 16) (6, 17, 6)\n","Training Model\n","Evaluating Model\n","---Permuted Data---\n","(404,)\n","(404,)\n","(24,) (24,)\n","Split Count: 1\n","(18, 45, 16) (18, 45, 6)\n","(6, 21, 16) (6, 21, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","(18, 45, 16) (18, 45, 6)\n","(6, 17, 16) (6, 17, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 3\n","(18, 45, 16) (18, 45, 6)\n","(6, 17, 16) (6, 17, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","(18, 21, 16) (18, 21, 6)\n","(6, 45, 16) (6, 45, 6)\n","Training Model\n","Evaluating Model\n","**Repetition 3\n","(404,)\n","(404,)\n","(24,) (24,)\n","Split Count: 1\n","(18, 45, 16) (18, 45, 6)\n","(6, 16, 16) (6, 16, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","(18, 45, 16) (18, 45, 6)\n","(6, 17, 16) (6, 17, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 3\n","(18, 17, 16) (18, 17, 6)\n","(6, 45, 16) (6, 45, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","(18, 45, 16) (18, 45, 6)\n","(6, 17, 16) (6, 17, 6)\n","Training Model\n","Evaluating Model\n","---Permuted Data---\n","(404,)\n","(404,)\n","(24,) (24,)\n","Split Count: 1\n","(18, 45, 16) (18, 45, 6)\n","(6, 17, 16) (6, 17, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","(18, 17, 16) (18, 17, 6)\n","(6, 45, 16) (6, 45, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 3\n","(18, 45, 16) (18, 45, 6)\n","(6, 17, 16) (6, 17, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","(18, 45, 16) (18, 45, 6)\n","(6, 17, 16) (6, 17, 6)\n","Training Model\n","Evaluating Model\n","**Repetition 4\n","(404,)\n","(404,)\n","(24,) (24,)\n","Split Count: 1\n","(18, 45, 16) (18, 45, 6)\n","(6, 21, 16) (6, 21, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","(18, 45, 16) (18, 45, 6)\n","(6, 16, 16) (6, 16, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 3\n","(18, 21, 16) (18, 21, 6)\n","(6, 45, 16) (6, 45, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","(18, 45, 16) (18, 45, 6)\n","(6, 17, 16) (6, 17, 6)\n","Training Model\n","Evaluating Model\n","---Permuted Data---\n","(404,)\n","(404,)\n","(24,) (24,)\n","Split Count: 1\n","(18, 45, 16) (18, 45, 6)\n","(6, 21, 16) (6, 21, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","(18, 45, 16) (18, 45, 6)\n","(6, 17, 16) (6, 17, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 3\n","(18, 45, 16) (18, 45, 6)\n","(6, 17, 16) (6, 17, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","(18, 21, 16) (18, 21, 6)\n","(6, 45, 16) (6, 45, 6)\n","Training Model\n","Evaluating Model\n","**Repetition 5\n","(404,)\n","(404,)\n","(24,) (24,)\n","Split Count: 1\n","(18, 45, 16) (18, 45, 6)\n","(6, 17, 16) (6, 17, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","(18, 21, 16) (18, 21, 6)\n","(6, 45, 16) (6, 45, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 3\n","(18, 45, 16) (18, 45, 6)\n","(6, 17, 16) (6, 17, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","(18, 45, 16) (18, 45, 6)\n","(6, 21, 16) (6, 21, 6)\n","Training Model\n","Evaluating Model\n","---Permuted Data---\n","(404,)\n","(404,)\n","(24,) (24,)\n","Split Count: 1\n","(18, 45, 16) (18, 45, 6)\n","(6, 16, 16) (6, 16, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","(18, 21, 16) (18, 21, 6)\n","(6, 45, 16) (6, 45, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 3\n","(18, 45, 16) (18, 45, 6)\n","(6, 21, 16) (6, 21, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","(18, 45, 16) (18, 45, 6)\n","(6, 17, 16) (6, 17, 6)\n","Training Model\n","Evaluating Model\n","**Repetition 6\n","(404,)\n","(404,)\n","(24,) (24,)\n","Split Count: 1\n","(18, 45, 16) (18, 45, 6)\n","(6, 21, 16) (6, 21, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","(18, 45, 16) (18, 45, 6)\n","(6, 17, 16) (6, 17, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 3\n","(18, 45, 16) (18, 45, 6)\n","(6, 17, 16) (6, 17, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","(18, 21, 16) (18, 21, 6)\n","(6, 45, 16) (6, 45, 6)\n","Training Model\n","Evaluating Model\n","---Permuted Data---\n","(404,)\n","(404,)\n","(24,) (24,)\n","Split Count: 1\n","(18, 45, 16) (18, 45, 6)\n","(6, 17, 16) (6, 17, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","(18, 21, 16) (18, 21, 6)\n","(6, 45, 16) (6, 45, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 3\n","(18, 45, 16) (18, 45, 6)\n","(6, 16, 16) (6, 16, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","(18, 45, 16) (18, 45, 6)\n","(6, 21, 16) (6, 21, 6)\n","Training Model\n","Evaluating Model\n","**Repetition 7\n","(404,)\n","(404,)\n","(24,) (24,)\n","Split Count: 1\n","(18, 45, 16) (18, 45, 6)\n","(6, 16, 16) (6, 16, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","(18, 21, 16) (18, 21, 6)\n","(6, 45, 16) (6, 45, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 3\n","(18, 45, 16) (18, 45, 6)\n","(6, 17, 16) (6, 17, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","(18, 45, 16) (18, 45, 6)\n","(6, 21, 16) (6, 21, 6)\n","Training Model\n","Evaluating Model\n","---Permuted Data---\n","(404,)\n","(404,)\n","(24,) (24,)\n","Split Count: 1\n","(18, 45, 16) (18, 45, 6)\n","(6, 17, 16) (6, 17, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","(18, 21, 16) (18, 21, 6)\n","(6, 45, 16) (6, 45, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 3\n","(18, 45, 16) (18, 45, 6)\n","(6, 21, 16) (6, 21, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","(18, 45, 16) (18, 45, 6)\n","(6, 17, 16) (6, 17, 6)\n","Training Model\n","Evaluating Model\n","**Repetition 8\n","(404,)\n","(404,)\n","(24,) (24,)\n","Split Count: 1\n","(18, 45, 16) (18, 45, 6)\n","(6, 17, 16) (6, 17, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","(18, 45, 16) (18, 45, 6)\n","(6, 21, 16) (6, 21, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 3\n","(18, 21, 16) (18, 21, 6)\n","(6, 45, 16) (6, 45, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","(18, 45, 16) (18, 45, 6)\n","(6, 16, 16) (6, 16, 6)\n","Training Model\n","Evaluating Model\n","---Permuted Data---\n","(404,)\n","(404,)\n","(24,) (24,)\n","Split Count: 1\n","(18, 45, 16) (18, 45, 6)\n","(6, 15, 16) (6, 15, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","(18, 45, 16) (18, 45, 6)\n","(6, 17, 16) (6, 17, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 3\n","(18, 17, 16) (18, 17, 6)\n","(6, 45, 16) (6, 45, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","(18, 45, 16) (18, 45, 6)\n","(6, 17, 16) (6, 17, 6)\n","Training Model\n","Evaluating Model\n","**Repetition 9\n","(404,)\n","(404,)\n","(24,) (24,)\n","Split Count: 1\n","(18, 45, 16) (18, 45, 6)\n","(6, 21, 16) (6, 21, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","(18, 45, 16) (18, 45, 6)\n","(6, 17, 16) (6, 17, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 3\n","(18, 45, 16) (18, 45, 6)\n","(6, 16, 16) (6, 16, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","(18, 21, 16) (18, 21, 6)\n","(6, 45, 16) (6, 45, 6)\n","Training Model\n","Evaluating Model\n","---Permuted Data---\n","(404,)\n","(404,)\n","(24,) (24,)\n","Split Count: 1\n","(18, 45, 16) (18, 45, 6)\n","(6, 17, 16) (6, 17, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","(18, 45, 16) (18, 45, 6)\n","(6, 17, 16) (6, 17, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 3\n","(18, 21, 16) (18, 21, 6)\n","(6, 45, 16) (6, 45, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","(18, 45, 16) (18, 45, 6)\n","(6, 21, 16) (6, 21, 6)\n","Training Model\n","Evaluating Model\n","**Repetition 10\n","(404,)\n","(404,)\n","(24,) (24,)\n","Split Count: 1\n","(18, 45, 16) (18, 45, 6)\n","(6, 17, 16) (6, 17, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","(18, 45, 16) (18, 45, 6)\n","(6, 17, 16) (6, 17, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 3\n","(18, 45, 16) (18, 45, 6)\n","(6, 17, 16) (6, 17, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","(18, 17, 16) (18, 17, 6)\n","(6, 45, 16) (6, 45, 6)\n","Training Model\n","Evaluating Model\n","---Permuted Data---\n","(404,)\n","(404,)\n","(24,) (24,)\n","Split Count: 1\n","(18, 21, 16) (18, 21, 6)\n","(6, 45, 16) (6, 45, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","(18, 45, 16) (18, 45, 6)\n","(6, 17, 16) (6, 17, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 3\n","(18, 45, 16) (18, 45, 6)\n","(6, 17, 16) (6, 17, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","(18, 45, 16) (18, 45, 6)\n","(6, 21, 16) (6, 21, 6)\n","Training Model\n","Evaluating Model\n","=======================\n","/content/drive/MyDrive/limb-position-EMG-Repo/EMG_data/27\n","**Repetition 1\n","(422,)\n","(422,)\n","(24,) (24,)\n","Split Count: 1\n","(18, 22, 16) (18, 22, 6)\n","(6, 20, 16) (6, 20, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","(18, 22, 16) (18, 22, 6)\n","(6, 20, 16) (6, 20, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 3\n","(18, 20, 16) (18, 20, 6)\n","(6, 22, 16) (6, 22, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","(18, 22, 16) (18, 22, 6)\n","(6, 18, 16) (6, 18, 6)\n","Training Model\n","Evaluating Model\n","---Permuted Data---\n","(422,)\n","(422,)\n","(24,) (24,)\n","Split Count: 1\n","(18, 22, 16) (18, 22, 6)\n","(6, 21, 16) (6, 21, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","(18, 22, 16) (18, 22, 6)\n","(6, 20, 16) (6, 20, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 3\n","(18, 21, 16) (18, 21, 6)\n","(6, 22, 16) (6, 22, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","(18, 22, 16) (18, 22, 6)\n","(6, 18, 16) (6, 18, 6)\n","Training Model\n","Evaluating Model\n","**Repetition 2\n","(422,)\n","(422,)\n","(24,) (24,)\n","Split Count: 1\n","(18, 22, 16) (18, 22, 6)\n","(6, 18, 16) (6, 18, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","(18, 21, 16) (18, 21, 6)\n","(6, 22, 16) (6, 22, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 3\n","(18, 22, 16) (18, 22, 6)\n","(6, 21, 16) (6, 21, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","(18, 22, 16) (18, 22, 6)\n","(6, 20, 16) (6, 20, 6)\n","Training Model\n","Evaluating Model\n","---Permuted Data---\n","(422,)\n","(422,)\n","(24,) (24,)\n","Split Count: 1\n","(18, 22, 16) (18, 22, 6)\n","(6, 18, 16) (6, 18, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","(18, 22, 16) (18, 22, 6)\n","(6, 21, 16) (6, 21, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 3\n","(18, 21, 16) (18, 21, 6)\n","(6, 22, 16) (6, 22, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","(18, 22, 16) (18, 22, 6)\n","(6, 20, 16) (6, 20, 6)\n","Training Model\n","Evaluating Model\n","**Repetition 3\n","(422,)\n","(422,)\n","(24,) (24,)\n","Split Count: 1\n","(18, 20, 16) (18, 20, 6)\n","(6, 22, 16) (6, 22, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","(18, 22, 16) (18, 22, 6)\n","(6, 20, 16) (6, 20, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 3\n","(18, 22, 16) (18, 22, 6)\n","(6, 18, 16) (6, 18, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","(18, 22, 16) (18, 22, 6)\n","(6, 20, 16) (6, 20, 6)\n","Training Model\n","Evaluating Model\n","---Permuted Data---\n","(422,)\n","(422,)\n","(24,) (24,)\n","Split Count: 1\n","(18, 22, 16) (18, 22, 6)\n","(6, 20, 16) (6, 20, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","(18, 21, 16) (18, 21, 6)\n","(6, 22, 16) (6, 22, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 3\n","(18, 22, 16) (18, 22, 6)\n","(6, 21, 16) (6, 21, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","(18, 22, 16) (18, 22, 6)\n","(6, 18, 16) (6, 18, 6)\n","Training Model\n","Evaluating Model\n","**Repetition 4\n","(422,)\n","(422,)\n","(24,) (24,)\n","Split Count: 1\n","(18, 22, 16) (18, 22, 6)\n","(6, 20, 16) (6, 20, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","(18, 22, 16) (18, 22, 6)\n","(6, 18, 16) (6, 18, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 3\n","(18, 22, 16) (18, 22, 6)\n","(6, 21, 16) (6, 21, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","(18, 21, 16) (18, 21, 6)\n","(6, 22, 16) (6, 22, 6)\n","Training Model\n","Evaluating Model\n","---Permuted Data---\n","(422,)\n","(422,)\n","(24,) (24,)\n","Split Count: 1\n","(18, 22, 16) (18, 22, 6)\n","(6, 20, 16) (6, 20, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","(18, 22, 16) (18, 22, 6)\n","(6, 18, 16) (6, 18, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 3\n","(18, 20, 16) (18, 20, 6)\n","(6, 22, 16) (6, 22, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","(18, 22, 16) (18, 22, 6)\n","(6, 20, 16) (6, 20, 6)\n","Training Model\n","Evaluating Model\n","**Repetition 5\n","(422,)\n","(422,)\n","(24,) (24,)\n","Split Count: 1\n","(18, 22, 16) (18, 22, 6)\n","(6, 20, 16) (6, 20, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","(18, 22, 16) (18, 22, 6)\n","(6, 18, 16) (6, 18, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 3\n","(18, 20, 16) (18, 20, 6)\n","(6, 22, 16) (6, 22, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","(18, 22, 16) (18, 22, 6)\n","(6, 18, 16) (6, 18, 6)\n","Training Model\n","Evaluating Model\n","---Permuted Data---\n","(422,)\n","(422,)\n","(24,) (24,)\n","Split Count: 1\n","(18, 21, 16) (18, 21, 6)\n","(6, 22, 16) (6, 22, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","(18, 22, 16) (18, 22, 6)\n","(6, 20, 16) (6, 20, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 3\n","(18, 22, 16) (18, 22, 6)\n","(6, 20, 16) (6, 20, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","(18, 22, 16) (18, 22, 6)\n","(6, 21, 16) (6, 21, 6)\n","Training Model\n","Evaluating Model\n","**Repetition 6\n","(422,)\n","(422,)\n","(24,) (24,)\n","Split Count: 1\n","(18, 21, 16) (18, 21, 6)\n","(6, 22, 16) (6, 22, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","(18, 22, 16) (18, 22, 6)\n","(6, 21, 16) (6, 21, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 3\n","(18, 22, 16) (18, 22, 6)\n","(6, 20, 16) (6, 20, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","(18, 22, 16) (18, 22, 6)\n","(6, 18, 16) (6, 18, 6)\n","Training Model\n","Evaluating Model\n","---Permuted Data---\n","(422,)\n","(422,)\n","(24,) (24,)\n","Split Count: 1\n","(18, 22, 16) (18, 22, 6)\n","(6, 18, 16) (6, 18, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","(18, 22, 16) (18, 22, 6)\n","(6, 20, 16) (6, 20, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 3\n","(18, 20, 16) (18, 20, 6)\n","(6, 22, 16) (6, 22, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","(18, 22, 16) (18, 22, 6)\n","(6, 18, 16) (6, 18, 6)\n","Training Model\n","Evaluating Model\n","**Repetition 7\n","(422,)\n","(422,)\n","(24,) (24,)\n","Split Count: 1\n","(18, 20, 16) (18, 20, 6)\n","(6, 22, 16) (6, 22, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","(18, 22, 16) (18, 22, 6)\n","(6, 18, 16) (6, 18, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 3\n","(18, 22, 16) (18, 22, 6)\n","(6, 20, 16) (6, 20, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","(18, 22, 16) (18, 22, 6)\n","(6, 18, 16) (6, 18, 6)\n","Training Model\n","Evaluating Model\n","---Permuted Data---\n","(422,)\n","(422,)\n","(24,) (24,)\n","Split Count: 1\n","(18, 21, 16) (18, 21, 6)\n","(6, 22, 16) (6, 22, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","(18, 22, 16) (18, 22, 6)\n","(6, 20, 16) (6, 20, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 3\n","(18, 22, 16) (18, 22, 6)\n","(6, 18, 16) (6, 18, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","(18, 22, 16) (18, 22, 6)\n","(6, 21, 16) (6, 21, 6)\n","Training Model\n","Evaluating Model\n","**Repetition 8\n","(422,)\n","(422,)\n","(24,) (24,)\n","Split Count: 1\n","(18, 22, 16) (18, 22, 6)\n","(6, 20, 16) (6, 20, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","(18, 22, 16) (18, 22, 6)\n","(6, 18, 16) (6, 18, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 3\n","(18, 22, 16) (18, 22, 6)\n","(6, 20, 16) (6, 20, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","(18, 20, 16) (18, 20, 6)\n","(6, 22, 16) (6, 22, 6)\n","Training Model\n","Evaluating Model\n","---Permuted Data---\n","(422,)\n","(422,)\n","(24,) (24,)\n","Split Count: 1\n","(18, 22, 16) (18, 22, 6)\n","(6, 21, 16) (6, 21, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","(18, 21, 16) (18, 21, 6)\n","(6, 22, 16) (6, 22, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 3\n","(18, 22, 16) (18, 22, 6)\n","(6, 20, 16) (6, 20, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","(18, 22, 16) (18, 22, 6)\n","(6, 18, 16) (6, 18, 6)\n","Training Model\n","Evaluating Model\n","**Repetition 9\n","(422,)\n","(422,)\n","(24,) (24,)\n","Split Count: 1\n","(18, 21, 16) (18, 21, 6)\n","(6, 22, 16) (6, 22, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","(18, 22, 16) (18, 22, 6)\n","(6, 18, 16) (6, 18, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 3\n","(18, 22, 16) (18, 22, 6)\n","(6, 21, 16) (6, 21, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","(18, 22, 16) (18, 22, 6)\n","(6, 20, 16) (6, 20, 6)\n","Training Model\n","Evaluating Model\n","---Permuted Data---\n","(422,)\n","(422,)\n","(24,) (24,)\n","Split Count: 1\n","(18, 22, 16) (18, 22, 6)\n","(6, 20, 16) (6, 20, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","(18, 20, 16) (18, 20, 6)\n","(6, 22, 16) (6, 22, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 3\n","(18, 22, 16) (18, 22, 6)\n","(6, 20, 16) (6, 20, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","(18, 22, 16) (18, 22, 6)\n","(6, 18, 16) (6, 18, 6)\n","Training Model\n","Evaluating Model\n","**Repetition 10\n","(422,)\n","(422,)\n","(24,) (24,)\n","Split Count: 1\n","(18, 22, 16) (18, 22, 6)\n","(6, 21, 16) (6, 21, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","(18, 22, 16) (18, 22, 6)\n","(6, 18, 16) (6, 18, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 3\n","(18, 21, 16) (18, 21, 6)\n","(6, 22, 16) (6, 22, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","(18, 22, 16) (18, 22, 6)\n","(6, 20, 16) (6, 20, 6)\n","Training Model\n","Evaluating Model\n","---Permuted Data---\n","(422,)\n","(422,)\n","(24,) (24,)\n","Split Count: 1\n","(18, 22, 16) (18, 22, 6)\n","(6, 21, 16) (6, 21, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 2\n","(18, 22, 16) (18, 22, 6)\n","(6, 20, 16) (6, 20, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 3\n","(18, 22, 16) (18, 22, 6)\n","(6, 18, 16) (6, 18, 6)\n","Training Model\n","Evaluating Model\n","Split Count: 4\n","(18, 21, 16) (18, 21, 6)\n","(6, 22, 16) (6, 22, 6)\n","Training Model\n","Evaluating Model\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gJu1vFs_9jxb","executionInfo":{"status":"ok","timestamp":1625676998568,"user_tz":240,"elapsed":327,"user":{"displayName":"Cesar Echavarria","photoUrl":"","userId":"12535184235153277849"}},"outputId":"55ba70db-3eef-4a4c-aeb8-3cf3d645ce05"},"source":["feature_matrix_in.shape"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(404, 16)"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j1eD8OIa9laq","executionInfo":{"status":"ok","timestamp":1625677037189,"user_tz":240,"elapsed":549,"user":{"displayName":"Cesar Echavarria","photoUrl":"","userId":"12535184235153277849"}},"outputId":"c876b87c-c194-4310-b3ae-7fa752a63700"},"source":["target_labels_in.shape"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(404,)"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"wGN61PIF9lli","executionInfo":{"status":"ok","timestamp":1625677354105,"user_tz":240,"elapsed":212,"user":{"displayName":"Cesar Echavarria","photoUrl":"","userId":"12535184235153277849"}}},"source":[" blocks = np.array([k for k,g in groupby(block_labels_in)])\n","classes = np.array([k for k,g in groupby(target_labels_in) if k!=0])"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nucQSxjE9lsG","executionInfo":{"status":"ok","timestamp":1625677355199,"user_tz":240,"elapsed":7,"user":{"displayName":"Cesar Echavarria","photoUrl":"","userId":"12535184235153277849"}},"outputId":"937f5cf5-4ee0-4f61-8497-d0ff78635b6c"},"source":["blocks.shape"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(24,)"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ldQ8w_K_9lyk","executionInfo":{"status":"ok","timestamp":1625677356209,"user_tz":240,"elapsed":4,"user":{"displayName":"Cesar Echavarria","photoUrl":"","userId":"12535184235153277849"}},"outputId":"50102a57-3d70-444e-d96c-cdaba5ef2073"},"source":["classes.shape"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(24,)"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xzV6IswL6l8T","executionInfo":{"status":"ok","timestamp":1625677269472,"user_tz":240,"elapsed":201,"user":{"displayName":"Cesar Echavarria","photoUrl":"","userId":"12535184235153277849"}},"outputId":"84f771cf-cbd1-44e1-d2e3-9a508e24ca87"},"source":["blocks"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 2.,  4.,  6.,  8., 10., 12., 14., 16., 18., 20., 22., 24., 26.,\n","       28., 30., 32., 34., 36., 38., 40., 42., 44., 46.])"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YqbInqvM6ofq","executionInfo":{"status":"ok","timestamp":1625677300316,"user_tz":240,"elapsed":8,"user":{"displayName":"Cesar Echavarria","photoUrl":"","userId":"12535184235153277849"}},"outputId":"054a622f-006d-47bb-a0f7-cbcf4bc1b03b"},"source":["block_labels_in"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n","        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n","        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n","        0.,  0.,  0.,  0.,  0.,  0.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n","        2.,  2.,  2.,  2.,  2.,  2.,  2.,  4.,  4.,  4.,  4.,  4.,  4.,\n","        4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  6.,  6.,\n","        6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  8.,\n","        8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,\n","        8., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10.,\n","       10., 10., 10., 10., 10., 12., 12., 12., 12., 12., 12., 12., 12.,\n","       12., 12., 12., 12., 12., 12., 12., 14., 14., 14., 14., 14., 14.,\n","       14., 14., 14., 14., 14., 14., 14., 14., 14., 16., 16., 16., 16.,\n","       16., 16., 16., 16., 16., 16., 16., 16., 16., 16., 16., 16., 18.,\n","       18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18.,\n","       20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.,\n","       20., 20., 20., 22., 22., 22., 22., 22., 22., 22., 22., 22., 22.,\n","       22., 22., 22., 22., 22., 22., 24., 24., 24., 24., 24., 24., 24.,\n","       24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 26., 26., 26.,\n","       26., 26., 26., 26., 26., 26., 26., 26., 26., 26., 26., 26., 28.,\n","       28., 28., 28., 28., 28., 28., 28., 28., 28., 28., 28., 28., 28.,\n","       28., 28., 30., 30., 30., 30., 30., 30., 30., 30., 30., 30., 30.,\n","       30., 30., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32.,\n","       32., 32., 34., 34., 34., 34., 34., 34., 34., 34., 34., 34., 34.,\n","       34., 34., 34., 36., 36., 36., 36., 36., 36., 36., 36., 36., 36.,\n","       36., 36., 36., 36., 38., 38., 38., 38., 38., 38., 38., 38., 38.,\n","       38., 38., 38., 38., 38., 38., 38., 38., 40., 40., 40., 40., 40.,\n","       40., 40., 40., 40., 40., 40., 40., 40., 40., 40., 40., 40., 42.,\n","       42., 42., 42., 42., 42., 42., 42., 42., 42., 42., 42., 42., 42.,\n","       42., 42., 42., 42., 42., 42., 42., 44., 44., 44., 44., 44., 44.,\n","       44., 44., 44., 44., 44., 44., 44., 44., 44., 44., 44., 46., 46.,\n","       46., 46., 46., 46., 46., 46., 46., 46., 46., 46., 46., 46., 46.,\n","       46.])"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vp0S9CnW6qjP","executionInfo":{"status":"ok","timestamp":1625677317526,"user_tz":240,"elapsed":206,"user":{"displayName":"Cesar Echavarria","photoUrl":"","userId":"12535184235153277849"}},"outputId":"d7c16397-82df-4df8-c605-515623e42b05"},"source":["target_labels_in"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2., 2., 2., 2., 2.,\n","       2., 2., 2., 2., 2., 2., 2., 2., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n","       3., 3., 3., 3., 3., 3., 3., 3., 4., 4., 4., 4., 4., 4., 4., 4., 4.,\n","       4., 4., 4., 4., 4., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n","       5., 5., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6.,\n","       6., 6., 6., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","       1., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 3.,\n","       3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 4., 4.,\n","       4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 5., 5., 5., 5., 5.,\n","       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 6., 6., 6., 6., 6., 6.,\n","       6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 1., 1., 1., 1., 1., 1., 1.,\n","       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2., 2., 2., 2., 2., 2.,\n","       2., 2., 2., 2., 2., 2., 2., 2., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n","       3., 3., 3., 3., 3., 3., 3., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4.,\n","       4., 4., 4., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 6.,\n","       6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 1., 1., 1., 1.,\n","       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2., 2., 2., 2., 2., 2.,\n","       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 3., 3., 3., 3., 3., 3., 3.,\n","       3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 4., 4., 4., 4., 4., 4., 4.,\n","       4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 5., 5., 5.,\n","       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 6., 6., 6.,\n","       6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6.])"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":291},"id":"gKSSrEAq60Ok","executionInfo":{"status":"ok","timestamp":1625677399654,"user_tz":240,"elapsed":639,"user":{"displayName":"Cesar Echavarria","photoUrl":"","userId":"12535184235153277849"}},"outputId":"9832a8e2-1525-4e3b-c30f-1234a32e7d37"},"source":["plt.plot(target_labels)"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f5f1f1ccf90>]"]},"metadata":{"tags":[]},"execution_count":31},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IwwGHnf27BWV","executionInfo":{"status":"ok","timestamp":1625677381962,"user_tz":240,"elapsed":505,"user":{"displayName":"Cesar Echavarria","photoUrl":"","userId":"12535184235153277849"}},"outputId":"1b9a2559-ad2b-4660-b8a4-7f0d824a5619"},"source":["block_labels"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 0.,  0.,  0., ..., 47., 47., 47.])"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"4wtUp5Ez7Cll"},"source":[""],"execution_count":null,"outputs":[]}]}