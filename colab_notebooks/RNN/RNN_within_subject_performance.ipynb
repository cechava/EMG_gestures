{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RNN_within_subject_performance.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNKE0l5yfCx8WnmVCmmZcXk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Rrhi6q4ZDzt4"},"source":[""]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ydmw6KDT22BD","executionInfo":{"status":"ok","timestamp":1632752932903,"user_tz":240,"elapsed":31681,"user":{"displayName":"Cesar Echavarria","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12535184235153277849"}},"outputId":"7099efd5-922d-4951-ec47-d62fc36fffb2"},"source":["#Run cell to mount Google Drive\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IDk5bnX229lS","executionInfo":{"status":"ok","timestamp":1632752969192,"user_tz":240,"elapsed":35456,"user":{"displayName":"Cesar Echavarria","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12535184235153277849"}},"outputId":"68a8776c-4c8d-4e67-f7de-90d9944059ef"},"source":["# install package to have access to custom functions\n","%pip install /content/drive/MyDrive/EMG_gestures/ --use-feature=in-tree-build"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing ./drive/MyDrive/EMG_gestures\n","Building wheels for collected packages: EMG-gestures\n","  Building wheel for EMG-gestures (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for EMG-gestures: filename=EMG_gestures-0.1.0-py3-none-any.whl size=46757 sha256=f016691e85d6a44bfbc201b0b2fb61daf24a67b3d6f0671f1d6d1c63d9948ca5\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-b4bc6gp6/wheels/a2/b7/61/2147fa082a9e51bef5dcc38dd3f0898fe0554d62203c0e383e\n","Successfully built EMG-gestures\n","Installing collected packages: EMG-gestures\n","Successfully installed EMG-gestures-0.1.0\n"]}]},{"cell_type":"code","metadata":{"id":"kolwq-Ju2-nl","executionInfo":{"status":"ok","timestamp":1632752971679,"user_tz":240,"elapsed":2491,"user":{"displayName":"Cesar Echavarria","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12535184235153277849"}}},"source":["#import necessary packages\n","\n","#our workhorses\n","import numpy as np\n","import pandas as pd\n","import scipy\n","\n","#to visualize\n","%matplotlib inline\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","#style params for figures\n","sns.set(font_scale = 2)\n","plt.style.use('seaborn-white')\n","plt.rc(\"axes\", labelweight=\"bold\")\n","from IPython.display import display, HTML\n","\n","#to load files\n","import os\n","import sys\n","import h5py\n","\n","#import cusotm functions\n","from EMG_gestures.utils import *\n","from EMG_gestures.analysis import within_subject_rnn_performance\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zG2xcSRg3RRJ","executionInfo":{"status":"ok","timestamp":1632814145609,"user_tz":240,"elapsed":61173935,"user":{"displayName":"Cesar Echavarria","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12535184235153277849"}},"outputId":"31795259-fde2-4c0c-95ab-648f770e172d"},"source":["#define where the data files are located\n","data_folder = '/content/drive/MyDrive/EMG_gestures/EMG_data/'\n","results_folder = '/content/drive/MyDrive/EMG_gestures/results_data/single_subject_training/RNN/'\n","\n","nsubjects = 36\n","\n","\n","# User-defined parameters\n","lo_freq = 20 #lower bound of bandpass filter\n","hi_freq = 450 #upper bound of bandpass filter\n","\n","win_size = 100 #define window size over which to compute time-domain features\n","step = win_size #keeping this parameter in case we want to re-run later with some overlap\n","\n","nreps = 10\n","exclude = [0,7]#labels to exclude\n","\n","#for RNN training\n","verbose = 0\n","epochs = 100\n","batch_size = 2\n","es_patience = 5\n","#number of permutations to use for training\n","n_shuffled_sets = 20\n","model_dict = {'fe_layers':1, 'fe_activation':'tanh'}\n","#performance metrics\n","score_list = ['f1','accuracy']\n","\n","\n","#subject_id = 1\n","for subject_id in range(32,nsubjects+1):\n","\n","    subject_folder = os.path.join(data_folder,'%02d'%(subject_id))\n","    print('=======================')\n","    print(subject_folder)\n","\n","    # Process data and get features \n","    #get features across segments and corresponding info\n","    feature_matrix_sub, target_labels_sub, window_tstamps_sub, \\\n","    block_labels_sub, series_labels_sub = get_subject_data_for_classification(subject_folder, lo_freq, hi_freq, \\\n","                                                                    win_size, step)\n","    np.random.seed(1)#for reproducibility\n","    results_df = []#initialize empty array for dataframes\n","\n","\n","    for rep in range(nreps):\n","        print('Subject %d|Rep %d'%(subject_id, rep+1))\n","        print('True Data')\n","        train_scores, test_scores,train_info_dict = within_subject_rnn_performance(feature_matrix_sub, target_labels_sub, block_labels_sub,\\\n","                                                                series_labels_sub, model_dict, exclude, score_list,\\\n","                                                                n_shuffled_sets = n_shuffled_sets,\\\n","                                                                verbose = verbose, epochs = epochs, batch_size = batch_size, es_patience = es_patience)\n","\n","        n_splits, n_scores = train_scores.shape\n","        #put testing results in dataframe\n","        data_dict = {'Fold':np.arange(n_splits)+1,\\\n","                            'Rep':[rep+1 for x in range(n_splits)],\\\n","                            'Type':['Train' for x in range(n_splits)],\\\n","                            'Shuffled':[False for x in range(n_splits)],\\\n","                            'Subject':[subject_id for x in range(n_splits)],\\\n","                     'Epochs':[epochs for x in range(n_splits)],\\\n","                'Batch_Size':[batch_size for x in range(n_splits)],\\\n","                'Train_Loss':train_info_dict['train_loss'],\\\n","                    'Val_Loss':train_info_dict['val_loss'],\\\n","                    'Epochs_Trained':train_info_dict['epochs_trained'],\\\n","                }\n","        for sidx in range(n_scores):\n","            data_dict['%s_score'%(score_list[sidx])] = train_scores[:,sidx]\n","        results_df.append(pd.DataFrame(data_dict))\n","\n","        data_dict = {'Fold':np.arange(n_splits)+1,\\\n","                            'Rep':[rep+1 for x in range(n_splits)],\\\n","                            'Type':['Test' for x in range(n_splits)],\\\n","                            'Shuffled':[False for x in range(n_splits)],\\\n","                            'Subject':[subject_id for x in range(n_splits)],\\\n","                     'Epochs':[epochs for x in range(n_splits)],\\\n","                'Batch_Size':[batch_size for x in range(n_splits)],\\\n","                'Train_Loss':train_info_dict['train_loss'],\\\n","                    'Val_Loss':train_info_dict['val_loss'],\\\n","                    'Epochs_Trained':train_info_dict['epochs_trained'],\\\n","                }\n","        for sidx in range(n_scores):\n","            data_dict['%s_score'%(score_list[sidx])] = test_scores[:,sidx]\n","        results_df.append(pd.DataFrame(data_dict))\n","        print('Subject %d|Rep %d'%(subject_id, rep+1))\n","        print('Permuted Data')\n","        target_labels_sub_perm = permute_class_within_sub(target_labels_sub, block_labels_sub, series_labels_sub, exclude)\n","        train_scores, test_scores, train_info_dict = within_subject_rnn_performance(feature_matrix_sub, target_labels_sub, block_labels_sub,\\\n","                                                                series_labels_sub, model_dict, exclude, score_list,\\\n","                                                                n_shuffled_sets = n_shuffled_sets,\\\n","                                                                verbose = verbose, epochs = epochs, batch_size = batch_size, es_patience = es_patience)\n","        n_splits, n_scores = train_scores.shape\n","        #put testing results in dataframe\n","        data_dict = {'Fold':np.arange(n_splits)+1,\\\n","                            'Rep':[rep+1 for x in range(n_splits)],\\\n","                            'Type':['Train' for x in range(n_splits)],\\\n","                            'Shuffled':[True for x in range(n_splits)],\\\n","                            'Subject':[subject_id for x in range(n_splits)],\\\n","                     'Epochs':[epochs for x in range(n_splits)],\\\n","                'Batch_Size':[batch_size for x in range(n_splits)],\\\n","                'Train_Loss':train_info_dict['train_loss'],\\\n","                    'Val_Loss':train_info_dict['val_loss'],\\\n","                    'Epochs_Trained':train_info_dict['epochs_trained'],\\\n","                }\n","        for sidx in range(n_scores):\n","            data_dict['%s_score'%(score_list[sidx])] = train_scores[:,sidx]\n","        results_df.append(pd.DataFrame(data_dict))\n","\n","        data_dict = {'Fold':np.arange(n_splits)+1,\\\n","                            'Rep':[rep+1 for x in range(n_splits)],\\\n","                            'Type':['Test' for x in range(n_splits)],\\\n","                            'Shuffled':[True for x in range(n_splits)],\\\n","                            'Subject':[subject_id for x in range(n_splits)],\\\n","                     'Epochs':[epochs for x in range(n_splits)],\\\n","                'Batch_Size':[batch_size for x in range(n_splits)],\\\n","                'Train_Loss':train_info_dict['train_loss'],\\\n","                    'Val_Loss':train_info_dict['val_loss'],\\\n","                    'Epochs_Trained':train_info_dict['epochs_trained'],\\\n","                }\n","        for sidx in range(n_scores):\n","            data_dict['%s_score'%(score_list[sidx])] = test_scores[:,sidx]\n","        results_df.append(pd.DataFrame(data_dict))\n","\n","    results_df = pd.concat(results_df, axis = 0)\n","    #save results to file\n","    results_fn = 'subject_%02d_within_subject_results.h5'%(subject_id)\n","    results_df.to_hdf(os.path.join(results_folder,results_fn), key='results_df', mode='w')\n","\n","    \n","\n"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/32\n","Subject 32|Rep 1\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 61\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 94\n","Evaluate Model\n","Subject 32|Rep 1\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 54\n","Evaluate Model\n","WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f70bc6c29e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f70bc6c29e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Split Count: 2\n","Training Model\n","Epochs Trained: 60\n","Evaluate Model\n","Subject 32|Rep 2\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 91\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 59\n","Evaluate Model\n","Subject 32|Rep 2\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 73\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 50\n","Evaluate Model\n","Subject 32|Rep 3\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 84\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 64\n","Evaluate Model\n","Subject 32|Rep 3\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 80\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 55\n","Evaluate Model\n","Subject 32|Rep 4\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 72\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 68\n","Evaluate Model\n","Subject 32|Rep 4\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 89\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 47\n","Evaluate Model\n","Subject 32|Rep 5\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 67\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 73\n","Evaluate Model\n","Subject 32|Rep 5\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 68\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 80\n","Evaluate Model\n","Subject 32|Rep 6\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 60\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 71\n","Evaluate Model\n","Subject 32|Rep 6\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 75\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 72\n","Evaluate Model\n","Subject 32|Rep 7\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 62\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 68\n","Evaluate Model\n","Subject 32|Rep 7\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 67\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 97\n","Evaluate Model\n","Subject 32|Rep 8\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 73\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 61\n","Evaluate Model\n","Subject 32|Rep 8\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 91\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 69\n","Evaluate Model\n","Subject 32|Rep 9\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 69\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 70\n","Evaluate Model\n","Subject 32|Rep 9\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 62\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 38\n","Evaluate Model\n","Subject 32|Rep 10\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 89\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 66\n","Evaluate Model\n","Subject 32|Rep 10\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 69\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 69\n","Evaluate Model\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/33\n","Subject 33|Rep 1\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 50\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 39\n","Evaluate Model\n","Subject 33|Rep 1\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 47\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 33\n","Evaluate Model\n","Subject 33|Rep 2\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 37\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 48\n","Evaluate Model\n","Subject 33|Rep 2\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 66\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 42\n","Evaluate Model\n","Subject 33|Rep 3\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 50\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 41\n","Evaluate Model\n","Subject 33|Rep 3\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 63\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 43\n","Evaluate Model\n","Subject 33|Rep 4\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 35\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 39\n","Evaluate Model\n","Subject 33|Rep 4\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 43\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 37\n","Evaluate Model\n","Subject 33|Rep 5\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 61\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 48\n","Evaluate Model\n","Subject 33|Rep 5\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 48\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 46\n","Evaluate Model\n","Subject 33|Rep 6\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 43\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 36\n","Evaluate Model\n","Subject 33|Rep 6\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 46\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 68\n","Evaluate Model\n","Subject 33|Rep 7\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 32\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 35\n","Evaluate Model\n","Subject 33|Rep 7\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 43\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 43\n","Evaluate Model\n","Subject 33|Rep 8\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 44\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 51\n","Evaluate Model\n","Subject 33|Rep 8\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 35\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 56\n","Evaluate Model\n","Subject 33|Rep 9\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 58\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 38\n","Evaluate Model\n","Subject 33|Rep 9\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 62\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 43\n","Evaluate Model\n","Subject 33|Rep 10\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 53\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 39\n","Evaluate Model\n","Subject 33|Rep 10\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 49\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 35\n","Evaluate Model\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/34\n","Subject 34|Rep 1\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 36\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 55\n","Evaluate Model\n","Subject 34|Rep 1\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 52\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 81\n","Evaluate Model\n","Subject 34|Rep 2\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 38\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 25\n","Evaluate Model\n","Subject 34|Rep 2\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 61\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 46\n","Evaluate Model\n","Subject 34|Rep 3\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 45\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 56\n","Evaluate Model\n","Subject 34|Rep 3\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 75\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 38\n","Evaluate Model\n","Subject 34|Rep 4\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 52\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 43\n","Evaluate Model\n","Subject 34|Rep 4\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 40\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 35\n","Evaluate Model\n","Subject 34|Rep 5\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 67\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 39\n","Evaluate Model\n","Subject 34|Rep 5\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 40\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 47\n","Evaluate Model\n","Subject 34|Rep 6\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 48\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 57\n","Evaluate Model\n","Subject 34|Rep 6\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 45\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 48\n","Evaluate Model\n","Subject 34|Rep 7\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 49\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 38\n","Evaluate Model\n","Subject 34|Rep 7\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 41\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 52\n","Evaluate Model\n","Subject 34|Rep 8\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 36\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 60\n","Evaluate Model\n","Subject 34|Rep 8\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 38\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 53\n","Evaluate Model\n","Subject 34|Rep 9\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 62\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 50\n","Evaluate Model\n","Subject 34|Rep 9\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 51\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 59\n","Evaluate Model\n","Subject 34|Rep 10\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 60\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 63\n","Evaluate Model\n","Subject 34|Rep 10\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 53\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 38\n","Evaluate Model\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/35\n","Subject 35|Rep 1\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 32\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 22\n","Evaluate Model\n","Subject 35|Rep 1\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 24\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 59\n","Evaluate Model\n","Subject 35|Rep 2\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 26\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 36\n","Evaluate Model\n","Subject 35|Rep 2\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 64\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 36\n","Evaluate Model\n","Subject 35|Rep 3\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 32\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 57\n","Evaluate Model\n","Subject 35|Rep 3\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 40\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 37\n","Evaluate Model\n","Subject 35|Rep 4\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 26\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 40\n","Evaluate Model\n","Subject 35|Rep 4\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 77\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 26\n","Evaluate Model\n","Subject 35|Rep 5\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 34\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 66\n","Evaluate Model\n","Subject 35|Rep 5\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 18\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 53\n","Evaluate Model\n","Subject 35|Rep 6\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 22\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 57\n","Evaluate Model\n","Subject 35|Rep 6\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 25\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 72\n","Evaluate Model\n","Subject 35|Rep 7\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 24\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 54\n","Evaluate Model\n","Subject 35|Rep 7\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 26\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 42\n","Evaluate Model\n","Subject 35|Rep 8\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 19\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 51\n","Evaluate Model\n","Subject 35|Rep 8\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 24\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 78\n","Evaluate Model\n","Subject 35|Rep 9\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 33\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 22\n","Evaluate Model\n","Subject 35|Rep 9\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 49\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 23\n","Evaluate Model\n","Subject 35|Rep 10\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 29\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 86\n","Evaluate Model\n","Subject 35|Rep 10\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 58\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 24\n","Evaluate Model\n","=======================\n","/content/drive/MyDrive/EMG_gestures/EMG_data/36\n","Subject 36|Rep 1\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 64\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 38\n","Evaluate Model\n","Subject 36|Rep 1\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 32\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 65\n","Evaluate Model\n","Subject 36|Rep 2\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 45\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 49\n","Evaluate Model\n","Subject 36|Rep 2\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 52\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 46\n","Evaluate Model\n","Subject 36|Rep 3\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 42\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 61\n","Evaluate Model\n","Subject 36|Rep 3\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 68\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 33\n","Evaluate Model\n","Subject 36|Rep 4\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 46\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 56\n","Evaluate Model\n","Subject 36|Rep 4\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 50\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 38\n","Evaluate Model\n","Subject 36|Rep 5\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 40\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 60\n","Evaluate Model\n","Subject 36|Rep 5\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 28\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 64\n","Evaluate Model\n","Subject 36|Rep 6\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 30\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 67\n","Evaluate Model\n","Subject 36|Rep 6\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 43\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 58\n","Evaluate Model\n","Subject 36|Rep 7\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 29\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 55\n","Evaluate Model\n","Subject 36|Rep 7\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 30\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 64\n","Evaluate Model\n","Subject 36|Rep 8\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 44\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 60\n","Evaluate Model\n","Subject 36|Rep 8\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 47\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 80\n","Evaluate Model\n","Subject 36|Rep 9\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 66\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 37\n","Evaluate Model\n","Subject 36|Rep 9\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 52\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 44\n","Evaluate Model\n","Subject 36|Rep 10\n","True Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 37\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 58\n","Evaluate Model\n","Subject 36|Rep 10\n","Permuted Data\n","Split Count: 1\n","Training Model\n","Epochs Trained: 92\n","Evaluate Model\n","Split Count: 2\n","Training Model\n","Epochs Trained: 35\n","Evaluate Model\n"]}]},{"cell_type":"code","metadata":{"id":"NjkLwq834c-V"},"source":["results_df.groupby(['Type','Shuffled']).mean()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t58LGCsO3RWB"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S4BAkNCd0p7_"},"source":[""],"execution_count":null,"outputs":[]}]}